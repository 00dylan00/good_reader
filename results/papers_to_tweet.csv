title,pmid,link,doi_link,keywords,abstract,citations,abstract_summary
Predictive coding networks for temporal prediction.,38557984,https://pubmed.ncbi.nlm.nih.gov/38557984/,https://doi.org/10.1371/journal.pcbi.1011183,[],"One of the key problems the brain faces is inferring the state of the world from a sequence of dynamically changing stimuli, and it is not yet clear how the sensory system achieves this task. A well-established computational framework for describing perceptual processes in the brain is provided by the theory of predictive coding. Although the original proposals of predictive coding have discussed temporal prediction, later work developing this theory mostly focused on static stimuli, and key questions on neural implementation and computational properties of temporal predictive coding networks remain open. Here, we address these questions and present a formulation of the temporal predictive coding model that can be naturally implemented in recurrent networks, in which activity dynamics rely only on local inputs to the neurons, and learning only utilises local Hebbian plasticity. Additionally, we show that temporal predictive coding networks can approximate the performance of the Kalman filter in predicting behaviour of linear systems, and behave as a variant of a Kalman filter which does not track its own subjective posterior variance. Importantly, temporal predictive coding networks can achieve similar accuracy as the Kalman filter without performing complex mathematical operations, but just employing simple computations that can be implemented by biological networks. Moreover, when trained with natural dynamic inputs, we found that temporal predictive coding can produce Gabor-like, motion-sensitive receptive fields resembling those observed in real neurons in visual areas. In addition, we demonstrate how the model can be effectively generalized to nonlinear systems. Overall, models presented in this paper show how biologically plausible circuits can predict future stimuli and may guide research on understanding specific neural circuits in brain areas involved in temporal prediction.",2,Predictive coding is a well-established computational framework for describing perceptual processes in the brain.
NeuronBridge: an intuitive web application for neuronal morphology search across large data sets.,38491365,https://pubmed.ncbi.nlm.nih.gov/38491365/,https://doi.org/10.1186/s12859-024-05732-7,"['Cloud computing', 'Connectomics', 'Database', 'Drosophila', 'Open data API', 'Serverless', 'Web service']","Neuroscience research in Drosophila is benefiting from large-scale connectomics efforts using electron microscopy (EM) to reveal all the neurons in a brain and their connections. To exploit this knowledge base, researchers relate a connectome's structure to neuronal function, often by studying individual neuron cell types. Vast libraries of fly driver lines expressing fluorescent reporter genes in sets of neurons have been created and imaged using confocal light microscopy (LM), enabling the targeting of neurons for experimentation. However, creating a fly line for driving gene expression within a single neuron found in an EM connectome remains a challenge, as it typically requires identifying a pair of driver lines where only the neuron of interest is expressed in both. This task and other emerging scientific workflows require finding similar neurons across large data sets imaged using different modalities.",1, Neuroscience research in Drosophila is benefiting from large-scale connectomics efforts using electron microscopy.
Mathematical models of Plasmodium vivax transmission: A scoping review.,38483975,https://pubmed.ncbi.nlm.nih.gov/38483975/,https://doi.org/10.1371/journal.pcbi.1011931,[],"Plasmodium vivax is one of the most geographically widespread malaria parasites in the world, primarily found across South-East Asia, Latin America, and parts of Africa. One of the significant characteristics of the P. vivax parasite is its ability to remain dormant in the human liver as hypnozoites and subsequently reactivate after the initial infection (i.e. relapse infections). Mathematical modelling approaches have been widely applied to understand P. vivax dynamics and predict the impact of intervention outcomes. Models that capture P. vivax dynamics differ from those that capture P. falciparum dynamics, as they must account for relapses caused by the activation of hypnozoites. In this article, we provide a scoping review of mathematical models that capture P. vivax transmission dynamics published between January 1988 and May 2023. The primary objective of this work is to provide a comprehensive summary of the mathematical models and techniques used to model P. vivax dynamics. In doing so, we aim to assist researchers working on mathematical epidemiology, disease transmission, and other aspects of P. vivax malaria by highlighting best practices in currently published models and highlighting where further model development is required. We categorise P. vivax models according to whether a deterministic or agent-based approach was used. We provide an overview of the different strategies used to incorporate the parasite's biology, use of multiple scales (within-host and population-level), superinfection, immunity, and treatment interventions. In most of the published literature, the rationale for different modelling approaches was driven by the research question at hand. Some models focus on the parasites' complicated biology, while others incorporate simplified assumptions to avoid model complexity. Overall, the existing literature on mathematical models for P. vivax encompasses various aspects of the parasite's dynamics. We recommend that future research should focus on refining how key aspects of P. vivax dynamics are modelled, including spatial heterogeneity in exposure risk and heterogeneity in susceptibility to infection, the accumulation of hypnozoite variation, the interaction between P. falciparum and P. vivax, acquisition of immunity, and recovery under superinfection.",1,Plasmodium vivax is one of the most geographically widespread malaria parasites in the world.
Prediction of protein-ligand binding affinity via deep learning models.,38446737,https://pubmed.ncbi.nlm.nih.gov/38446737/,https://doi.org/10.1093/bib/bbae081,"['accurate prediction', 'database', 'deep learning model', 'input representation', 'protein–ligand binding affinity']","Accurately predicting the binding affinity between proteins and ligands is crucial in drug screening and optimization, but it is still a challenge in computer-aided drug design. The recent success of AlphaFold2 in predicting protein structures has brought new hope for deep learning (DL) models to accurately predict protein-ligand binding affinity. However, the current DL models still face limitations due to the low-quality database, inaccurate input representation and inappropriate model architecture. In this work, we review the computational methods, specifically DL-based models, used to predict protein-ligand binding affinity. We start with a brief introduction to protein-ligand binding affinity and the traditional computational methods used to calculate them. We then introduce the basic principles of DL models for predicting protein-ligand binding affinity. Next, we review the commonly used databases, input representations and DL models in this field. Finally, we discuss the potential challenges and future work in accurately predicting protein-ligand binding affinity via DL models.",1,Accurately predicting the binding affinity between proteins and ligands is crucial in drug screening and optimization.
Ribotin: automated assembly and phasing of rDNA morphs.,38441320,https://pubmed.ncbi.nlm.nih.gov/38441320/,https://doi.org/10.1093/bioinformatics/btae124,[],"The ribosomal DNA (rDNA) arrays are highly repetitive and homogenous regions which exist in all life. Due to their repetitiveness, current assembly methods do not fully assemble the rDNA arrays in humans and many other eukaryotes, and so variation within the rDNA arrays cannot be effectively studied.",1,The ribosomal DNA (rDNA) arrays are highly repetitive and homogenous regions which exist in all life.
Methods and considerations for estimating parameters in biophysically detailed neural models with simulation based inference.,38408099,https://pubmed.ncbi.nlm.nih.gov/38408099/,https://doi.org/10.1371/journal.pcbi.1011108,[],"Biophysically detailed neural models are a powerful technique to study neural dynamics in health and disease with a growing number of established and openly available models. A major challenge in the use of such models is that parameter inference is an inherently difficult and unsolved problem. Identifying unique parameter distributions that can account for observed neural dynamics, and differences across experimental conditions, is essential to their meaningful use. Recently, simulation based inference (SBI) has been proposed as an approach to perform Bayesian inference to estimate parameters in detailed neural models. SBI overcomes the challenge of not having access to a likelihood function, which has severely limited inference methods in such models, by leveraging advances in deep learning to perform density estimation. While the substantial methodological advancements offered by SBI are promising, their use in large scale biophysically detailed models is challenging and methods for doing so have not been established, particularly when inferring parameters that can account for time series waveforms. We provide guidelines and considerations on how SBI can be applied to estimate time series waveforms in biophysically detailed neural models starting with a simplified example and extending to specific applications to common MEG/EEG waveforms using the the large scale neural modeling framework of the Human Neocortical Neurosolver. Specifically, we describe how to estimate and compare results from example oscillatory and event related potential simulations. We also describe how diagnostics can be used to assess the quality and uniqueness of the posterior estimates. The methods described provide a principled foundation to guide future applications of SBI in a wide variety of applications that use detailed models to study neural dynamics.",1,Biophysically detailed neural models are a powerful technique to study neural dynamics in health and disease.
Hound: a novel tool for automated mapping of genotype to phenotype in bacterial genomes assembled de novo.,38385882,https://pubmed.ncbi.nlm.nih.gov/38385882/,https://doi.org/10.1093/bib/bbae057,"['antibiotic resistance', 'genomic surveillance', 'reference-free']","Increasing evidence suggests that microbial species have a strong within species genetic heterogeneity. This can be problematic for the analysis of prokaryote genomes, which commonly relies on a reference genome to guide the assembly process. Differences between reference and sample genomes will therefore introduce errors in final assembly, jeopardizing the detection from structural variations to point mutations-critical for genomic surveillance of antibiotic resistance. Here we present Hound, a pipeline that integrates publicly available tools to assemble prokaryote genomes de novo, detect user-given genes by similarity to report mutations found in the coding sequence, promoter, as well as relative gene copy number within the assembly. Importantly, Hound can use the query sequence as a guide to merge contigs, and reconstruct genes that were fragmented by the assembler. To showcase Hound, we screened through 5032 bacterial whole-genome sequences isolated from farmed animals and human infections, using the amino acid sequence encoded by blaTEM-1, to detect and predict resistance to amoxicillin/clavulanate which is driven by over-expression of this gene. We believe this tool can facilitate the analysis of prokaryote species that currently lack a reference genome, and can be scaled either up to build automated systems for genomic surveillance or down to integrate into antibiotic susceptibility point-of-care diagnostics.",1,Hound is a pipeline that integrates publicly available tools to assemble prokaryote genomes de novo.
Acceleration of Graph Neural Network-Based Prediction Models in Chemistry via Co-Design Optimization on Intelligence Processing Units.,38382011,https://pubmed.ncbi.nlm.nih.gov/38382011/,https://doi.org/10.1021/acs.jcim.3c01312,[],"Atomic structure prediction and associated property calculations are the bedrock of chemical physics. Since high-fidelity ab initio modeling techniques for computing the structure and properties can be prohibitively expensive, this motivates the development of machine-learning (ML) models that make these predictions more efficiently. Training graph neural networks over large atomistic databases introduces unique computational challenges, such as the need to process millions of small graphs with variable size and support communication patterns that are distinct from learning over large graphs, such as social networks. We demonstrate a novel hardware-software codesign approach to scale up the training of atomistic graph neural networks (GNN) for structure and property prediction. First, to eliminate redundant computation and memory associated with alternative padding techniques and to improve throughput via minimizing communication, we formulate the effective coalescing of the batches of variable-size atomistic graphs as the bin packing problem and introduce a hardware-agnostic algorithm to pack these batches. In addition, we propose hardware-specific optimizations, including a planner and vectorization for the gather-scatter operations targeted for Graphcore's Intelligence Processing Unit (IPU), as well as model-specific optimizations such as merged communication collectives and optimized softplus. Putting these all together, we demonstrate the effectiveness of the proposed codesign approach by providing an implementation of a well-established atomistic GNN on the Graphcore IPUs. We evaluate the training performance on multiple atomistic graph databases with varying degrees of graph counts, sizes, and sparsity. We demonstrate that such a codesign approach can reduce the training time of atomistic GNNs and can improve their performance by up to 1.5× compared to the baseline implementation of the model on the IPUs. Additionally, we compare our IPU implementation with a Nvidia GPU-based implementation and show that our atomistic GNN implementation on the IPUs can run 1.8× faster on average compared to the execution time on the GPUs.",1,Atomic structure prediction and associated property calculations are the bedrock of chemical physics.
AlphaFold2 Predicts Whether Proteins Interact Amidst Confounding Structural Compatibility.,38373070,https://pubmed.ncbi.nlm.nih.gov/38373070/,https://doi.org/10.1021/acs.jcim.3c01805,[],"Predicting whether two proteins physically interact is one of the holy grails of computational biology, galvanized by rapid advancements in deep learning. AlphaFold2, although not developed with this goal, is promising in this respect. Here, I test the prediction capability of AlphaFold2 on a very challenging data set, where proteins are structurally compatible, even when they do not interact. AlphaFold2 achieves high discrimination between interacting and non-interacting proteins, and the cases of misclassifications can either be rescued by revisiting the input sequences or can suggest false positives and negatives in the data set. AlphaFold2 is thus not impaired by the compatibility between protein structures and has the potential to be applied on a large scale.",1,Predicting whether two proteins physically interact is one of the holy grails of computational biology.
Structure-Based Discovery of the SARS-CoV-2 Main Protease Noncovalent Inhibitors from Traditional Chinese Medicine.,38346323,https://pubmed.ncbi.nlm.nih.gov/38346323/,https://doi.org/10.1021/acs.jcim.3c01327,[],"Traditional Chinese medicine (TCM) has been extensively employed for the treatment of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). However, there is demand for discovering more SARS-CoV-2 Mpro inhibitors with diverse scaffolds to optimize anti-SARS-CoV-2 lead compounds. In this study, comprehensive in silico and in vitro assays were utilized to determine the potential inhibitors from TCM compounds against SARS-CoV-2 Mpro, which is an important therapeutic target for SARS-CoV-2. The ensemble docking analysis of 18263 TCM compounds against 15 SARS-CoV-2 Mpro conformations identified 19 TCM compounds as promising candidates. Further in vitro testing validated three compounds as inhibitors of SARS-CoV-2 Mpro and showed IC",1,Traditional Chinese medicine (TCM) has been extensively employed for the treatment of coronavirus disease 2019 (COVID-19) caused by SARS-CoV-2.
NFTest: automated testing of Nextflow pipelines.,38341660,https://pubmed.ncbi.nlm.nih.gov/38341660/,https://doi.org/10.1093/bioinformatics/btae081,[],The ongoing expansion in the volume of biomedical data has contributed to a growing complexity in the tools and technologies used in research with an increased reliance on complex workflows written in orchestration languages such as Nextflow to integrate algorithms into processing pipelines. The growing use of workflows involving various tools and algorithms has led to increased scrutiny of software development practices to avoid errors in individual tools and in the connections between them.,1,The expansion in the volume of biomedical data has contributed to a growing complexity in the tools and technologies used in research.
PipeVal: light-weight extensible tool for file validation.,38341658,https://pubmed.ncbi.nlm.nih.gov/38341658/,https://doi.org/10.1093/bioinformatics/btae079,[],"The volume of biomedical data generated each year is growing exponentially as high-throughput molecular, imaging and mHealth technologies expand. This rise in data volume has contributed to an increasing reliance on and demand for computational methods, and consequently to increased attention to software quality and data integrity.",1,"The volume of biomedical data generated each year is growing exponentially as high-throughput molecular, imaging and mHealth technologies expand."
labelSeg: segment annotation for tumor copy number alteration profiles.,38300514,https://pubmed.ncbi.nlm.nih.gov/38300514/,https://doi.org/10.1093/bib/bbad541,"['density-based clustering', 'segment annotation', 'somatic copy number alterations']","Somatic copy number alterations (SCNAs) are a predominant type of oncogenomic alterations that affect a large proportion of the genome in the majority of cancer samples. Current technologies allow high-throughput measurement of such copy number aberrations, generating results consisting of frequently large sets of SCNA segments. However, the automated annotation and integration of such data are particularly challenging because the measured signals reflect biased, relative copy number ratios. In this study, we introduce labelSeg, an algorithm designed for rapid and accurate annotation of CNA segments, with the aim of enhancing the interpretation of tumor SCNA profiles. Leveraging density-based clustering and exploiting the length-amplitude relationships of SCNA, our algorithm proficiently identifies distinct relative copy number states from individual segment profiles. Its compatibility with most CNA measurement platforms makes it suitable for large-scale integrative data analysis. We confirmed its performance on both simulated and sample-derived data from The Cancer Genome Atlas reference dataset, and we demonstrated its utility in integrating heterogeneous segment profiles from different data sources and measurement platforms. Our comparative and integrative analysis revealed common SCNA patterns in cancer and protein-coding genes with a strong correlation between SCNA and messenger RNA expression, promoting the investigation into the role of SCNA in cancer development.",1,Somatic copy number alterations (SCNAs) are a predominant type of oncogenomic alterations.
Real-World Molecular Out-Of-Distribution: Specification and Investigation.,38300258,https://pubmed.ncbi.nlm.nih.gov/38300258/,https://doi.org/10.1021/acs.jcim.3c01774,[],This study presents a rigorous framework for investigating molecular out-of-distribution (MOOD) generalization in drug discovery. The concept of MOOD is first clarified through a ,1,This study presents a rigorous framework for investigating molecular out-of-distribution (MOOD) generalization in drug discovery.
"SerotoninAI: Serotonergic System Focused, Artificial Intelligence-Based Application for Drug Discovery.",38289046,https://pubmed.ncbi.nlm.nih.gov/38289046/,https://doi.org/10.1021/acs.jcim.3c01517,[],"SerotoninAI is an innovative web application for scientific purposes focused on the serotonergic system. By leveraging SerotoninAI, researchers can assess the affinity (pKi value) of a molecule to all main serotonin receptors and serotonin transporters based on molecule structure introduced as SMILES. Additionally, the application provides essential insights into critical attributes of potential drugs such as blood-brain barrier penetration and human intestinal absorption. The complexity of the serotonergic system demands advanced tools for accurate predictions, which is a fundamental requirement in drug development. SerotoninAI addresses this need by providing an intuitive user interface that generates predictions of pKi values for the main serotonergic targets. The application is freely available on the Internet at https://serotoninai.streamlit.app/, implemented in Streamlit with all major web browsers supported. Currently, to the best of our knowledge, there is no tool that allows users to access affinity predictions for serotonergic targets without registration or financial obligations. SerotoninAI significantly increases the scope of drug development activities worldwide. The source code of the application is available at https://github.com/nczub/SerotoninAI_streamlit.",1,SerotoninAI is an innovative web application for scientific purposes focused on the serotonergic system.
Reconstructing growth and dynamic trajectories from single-cell transcriptomics data.,38274364,https://pubmed.ncbi.nlm.nih.gov/38274364/,https://doi.org/10.1038/s42256-023-00763-w,"['Data integration', 'Machine learning']","Time-series single-cell RNA sequencing (scRNA-seq) datasets provide unprecedented opportunities to learn dynamic processes of cellular systems. Due to the destructive nature of sequencing, it remains challenging to link the scRNA-seq snapshots sampled at different time points. Here we present TIGON, a dynamic, unbalanced optimal transport algorithm that reconstructs dynamic trajectories and population growth simultaneously as well as the underlying gene regulatory network from multiple snapshots. To tackle the high-dimensional optimal transport problem, we introduce a deep learning method using a dimensionless formulation based on the Wasserstein-Fisher-Rao (WFR) distance. TIGON is evaluated on simulated data and compared with existing methods for its robustness and accuracy in predicting cell state transition and cell population growth. Using three scRNA-seq datasets, we show the importance of growth in the temporal inference, TIGON's capability in reconstructing gene expression at unmeasured time points and its applications to temporal gene regulatory networks and cell-cell communication inference.",1,Time-series single-cell RNA sequencing (scRNA-seq) datasets provide unprecedented opportunities to learn dynamic processes of cellular systems.
A granularity-level information fusion strategy on hypergraph transformer for predicting synergistic effects of anticancer drugs.,38243692,https://pubmed.ncbi.nlm.nih.gov/38243692/,https://doi.org/10.1093/bib/bbad522,"['anticancer drugs', 'granularity-level information fusion', 'hypergraph', 'predicting synergistic effects', 'transformer']","Combination therapy has exhibited substantial potential compared to monotherapy. However, due to the explosive growth in the number of cancer drugs, the screening of synergistic drug combinations has become both expensive and time-consuming. Synergistic drug combinations refer to the concurrent use of two or more drugs to enhance treatment efficacy. Currently, numerous computational methods have been developed to predict the synergistic effects of anticancer drugs. However, there has been insufficient exploration of how to mine drug and cell line data at different granularity levels for predicting synergistic anticancer drug combinations. Therefore, this study proposes a granularity-level information fusion strategy based on the hypergraph transformer, named HypertranSynergy, to predict synergistic effects of anticancer drugs. HypertranSynergy introduces synergistic connections between cancer cell lines and drug combinations using hypergraph. Then, the Coarse-grained Information Extraction (CIE) module merges the hypergraph with a transformer for node embeddings. In the CIE module, Contranorm is a normalization layer that mitigates over-smoothing, while Gaussian noise addresses local information gaps. Additionally, the Fine-grained Information Extraction (FIE) module assesses fine-grained information's impact on predictions by employing similarity-aware matrices from drug/cell line features. Both CIE and FIE modules are integrated into HypertranSynergy. In addition, HypertranSynergy achieved the AUC of 0.93${\pm }$0.01 and the AUPR of 0.69${\pm }$0.02 in 5-fold cross-validation of classification task, and the RMSE of 13.77${\pm }$0.07 and the PCC of 0.81${\pm }$0.02 in 5-fold cross-validation of regression task. These results are better than most of the state-of-the-art models.",4,Synergistic drug combinations refer to the concurrent use of two or more drugs to enhance treatment efficacy.
Microbial interactions from a new perspective: reinforcement learning reveals new insights into microbiome evolution.,38212999,https://pubmed.ncbi.nlm.nih.gov/38212999/,https://doi.org/10.1093/bioinformatics/btae003,[],"Microbes are essential part of all ecosystems, influencing material flow and shaping their surroundings. Metabolic modeling has been a useful tool and provided tremendous insights into microbial community metabolism. However, current methods based on flux balance analysis (FBA) usually fail to predict metabolic and regulatory strategies that lead to long-term survival and stability especially in heterogenous communities.",1,"Microbes are essential part of all ecosystems, influencing material flow and shaping their surroundings."
High-performing neural network models of visual cortex benefit from high latent dimensionality.,38198504,https://pubmed.ncbi.nlm.nih.gov/38198504/,https://doi.org/10.1371/journal.pcbi.1011792,[],"Geometric descriptions of deep neural networks (DNNs) have the potential to uncover core representational principles of computational models in neuroscience. Here we examined the geometry of DNN models of visual cortex by quantifying the latent dimensionality of their natural image representations. A popular view holds that optimal DNNs compress their representations onto low-dimensional subspaces to achieve invariance and robustness, which suggests that better models of visual cortex should have lower dimensional geometries. Surprisingly, we found a strong trend in the opposite direction-neural networks with high-dimensional image subspaces tended to have better generalization performance when predicting cortical responses to held-out stimuli in both monkey electrophysiology and human fMRI data. Moreover, we found that high dimensionality was associated with better performance when learning new categories of stimuli, suggesting that higher dimensional representations are better suited to generalize beyond their training domains. These findings suggest a general principle whereby high-dimensional geometry confers computational benefits to DNN models of visual cortex.",1,Geometric descriptions of deep neural networks (DNNs) have the potential to uncover core representational principles of computational models in neuroscience.
Predicting drug-protein interactions by preserving the graph information of multi source data.,38177981,https://pubmed.ncbi.nlm.nih.gov/38177981/,https://doi.org/10.1186/s12859-023-05620-6,"['Drug–target interactions', 'Graph attention networks', 'Residual graph convolutional neural networks']","Examining potential drug-target interactions (DTIs) is a pivotal component of drug discovery and repurposing. Recently, there has been a significant rise in the use of computational techniques to predict DTIs. Nevertheless, previous investigations have predominantly concentrated on assessing either the connections between nodes or the consistency of the network's topological structure in isolation. Such one-sided approaches could severely hinder the accuracy of DTI predictions. In this study, we propose a novel method called TTGCN, which combines heterogeneous graph convolutional neural networks (GCN) and graph attention networks (GAT) to address the task of DTI prediction. TTGCN employs a two-tiered feature learning strategy, utilizing GAT and residual GCN (R-GCN) to extract drug and target embeddings from the diverse network, respectively. These drug and target embeddings are then fused through a mean-pooling layer. Finally, we employ an inductive matrix completion technique to forecast DTIs while preserving the network's node connectivity and topological structure. Our approach demonstrates superior performance in terms of area under the curve and area under the precision-recall curve in experimental comparisons, highlighting its significant advantages in predicting DTIs. Furthermore, case studies provide additional evidence of its ability to identify potential DTIs.",1,Examining potential drug-target interactions (DTIs) is a pivotal component of drug discovery and repurposing.
Joint deep autoencoder and subgraph augmentation for inferring microbial responses to drugs.,38171927,https://pubmed.ncbi.nlm.nih.gov/38171927/,https://doi.org/10.1093/bib/bbad483,"['deep autoencoder', 'microbe and drug subgraphs', 'microbial responses to drugs', 'multi-hop neighborhood information']","Exploring microbial stress responses to drugs is crucial for the advancement of new therapeutic methods. While current artificial intelligence methodologies have expedited our understanding of potential microbial responses to drugs, the models are constrained by the imprecise representation of microbes and drugs. To this end, we combine deep autoencoder and subgraph augmentation technology for the first time to propose a model called JDASA-MRD, which can identify the potential indistinguishable responses of microbes to drugs. In the JDASA-MRD model, we begin by feeding the established similarity matrices of microbe and drug into the deep autoencoder, enabling to extract robust initial features of both microbes and drugs. Subsequently, we employ the MinHash and HyperLogLog algorithms to account intersections and cardinality data between microbe and drug subgraphs, thus deeply extracting the multi-hop neighborhood information of nodes. Finally, by integrating the initial node features with subgraph topological information, we leverage graph neural network technology to predict the microbes' responses to drugs, offering a more effective solution to the 'over-smoothing' challenge. Comparative analyses on multiple public datasets confirm that the JDASA-MRD model's performance surpasses that of current state-of-the-art models. This research aims to offer a more profound insight into the adaptability of microbes to drugs and to furnish pivotal guidance for drug treatment strategies. Our data and code are publicly available at: https://github.com/ZZCrazy00/JDASA-MRD.",2,JDASA-MRD can identify the potential indistinguishable responses of microbes to drugs.
PyRates-A code-generation tool for modeling dynamical systems in biology and beyond.,38150479,https://pubmed.ncbi.nlm.nih.gov/38150479/,https://doi.org/10.1371/journal.pcbi.1011761,[],"The mathematical study of real-world dynamical systems relies on models composed of differential equations. Numerical methods for solving and analyzing differential equation systems are essential when complex biological problems have to be studied, such as the spreading of a virus, the evolution of competing species in an ecosystem, or the dynamics of neurons in the brain. Here we present PyRates, a Python-based software for modeling and analyzing differential equation systems via numerical methods. PyRates is specifically designed to account for the inherent complexity of biological systems. It provides a new language for defining models that mirrors the modular organization of real-world dynamical systems and thus simplifies the implementation of complex networks of interacting dynamic entities. Furthermore, PyRates provides extensive support for the various forms of interaction delays that can be observed in biological systems. The core of PyRates is a versatile code-generation system that translates user-defined models into ""backend"" implementations in various languages, including Python, Fortran, Matlab, and Julia. This allows users to apply a wide range of analysis methods for dynamical systems, eliminating the need for manual translation between code bases. PyRates may also be used as a model definition interface for the creation of custom dynamical systems tools. To demonstrate this, we developed two extensions of PyRates for common analyses of dynamic models of biological systems: PyCoBi for bifurcation analysis and RectiPy for parameter fitting. We demonstrate in a series of example models how PyRates can be used in combination with PyCoBi and RectiPy for model analysis and fitting. Together, these tools offer a versatile framework for applying computational modeling and numerical analysis methods to dynamical systems in biology and beyond.",1,PyRates is a Python-based software for modeling and analyzing differential equation systems via numerical methods. It is specifically designed to account for the inherent complexity of biological systems.
,38146436,https://pubmed.ncbi.nlm.nih.gov/38146436/,https://doi.org/10.1016/j.csbj.2023.11.048,"['Artificial intelligence', 'Computational biotechnology', 'Digital pathology', 'Immune', 'Response']","The immune response associated with oncogenesis and potential oncological ther- apeutic interventions has dominated the field of cancer research over the last decade. T-cell lymphocytes in the tumor microenvironment are a crucial aspect of cancer's adaptive immunity, and the quantification of T-cells in specific can- cer types has been suggested as a potential diagnostic aid. However, this is cur- rently not part of routine diagnostics. To address this challenge, we present a new method called ",1,T-cell lymphocytes in the tumor microenvironment are a crucial aspect of cancer's adaptive immunity.
Method to determine whether sleep phenotypes are driven by endogenous circadian rhythms or environmental light by combining longitudinal data and personalised mathematical models.,38134229,https://pubmed.ncbi.nlm.nih.gov/38134229/,https://doi.org/10.1371/journal.pcbi.1011743,[],"Sleep timing varies between individuals and can be altered in mental and physical health conditions. Sleep and circadian sleep phenotypes, including circadian rhythm sleep-wake disorders, may be driven by endogenous physiological processes, exogeneous environmental light exposure along with social constraints and behavioural factors. Identifying the relative contributions of these driving factors to different phenotypes is essential for the design of personalised interventions. The timing of the human sleep-wake cycle has been modelled as an interaction of a relaxation oscillator (the sleep homeostat), a stable limit cycle oscillator with a near 24-hour period (the circadian process), man-made light exposure and the natural light-dark cycle generated by the Earth's rotation. However, these models have rarely been used to quantitatively describe sleep at the individual level. Here, we present a new Homeostatic-Circadian-Light model (HCL) which is simpler, more transparent and more computationally efficient than other available models and is designed to run using longitudinal sleep and light exposure data from wearable sensors. We carry out a systematic sensitivity analysis for all model parameters and discuss parameter identifiability. We demonstrate that individual sleep phenotypes in each of 34 older participants (65-83y) can be described by feeding individual participant light exposure patterns into the model and fitting two parameters that capture individual average sleep duration and timing. The fitted parameters describe endogenous drivers of sleep phenotypes. We then quantify exogenous drivers using a novel metric which encodes the circadian phase dependence of the response to light. Combining endogenous and exogeneous drivers better explains individual mean mid-sleep (adjusted R-squared 0.64) than either driver on its own (adjusted R-squared 0.08 and 0.17 respectively). Critically, our model and analysis highlights that different people exhibiting the same sleep phenotype may have different driving factors and opens the door to personalised interventions to regularize sleep-wake timing that are readily implementable with current digital health technology.",1,"Sleep and circadian sleep phenotypes may be driven by endogenous physiological processes, exogeneous environmental light exposure along with social constraints and behavioural factors."
An agent-based modeling approach for lung fibrosis in response to COVID-19.,38127835,https://pubmed.ncbi.nlm.nih.gov/38127835/,https://doi.org/10.1371/journal.pcbi.1011741,[],"The severity of the COVID-19 pandemic has created an emerging need to investigate the long-term effects of infection on patients. Many individuals are at risk of suffering pulmonary fibrosis due to the pathogenesis of lung injury and impairment in the healing mechanism. Fibroblasts are the central mediators of extracellular matrix (ECM) deposition during tissue regeneration, regulated by anti-inflammatory cytokines including transforming growth factor beta (TGF-β). The TGF-β-dependent accumulation of fibroblasts at the damaged site and excess fibrillar collagen deposition lead to fibrosis. We developed an open-source, multiscale tissue simulator to investigate the role of TGF-β sources in the progression of lung fibrosis after SARS-CoV-2 exposure, intracellular viral replication, infection of epithelial cells, and host immune response. Using the model, we predicted the dynamics of fibroblasts, TGF-β, and collagen deposition for 15 days post-infection in virtual lung tissue. Our results showed variation in collagen area fractions between 2% and 40% depending on the spatial behavior of the sources (stationary or mobile), the rate of activation of TGF-β, and the duration of TGF-β sources. We identified M2 macrophages as primary contributors to higher collagen area fraction. Our simulation results also predicted fibrotic outcomes even with lower collagen area fraction when spatially-localized latent TGF-β sources were active for longer times. We validated our model by comparing simulated dynamics for TGF-β, collagen area fraction, and macrophage cell population with independent experimental data from mouse models. Our results showed that partial removal of TGF-β sources changed the fibrotic patterns; in the presence of persistent TGF-β sources, partial removal of TGF-β from the ECM significantly increased collagen area fraction due to maintenance of chemotactic gradients driving fibroblast movement. The computational findings are consistent with independent experimental and clinical observations of collagen area fractions and cell population dynamics not used in developing the model. These critical insights into the activity of TGF-β sources may find applications in the current clinical trials targeting TGF-β for the resolution of lung fibrosis.",2,Many individuals are at risk of suffering pulmonary fibrosis due to the pathogenesis of lung injury and impairment in the healing mechanism.
E2EATP: Fast and High-Accuracy Protein-ATP Binding Residue Prediction via Protein Language Model Embedding.,38127815,https://pubmed.ncbi.nlm.nih.gov/38127815/,https://doi.org/10.1021/acs.jcim.3c01298,[],"Identifying the ATP-binding sites of proteins is fundamentally important to uncover the mechanisms of protein functions and explore drug discovery. Many computational methods are proposed to predict ATP-binding sites. However, due to the limitation of the quality of feature representation, the prediction performance still has a big room for improvement. In this study, we propose an end-to-end deep learning model, E2EATP, to dig out more discriminative information from a protein sequence for improving the ATP-binding site prediction performance. Concretely, we employ a pretrained deep learning-based protein language model (ESM2) to automatically extract high-latent discriminative representations of protein sequences relevant for protein functions. Based on ESM2, we design a residual convolutional neural network to train a protein-ATP binding site prediction model. Furthermore, a weighted focal loss function is used to reduce the negative impact of imbalanced data on the model training stage. Experimental results on the two independent testing data sets demonstrate that E2EATP could achieve higher Matthew's correlation coefficient and AUC values than most existing state-of-the-art prediction methods. The speed (about 0.05 s per protein) of E2EATP is much faster than the other existing prediction methods. Detailed data analyses show that the major advantage of E2EATP lies at the utilization of the pretrained protein language model that extracts more discriminative information from the protein sequence only. The standalone package of E2EATP is freely available for academic at https://github.com/jun-csbio/e2eatp/.",1,Identifying the ATP-binding sites of proteins is fundamentally important to uncover the mechanisms of protein functions.
PEPMatch: a tool to identify short peptide sequence matches in large sets of proteins.,38110863,https://pubmed.ncbi.nlm.nih.gov/38110863/,https://doi.org/10.1186/s12859-023-05606-4,"['BLAST comparison', 'Benchmarking', 'Immunology', 'K-mer mapping', 'Peptide matching', 'Sequence searching', 'T-cell epitopes']","Numerous tools exist for biological sequence comparisons and search. One case of particular interest for immunologists is finding matches for linear peptide T cell epitopes, typically between 8 and 15 residues in length, in a large set of protein sequences. Both to find exact matches or matches that account for residue substitutions. The utility of such tools is critical in applications ranging from identifying conservation across viral epitopes, identifying putative epitope targets for allergens, and finding matches for cancer-associated neoepitopes to examine the role of tolerance in tumor recognition.",1,Many tools exist for biological sequence comparisons and search.
TCGAplot: an R package for integrative pan-cancer analysis and visualization of TCGA multi-omics data.,38105215,https://pubmed.ncbi.nlm.nih.gov/38105215/,https://doi.org/10.1186/s12859-023-05615-3,"['Pan-cancer analysis', 'TCGA', 'TCGAplot', 'User-defined function', 'Visualization']","Pan-cancer analysis examines both the commonalities and heterogeneity among genomic and cellular alterations across numerous types of tumors. Pan-cancer analysis of gene expression, tumor mutational burden (TMB), microsatellite instability (MSI), and tumor immune microenvironment (TIME), and methylation becomes available based on the multi-omics data from The Cancer Genome Atlas Program (TCGA). Some online tools provide analysis of gene and protein expression, mutation, methylation, and survival for TCGA data. However, these online tools were either Uni-functional or were not able to perform analysis of user-defined functions. Therefore, we created the TCGAplot R package to facilitate perform pan-cancer analysis and visualization of the built-in multi-omic TCGA data.",2,Pan-cancer analysis examines both the commonalities and heterogeneity among genomic and cellular alterations across numerous types of tumors.
Differentiable rotamer sampling with molecular force fields.,38095857,https://pubmed.ncbi.nlm.nih.gov/38095857/,https://doi.org/10.1093/bib/bbad456,"['Boltzmann generator', 'differentiable programming', 'molecular dynamics', 'neural network', 'rotameric sampling', 'statistical mechanics']","Molecular dynamics (MD) is the primary computational method by which modern structural biology explores macromolecule structure and function. Boltzmann generators have been proposed as an alternative to MD, by replacing the integration of molecular systems over time with the training of generative neural networks. This neural network approach to MD enables convergence to thermodynamic equilibrium faster than traditional MD; however, critical gaps in the theory and computational feasibility of Boltzmann generators significantly reduce their usability. Here, we develop a mathematical foundation to overcome these barriers; we demonstrate that the Boltzmann generator approach is sufficiently rapid to replace traditional MD for complex macromolecules, such as proteins in specific applications, and we provide a comprehensive toolkit for the exploration of molecular energy landscapes with neural networks.",1,Molecular dynamics (MD) is the primary computational method by which modern structural biology explores macromolecule structure and function.
ICBcomb: a comprehensive expression database for immune checkpoint blockade combination therapy.,38095856,https://pubmed.ncbi.nlm.nih.gov/38095856/,https://doi.org/10.1093/bib/bbad457,"['bioinformatics', 'cancer', 'combination therapy', 'database', 'immunotherapy', 'tumor immunology']","The success of immune checkpoint blockade (ICB) promotes the immunotherapy to be a new pillar in cancer treatment. However, the low response rate of the ICB therapy limits its application. To increase the response rate and enhance efficacy, the ICB combination therapy has emerged and its clinical trials are increasing. Nevertheless, the gene expression profile and its pattern of ICB combination were not comprehensively studied, which limits the understanding of the ICB combination therapy and the identification of new drugs. Here, we constructed ICBcomb (http://bioinfo.life.hust.edu.cn/ICBcomb/), a comprehensive database, by analyzing the human and mouse expression data of the ICB combination therapy and comparing them between groups treated with ICB, other drugs or their combinations. ICBcomb contains 1399 samples across 29 cancer types involving 52 drugs. It provides a user-friendly web interface for demonstrating the results of the available comparisons in the ICB combination therapy datasets with five functional modules: [1, 2] the 'Dataset/Disease' modules for browsing the expression, enrichment and comparison results in each dataset or disease; [3] the 'Gene' module for inputting a gene symbol and displaying its expression and comparison results across datasets/diseases; [4] the 'Gene Set' module for GSVA/GSEA enrichment analysis on the built-in gene sets and the user-input gene sets in different comparisons; [5] the 'Immune Cell' module for immune cell infiltration comparison between different groups by immune cell abundance analysis. The ICBcomb database provides the first resource for gene expression profile and comparison in ICB combination therapy, which may provide clues for discovering the mechanism of effective combination strategies and new combinatory drugs.",1,ICBcomb contains 1399 samples across 29 cancer types involving 52 drugs.
Exploring the relationship between ,38094217,https://pubmed.ncbi.nlm.nih.gov/38094217/,https://doi.org/10.1016/j.csbj.2023.11.027,"['Dysbiosis', 'Gut', 'Inflammatory bowel disease', 'Microbiota', 'Therapies']","Inflammatory bowel disease (IBD) is a group of disorders characterized by an inflammation of the gastrointestinal tract (GIT) and represents a major social and economic burden. Despite ongoing research into the etiology and pathophysiology of this multifactorial disease, treatment options remain limited. From this perspective, the gut microbiota has emerged as a potential player in the pathogenesis of IBD, and animal and human studies support this hypothesis. Indeed, the human gut is one of the most complex ecological communities (composed of 10",1,Inflammatory bowel disease (IBD) is a group of disorders characterized by an inflammation of the gastrointestinal tract.
Local Disordered Region Sampling (LDRS) for ensemble modeling of proteins with experimentally undetermined or low confidence prediction segments.,38060268,https://pubmed.ncbi.nlm.nih.gov/38060268/,https://doi.org/10.1093/bioinformatics/btad739,[],"The Local Disordered Region Sampling (LDRS, pronounced loaders) tool is a new module developed for IDPConformerGenerator, a previously validated approach to model intrinsically disordered proteins (IDPs). The IDPConformerGenerator LDRS module provides a method for generating all-atom conformations of intrinsically disordered protein regions at N- and C-termini of and in loops or linkers between folded regions of an existing protein structure. These disordered elements often lead to missing coordinates in experimental structures or low confidence in predicted structures. Requiring only a pre-existing PDB or mmCIF formatted structural template of the protein with missing coordinates or with predicted confidence scores and its full-length primary sequence, LDRS will automatically generate physically meaningful conformational ensembles of the missing flexible regions to complete the full-length protein. The capabilities of the LDRS tool of IDPConformerGenerator include modeling phosphorylation sites using enhanced Monte Carlo-Side Chain Entropy, transmembrane proteins within an all-atom bilayer, and multi-chain complexes. The modeling capacity of LDRS capitalizes on the modularity, the ability to be used as a library and via command-line, and the computational speed of the IDPConformerGenerator platform.",2,The Local Disordered Region Sampling (LDRS) tool is a new module developed for IDPConformerGenerator.
Major depressive disorder and bistability in an HPA-CNS toggle switch.,38055769,https://pubmed.ncbi.nlm.nih.gov/38055769/,https://doi.org/10.1371/journal.pcbi.1011645,[],"Major depressive disorder (MDD) is the most common psychiatric disorder. It has a complex and heterogeneous etiology. Most treatments take weeks to show effects and work well only for a fraction of the patients. Thus, new concepts are needed to understand MDD and its dynamics. One of the strong correlates of MDD is increased activity and dysregulation of the hypothalamic-pituitary-adrenal (HPA) axis which produces the stress hormone cortisol. Existing mathematical models of the HPA axis describe its operation on the scale of hours, and thus are unable to explore the dynamic on the scale of weeks that characterizes many aspects of MDD. Here, we propose a mathematical model of MDD on the scale of weeks, a timescale provided by the growth of the HPA hormone glands under control of HPA hormones. We add to this the mutual inhibition of the HPA axis and the hippocampus and other regions of the central nervous system (CNS) that forms a toggle switch. The model shows bistability between euthymic and depressed states, with a slow timescale of weeks in its dynamics. It explains why prolonged but not acute stress can trigger a self-sustaining depressive episode that persists even after the stress is removed. The model explains the weeks timescale for drugs to take effect, as well as the dysregulation of the HPA axis in MDD, based on gland mass changes. This understanding of MDD dynamics may help to guide strategies for treatment.",1,Major depressive disorder (MDD) is the most common psychiatric disorder. It has a complex and heterogeneous etiology.
An automated pipeline integrating AlphaFold 2 and MODELLER for protein structure prediction.,38047234,https://pubmed.ncbi.nlm.nih.gov/38047234/,https://doi.org/10.1016/j.csbj.2023.10.056,"['AlphaFold 2', 'Deep learning', 'MODELLER', 'Protein structure prediction']","The ability to predict a protein's three-dimensional conformation represents a crucial starting point for investigating evolutionary connections with other members of the corresponding protein family, examining interactions with other proteins, and potentially utilizing this knowledge for the purpose of rational drug design. In this work, we evaluated the feasibility of improving AlphaFold2's three-dimensional protein predictions by developing a novel pipeline (AlphaMod) that incorporates AlphaFold2 with MODELLER, a template-based modeling program. Additionally, our tool can drive a comprehensive quality assessment of the tertiary protein structure by incorporating and comparing a set of different quality assessment tools. The outcomes of selected tools are combined into a composite score (BORDASCORE) that exhibits a meaningful correlation with GDT_TS and facilitates the selection of optimal models in the absence of a reference structure. To validate AlphaMod's results, we conducted evaluations using two distinct datasets summing up to 72 targets, previously used to independently assess AlphaFold2's performance. The generated models underwent evaluation through two methods: i) averaging the GDT_TS scores across all produced structures for a single target sequence, and ii) a pairwise comparison of the best structures generated by AlphaFold2 and AlphaMod. The latter, within the unsupervised setups, shows a rising accuracy of approximately 34% over AlphaFold2. While, when considering the supervised setup, AlphaMod surpasses AlphaFold2 in 18% of the instances. Finally, there is an 11% correspondence in outcomes between the diverse methodologies. Consequently, AlphaMod's best-predicted tertiary structures in several cases exhibited a significant improvement in the accuracy of the predictions with respect to the best models obtained by AlphaFold2. This pipeline paves the way for the integration of additional data and AI-based algorithms to further improve the reliability of the predictions.",1,The ability to predict a protein's three-dimensional conformation represents a crucial starting point for investigating evolutionary connections with other members of the corresponding protein family.
VAP risk index: Early prediction and hospital phenotyping of ventilator-associated pneumonia using machine learning.,38042602,https://pubmed.ncbi.nlm.nih.gov/38042602/,https://doi.org/10.1016/j.artmed.2023.102715,"['Clinical suspicion of infection', 'Early prediction', 'Inter-hospital comparison', 'Machine learning', 'Ventilator-associated pneumonia']","Ventilator-associated pneumonia (VAP) is a leading cause of morbidity and mortality in intensive care units (ICUs). Early identification of patients at risk of VAP enables early intervention, which in turn improves patient outcomes. We developed a predictive model for individualized risk assessment utilizing machine learning to identify patients at risk of developing VAP.",1,Ventilator-associated pneumonia (VAP) is a leading cause of morbidity and mortality in intensive care units.
Learning massive interpretable gene regulatory networks of the human brain by merging Bayesian networks.,38039337,https://pubmed.ncbi.nlm.nih.gov/38039337/,https://doi.org/10.1371/journal.pcbi.1011443,[],"We present the Fast Greedy Equivalence Search (FGES)-Merge, a new method for learning the structure of gene regulatory networks via merging locally learned Bayesian networks, based on the fast greedy equivalent search algorithm. The method is competitive with the state of the art in terms of the Matthews correlation coefficient, which takes into account both precision and recall, while also improving upon it in terms of speed, scaling up to tens of thousands of variables and being able to use empirical knowledge about the topological structure of gene regulatory networks. To showcase the ability of our method to scale to massive networks, we apply it to learning the gene regulatory network for the full human genome using data from samples of different brain structures (from the Allen Human Brain Atlas). Furthermore, this Bayesian network model should predict interactions between genes in a way that is clear to experts, following the current trends in explainable artificial intelligence. To achieve this, we also present a new open-access visualization tool that facilitates the exploration of massive networks and can aid in finding nodes of interest for experimental tests.",1,Fast Greedy Equivalence Search (FGES)-Merge is a new method for learning the structure of gene regulatory networks.
Hostile: accurate decontamination of microbial host sequences.,38039142,https://pubmed.ncbi.nlm.nih.gov/38039142/,https://doi.org/10.1093/bioinformatics/btad728,[],Microbial sequences generated from clinical samples are often contaminated with human host sequences that must be removed for ethical and legal reasons. Care must be taken to excise host sequences without inadvertently removing target microbial sequences to the detriment of downstream analyses such as variant calling and de novo assembly.,1,Microbial sequences generated from clinical samples are often contaminated with human host sequences that must be removed for ethical and legal reasons.
The application of machine learning methods to the prediction of novel ligands for ROR,38022699,https://pubmed.ncbi.nlm.nih.gov/38022699/,https://doi.org/10.1016/j.csbj.2023.10.021,"['Machine learning', 'Nuclear receptors', 'QSAR', 'RORγ', 'Virtual screening']","In this work, we developed and applied a computational procedure for creating and validating predictive models capable of estimating the biological activity of ligands. The combination of modern machine learning methods, experimental data, and the appropriate setup of molecular descriptors led to a set of well-performing models. We thoroughly inspected both the methodological space and various possibilities for creating a chemical feature space. The resulting models were applied to the virtual screening of the ZINC20 database to identify new, biologically active ligands of ROR",1,"In this work, we developed and applied a computational procedure for creating and validating predictive models."
DeepProSite: structure-aware protein binding site prediction using ESMFold and pretrained language model.,38015872,https://pubmed.ncbi.nlm.nih.gov/38015872/,https://doi.org/10.1093/bioinformatics/btad718,[],"Identifying the functional sites of a protein, such as the binding sites of proteins, peptides, or other biological components, is crucial for understanding related biological processes and drug design. However, existing sequence-based methods have limited predictive accuracy, as they only consider sequence-adjacent contextual features and lack structural information.",1,Identifying the functional sites of a protein is crucial for understanding related biological processes and drug design.
Term-BLAST-like alignment tool for concept recognition in noisy clinical texts.,38001031,https://pubmed.ncbi.nlm.nih.gov/38001031/,https://doi.org/10.1093/bioinformatics/btad716,[],"Methods for concept recognition (CR) in clinical texts have largely been tested on abstracts or articles from the medical literature. However, texts from electronic health records (EHRs) frequently contain spelling errors, abbreviations, and other nonstandard ways of representing clinical concepts.",1, Methods for concept recognition (CR) in clinical texts have largely been tested on abstracts or articles from the medical literature.
"Transfer learning for clustering single-cell RNA-seq data crossing-species and batch, case on uterine fibroids.",37991248,https://pubmed.ncbi.nlm.nih.gov/37991248/,https://doi.org/10.1093/bib/bbad426,"['batch effect', 'graph convolutional networks', 'single-cell RNA-seq data', 'transfer learning', 'uterine fibroids']","Due to the high dimensionality and sparsity of the gene expression matrix in single-cell RNA-sequencing (scRNA-seq) data, coupled with significant noise generated by shallow sequencing, it poses a great challenge for cell clustering methods. While numerous computational methods have been proposed, the majority of existing approaches center on processing the target dataset itself. This approach disregards the wealth of knowledge present within other species and batches of scRNA-seq data. In light of this, our paper proposes a novel method named graph-based deep embedding clustering (GDEC) that leverages transfer learning across species and batches. GDEC integrates graph convolutional networks, effectively overcoming the challenges posed by sparse gene expression matrices. Additionally, the incorporation of DEC in GDEC enables the partitioning of cell clusters within a lower-dimensional space, thereby mitigating the adverse effects of noise on clustering outcomes. GDEC constructs a model based on existing scRNA-seq datasets and then applying transfer learning techniques to fine-tune the model using a limited amount of prior knowledge gleaned from the target dataset. This empowers GDEC to adeptly cluster scRNA-seq data cross different species and batches. Through cross-species and cross-batch clustering experiments, we conducted a comparative analysis between GDEC and conventional packages. Furthermore, we implemented GDEC on the scRNA-seq data of uterine fibroids. Compared results obtained from the Seurat package, GDEC unveiled a novel cell type (epithelial cells) and identified a notable number of new pathways among various cell types, thus underscoring the enhanced analytical capabilities of GDEC. Availability and implementation: https://github.com/YuzhiSun/GDEC/tree/main.",1,The high dimensionality and sparsity of the gene expression matrix in single-cell RNA-sequencing (scRNA-seq) data poses a great challenge for cell clustering methods.
Identifying promoter sequence architectures via a chunking-based algorithm using non-negative matrix factorisation.,37983292,https://pubmed.ncbi.nlm.nih.gov/37983292/,https://doi.org/10.1371/journal.pcbi.1011491,[],"Core promoters are stretches of DNA at the beginning of genes that contain information that facilitates the binding of transcription initiation complexes. Different functional subsets of genes have core promoters with distinct architectures and characteristic motifs. Some of these motifs inform the selection of transcription start sites (TSS). By discovering motifs with fixed distances from known TSS positions, we could in principle classify promoters into different functional groups. Due to the variability and overlap of architectures, promoter classification is a difficult task that requires new approaches. In this study, we present a new method based on non-negative matrix factorisation (NMF) and the associated software called seqArchR that clusters promoter sequences based on their motifs at near-fixed distances from a reference point, such as TSS. When combined with experimental data from CAGE, seqArchR can efficiently identify TSS-directing motifs, including known ones like TATA, DPE, and nucleosome positioning signal, as well as novel lineage-specific motifs and the function of genes associated with them. By using seqArchR on developmental time courses, we reveal how relative use of promoter architectures changes over time with stage-specific expression. seqArchR is a powerful tool for initial genome-wide classification and functional characterisation of promoters. Its use cases are more general: it can also be used to discover any motifs at near-fixed distances from a reference point, even if they are present in only a small subset of sequences.",1,Core promoters are stretches of DNA at the beginning of genes that contain information that facilitates the binding of transcription initiation complexes.
Overcoming chemotherapy resistance in low-grade gliomas: A computational approach.,37983271,https://pubmed.ncbi.nlm.nih.gov/37983271/,https://doi.org/10.1371/journal.pcbi.1011208,[],"Low-grade gliomas are primary brain tumors that arise from glial cells and are usually treated with temozolomide (TMZ) as a chemotherapeutic option. They are often incurable, but patients have a prolonged survival. One of the shortcomings of the treatment is that patients eventually develop drug resistance. Recent findings show that persisters, cells that enter a dormancy state to resist treatment, play an important role in the development of resistance to TMZ. In this study we constructed a mathematical model of low-grade glioma response to TMZ incorporating a persister population. The model was able to describe the volumetric longitudinal dynamics, observed in routine FLAIR 3D sequences, of low-grade glioma patients acquiring TMZ resistance. We used the model to explore different TMZ administration protocols, first on virtual clones of real patients and afterwards on virtual patients preserving the relationships between parameters of real patients. In silico clinical trials showed that resistance development was deferred by protocols in which individual doses are administered after rest periods, rather than the 28-days cycle standard protocol. This led to median survival gains in virtual patients of more than 15 months when using resting periods between two and three weeks and agreed with recent experimental observations in animal models. Additionally, we tested adaptive variations of these new protocols, what showed a potential reduction in toxicity, but no survival gain. Our computational results highlight the need of further clinical trials that could obtain better results from treatment with TMZ in low grade gliomas.",1,"Low-grade gliomas are incurable, but patients have a prolonged survival. One of the shortcomings of the treatment is that patients eventually develop drug resistance."
Computational design of novel Cas9 PAM-interacting domains using evolution-based modelling and structural quality assessment.,37976326,https://pubmed.ncbi.nlm.nih.gov/37976326/,https://doi.org/10.1371/journal.pcbi.1011621,[],"We present here an approach to protein design that combines (i) scarce functional information such as experimental data (ii) evolutionary information learned from a natural sequence variants and (iii) physics-grounded modeling. Using a Restricted Boltzmann Machine (RBM), we learn a sequence model of a protein family. We use semi-supervision to leverage available functional information during the RBM training. We then propose a strategy to explore the protein representation space that can be informed by external models such as an empirical force-field method (FoldX). Our approach is applied to a domain of the Cas9 protein responsible for recognition of a short DNA motif. We experimentally assess the functionality of 71 variants generated to explore a range of RBM and FoldX energies. Sequences with as many as 50 differences (20% of the protein domain) to the wild-type retained functionality. Overall, 21/71 sequences designed with our method were functional. Interestingly, 6/71 sequences showed an improved activity in comparison with the original wild-type protein sequence. These results demonstrate the interest in further exploring the synergies between machine-learning of protein sequence representations and physics grounded modeling strategies informed by structural information.",1,"Using a Restricted Boltzmann Machine (RBM), we learn a sequence model of a protein family."
The mechanism of MinD stability modulation by MinE in Min protein dynamics.,37976301,https://pubmed.ncbi.nlm.nih.gov/37976301/,https://doi.org/10.1371/journal.pcbi.1011615,[],"The patterns formed both in vivo and in vitro by the Min protein system have attracted much interest because of the complexity of their dynamic interactions given the apparent simplicity of the component parts. Despite both the experimental and theoretical attention paid to this system, the details of the biochemical interactions of MinD and MinE, the proteins responsible for the patterning, are still unclear. For example, no model consistent with the known biochemistry has yet accounted for the observed dual role of MinE in the membrane stability of MinD. Until now, a statistical comparison of models to the time course of Min protein concentrations on the membrane has not been carried out. Such an approach is a powerful way to test existing and novel models that are difficult to test using a purely experimental approach. Here, we extract time series from previously published fluorescence microscopy time lapse images of in vitro experiments and fit two previously described and one novel mathematical model to the data. We find that the novel model, which we call the Asymmetric Activation with Bridged Stability Model, fits the time-course data best. It is also consistent with known biochemistry and explains the dual MinE role via MinE-dependent membrane stability that transitions under the influence of rising MinE to membrane instability with positive feedback. Our results reveal a more complex network of interactions between MinD and MinE underlying Min-system dynamics than previously considered.",1,The patterns formed both in vivo and in vitro by the Min protein system have attracted much interest.
Inferring microbial interactions with their environment from genomic and metagenomic data.,37956203,https://pubmed.ncbi.nlm.nih.gov/37956203/,https://doi.org/10.1371/journal.pcbi.1011661,[],"Microbial communities assemble through a complex set of interactions between microbes and their environment, and the resulting metabolic impact on the host ecosystem can be profound. Microbial activity is known to impact human health, plant growth, water quality, and soil carbon storage which has lead to the development of many approaches and products meant to manipulate the microbiome. In order to understand, predict, and improve microbial community engineering, genome-scale modeling techniques have been developed to translate genomic data into inferred microbial dynamics. However, these techniques rely heavily on simulation to draw conclusions which may vary with unknown parameters or initial conditions, rather than more robust qualitative analysis. To better understand microbial community dynamics using genome-scale modeling, we provide a tool to investigate the network of interactions between microbes and environmental metabolites over time. Using our previously developed algorithm for simulating microbial communities from genome-scale metabolic models (GSMs), we infer the set of microbe-metabolite interactions within a microbial community in a particular environment. Because these interactions depend on the available environmental metabolites, we refer to the networks that we infer as metabolically contextualized, and so name our tool MetConSIN: Metabolically Contextualized Species Interaction Networks.",1,"Microbial activity is known to impact human health, plant growth, water quality, and soil carbon storage."
ILIAD: a suite of automated Snakemake workflows for processing genomic data for downstream applications.,37940870,https://pubmed.ncbi.nlm.nih.gov/37940870/,https://doi.org/10.1186/s12859-023-05548-x,"['Genetic data', 'Genome mapping', 'Genomics', 'Iliad', 'Pipeline', 'Snakemake', 'Variant calling', 'Workflow']","Processing raw genomic data for downstream applications such as imputation, association studies, and modeling requires numerous third-party bioinformatics software tools. It is highly time-consuming and resource-intensive with computational demands and storage limitations that pose significant challenges that increase cost. The use of software tools independent of one another, in a disjointed stepwise fashion, increases the difficulty and sets forth higher error rates because of fragmented job executions in alignment, variant calling, and/or build conversion complications. As sequencing data availability grows, the ability for biologists to process it using stable, automated, and reproducible workflows is paramount as it significantly reduces the time to generate clean and reliable data.",1," Processing raw genomic data for downstream applications such as imputation, association studies, and modeling requires numerous third-party bioinformatics software tools."
aPEAR: an R package for autonomous visualization of pathway enrichment networks.,37935424,https://pubmed.ncbi.nlm.nih.gov/37935424/,https://doi.org/10.1093/bioinformatics/btad672,[],"The interpretation of pathway enrichment analysis results is frequently complicated by an overwhelming and redundant list of significantly affected pathways. Here, we present an R package aPEAR (Advanced Pathway Enrichment Analysis Representation) which leverages similarities between the pathway gene sets and represents them as a network of interconnected clusters. Each cluster is assigned a meaningful name that highlights the main biological themes in the experiment. Our approach enables an automated and objective overview of the data without manual and time-consuming parameter tweaking.",3,R package aPEAR leverages similarities between the pathway gene sets and represents them as a network of interconnected clusters.
PROSTATA: a framework for protein stability assessment using transformers.,37935419,https://pubmed.ncbi.nlm.nih.gov/37935419/,https://doi.org/10.1093/bioinformatics/btad671,[],"Accurate prediction of change in protein stability due to point mutations is an attractive goal that remains unachieved. Despite the high interest in this area, little consideration has been given to the transformer architecture, which is dominant in many fields of machine learning.",1,Accurate prediction of change in protein stability due to point mutations is an attractive goal that remains unachieved.
FLED: a full-length eccDNA detector for long-reads sequencing data.,37930031,https://pubmed.ncbi.nlm.nih.gov/37930031/,https://doi.org/10.1093/bib/bbad388,"['extrachromosomal circular DNA', 'full-length detection', 'long-read sequencing technology']","Reconstructing the full-length sequence of extrachromosomal circular DNA (eccDNA) from short sequencing reads has proved challenging given the similarity of eccDNAs and their corresponding linear DNAs. Previous sequencing methods were unable to achieve high-throughput detection of full-length eccDNAs. Herein, a novel algorithm was developed, called Full-Length eccDNA Detection (FLED), to reconstruct the sequence of eccDNAs based on the strategy that combined rolling circle amplification and nanopore long-reads sequencing technology. Seven human epithelial and cancer cell line samples were analyzed by FLED and over 5000 full-length eccDNAs were identified per sample. The structures of identified eccDNAs were validated by both Polymerase Chain Reaction (PCR) and Sanger sequencing. Compared to other published nanopore-based eccDNA detectors, FLED exhibited higher sensitivity. In cancer cell lines, the genes overlapped with eccDNA regions were enriched in cancer-related pathways and cis-regulatory elements can be predicted in the upstream or downstream of intact genes on eccDNA molecules, and the expressions of these cancer-related genes were dysregulated in tumor cell lines, indicating the regulatory potency of eccDNAs in biological processes. The proposed method takes advantage of nanopore long reads and enables unbiased reconstruction of full-length eccDNA sequences. FLED is implemented using Python3 which is freely available on GitHub (https://github.com/FuyuLi/FLED).",2,Reconstructing the full-length sequence of extrachromosomal circular DNA (eccDNA) from short sequencing reads has proved challenging.
"Diagnosis of Alzheimer's disease by joining dual attention CNN and MLP based on structural MRIs, clinical and genetic data.",37925204,https://pubmed.ncbi.nlm.nih.gov/37925204/,https://doi.org/10.1016/j.artmed.2023.102678,"['Alzheimer’s disease', 'Attention mechanism', 'Convolutional neural network', 'Multi-modality data', 'Multilayer perceptron']","Alzheimer's disease (AD) is an irreversible central nervous degenerative disease, while mild cognitive impairment (MCI) is a precursor state of AD. Accurate early diagnosis of AD is conducive to the prevention and early intervention treatment of AD. Although some computational methods have been developed for AD diagnosis, most employ only neuroimaging, ignoring other data (e.g., genetic, clinical) that may have potential disease information. In addition, the results of some methods lack interpretability. In this work, we proposed a novel method (called DANMLP) of joining dual attention convolutional neural network (CNN) and multilayer perceptron (MLP) for computer-aided AD diagnosis by integrating multi-modality data of the structural magnetic resonance imaging (sMRI), clinical data (i.e., demographics, neuropsychology), and APOE genetic data. Our DANMLP consists of four primary components: (1) the Patch-CNN for extracting the image characteristics from each local patch, (2) the position self-attention block for capturing the dependencies between features within a patch, (3) the channel self-attention block for capturing dependencies of inter-patch features, (4) two MLP networks for extracting the clinical features and outputting the AD classification results, respectively. Compared with other state-of-the-art methods in the 5CV test, DANMLP achieves 93% and 82.4% classification accuracy for the AD vs. MCI and MCI vs. NC tasks on the ADNI database, which is 0.2%∼15.2% and 3.4%∼26.8% higher than that of other five methods, respectively. The individualized visualization of focal areas can also help clinicians in the early diagnosis of AD. These results indicate that DANMLP can be effectively used for diagnosing AD and MCI patients.",1,Alzheimer's disease (AD) is an irreversible central nervous degenerative disease. Mild cognitive impairment (MCI) is a precursor state of AD.
Research agenda for using artificial intelligence in health governance: interpretive scoping review and framework.,37904172,https://pubmed.ncbi.nlm.nih.gov/37904172/,https://doi.org/10.1186/s13040-023-00346-w,"['Artificial intelligence', 'Framework', 'Governance', 'Health system', 'Stewardship']","The governance of health systems is complex in nature due to several intertwined and multi-dimensional factors contributing to it. Recent challenges of health systems reflect the need for innovative approaches that can minimize adverse consequences of policies. Hence, there is compelling evidence of a distinct outlook on the health ecosystem using artificial intelligence (AI). Therefore, this study aimed to investigate the roles of AI and its applications in health system governance through an interpretive scoping review of current evidence.",1,The governance of health systems is complex in nature due to several intertwined and multi-dimensional factors contributing to it.
Extracting cancer concepts from clinical notes using natural language processing: a systematic review.,37898795,https://pubmed.ncbi.nlm.nih.gov/37898795/,https://doi.org/10.1186/s12859-023-05480-0,"['Information system', 'Machine learning', 'NLP', 'Natural language processing', 'Neoplasms', 'Systematic review', 'Terminology']",Extracting information from free texts using natural language processing (NLP) can save time and reduce the hassle of manually extracting large quantities of data from incredibly complex clinical notes of cancer patients. This study aimed to systematically review studies that used NLP methods to identify cancer concepts from clinical notes automatically.,1,Natural language processing (NLP) can save time and reduce the hassle of manually extracting large quantities of data from incredibly complex clinical notes of cancer patients.
An End-to-End Deep Hybrid Autoencoder Based Method for Single-Cell RNA-Seq Data Analysis.,37889828,https://pubmed.ncbi.nlm.nih.gov/37889828/,https://doi.org/10.1109/TCBB.2023.3328029,[],"Single-cell RNA sequencing technology provides powerful support for researchers to understand the complex mechanisms of cells at the single-cell level. Due to the high sparsity, technical noise, and computational complexity of single-cell transcriptome data, the existing data analysis methods are unable to effectively extract the fine-grained characteristics of scRNA-seq data, resulting in inaccurately analyze the heterogeneity of the individual cell from a great quantity of cell mixtures. To address these shortcomings, we proposed an end-to-end analysis method called dhaSCA, which integrates the Graph convolutional neural network (GCN) feature learning and downstream tasks such as classification and imputation into a unified deep learning manner. dhaSCA uses hybrid GCN-MLP deep autoencoder and to capture structural information between cells, and learn the low dimensional cell representation. It also introduces downstream tasks as constraints to guide the model to learn more accurate cell features. We conducted various experiments to evaluate the performance of dhaSCA based on eight real RNA-Seq datasets, including classification, imputation, clustering, and visualization. The results show that dhaSCA outperforms other state-of-the-art methods in these downstream tasks. Therefore, dhaSCA is able to obtain a richer representation of cells, and provides strong support for efficient analysis of single-cell data.",1,Single-cell RNA sequencing technology provides powerful support for researchers to understand the complex mechanisms of cells at the single-cell level.
Genome-wide association mapping highlights candidate genes and immune genotypes for net blotch and powdery mildew resistance in barley.,37867969,https://pubmed.ncbi.nlm.nih.gov/37867969/,https://doi.org/10.1016/j.csbj.2023.10.014,"['Disease resistance', 'GWAS', 'Gene models', 'Hordeum vulgare L.', 'LD', 'Net blotch', 'Powdery mildew']","Net blotch (NB) and powdery mildew (PM) are major barley diseases with the potential to cause a dramatic loss in grain yield. Breeding for resistant barley genotypes in combination with identifying candidate resistant genes will accelerate the genetic improvement for resistance to NB and PM. To address this challenge, a set of 122 highly diverse barley genotypes from 34 countries were evaluated for NB and PM resistance under natural infection for in two growing seasons. Moreover, four yield traits; plant height (Ph), spike length (SL), spike weight (SW), and the number of spikelets per spike (NOS) were recorded. High genetic variation was found among genotypes in all traits scored in this study. No significant phenotypic correlation was found in the resistance between PM and NB. Immune genotypes for NB and PM were identified. A total of 21 genotypes were immune to both diseases. Of the 21 genotypes, the German genotype HOR_9570 was selected as the most promising genotype that can be used for future breeding programs. Furthermore, a genome-wide association study (GWAS) was used to identify resistant alleles to PM and NB. The results of GWAS revealed a set of 14 and 25 significant SNPs that were associated with increased resistance to PM and NB, respectively. This study provided very important genetic resources that are highly resistant to the Egyptian PM and NB pathotypes and revealed SNP markers that can be utilized to genetically improve resistance to PM and NB.",1,Net blotch (NB) and powdery mildew (PM) are major barley diseases with the potential to cause a dramatic loss in grain yield.
NG-SEM: an effective non-Gaussian structural equation modeling framework for gene regulatory network inference from single-cell RNA-seq data.,37864293,https://pubmed.ncbi.nlm.nih.gov/37864293/,https://doi.org/10.1093/bib/bbad369,"['gene expression', 'gene regulatory network', 'single cell']","Inference of gene regulatory network (GRN) from gene expression profiles has been a central problem in systems biology and bioinformatics in the past decades. The tremendous emergency of single-cell RNA sequencing (scRNA-seq) data brings new opportunities and challenges for GRN inference: the extensive dropouts and complicated noise structure may also degrade the performance of contemporary gene regulatory models. Thus, there is an urgent need to develop more accurate methods for gene regulatory network inference in single-cell data while considering the noise structure at the same time. In this paper, we extend the traditional structural equation modeling (SEM) framework by considering a flexible noise modeling strategy, namely we use the Gaussian mixtures to approximate the complex stochastic nature of a biological system, since the Gaussian mixture framework can be arguably served as a universal approximation for any continuous distributions. The proposed non-Gaussian SEM framework is called NG-SEM, which can be optimized by iteratively performing Expectation-Maximization algorithm and weighted least-squares method. Moreover, the Akaike Information Criteria is adopted to select the number of components of the Gaussian mixture. To probe the accuracy and stability of our proposed method, we design a comprehensive variate of control experiments to systematically investigate the performance of NG-SEM under various conditions, including simulations and real biological data sets. Results on synthetic data demonstrate that this strategy can improve the performance of traditional Gaussian SEM model and results on real biological data sets verify that NG-SEM outperforms other five state-of-the-art methods.",1,Inference of gene regulatory network (GRN) from gene expression profiles has been a central problem in systems biology and bioinformatics.
A Review of Machine Learning and Algorithmic Methods for Protein Phosphorylation Site Prediction.,37863385,https://pubmed.ncbi.nlm.nih.gov/37863385/,https://doi.org/10.1016/j.gpb.2023.03.007,"['Database', 'Deep learning', 'Machine learning', 'Phosphorylation', 'Post-translational modification']","Post-translational modifications (PTMs) have key roles in extending the functional diversity of proteins and, as a result, regulating diverse cellular processes in prokaryotic and eukaryotic organisms. Phosphorylation modification is a vital PTM that occurs in most proteins and plays a significant role in many biological processes. Disorders in the phosphorylation process lead to multiple diseases, including neurological disorders and cancers. The purpose of this review is to organize this body of knowledge associated with phosphorylation site (p-site) prediction to facilitate future research in this field. At first, we comprehensively review all related databases and introduce all steps regarding dataset creation, data preprocessing, and method evaluation in p-site prediction. Next, we investigate p-site prediction methods, which are divided into two computational groups: algorithmic and machine learning (ML). Additionally, it is shown that there are basically two main approaches for p-site prediction by ML: conventional and end-to-end deep learning methods, both of which are given an overview. Moreover, this review introduces the most important feature extraction techniques, which have mostly been used in p-site prediction. Finally, we create three test sets from new proteins related to the released version of the database of protein post-translational modifications (dbPTM) in 2022 based on general and human species. Evaluating online p-site prediction tools on newly added proteins introduced in the dbPTM 2022 release, distinct from those in the dbPTM 2019 release, reveals their limitations. In other words, the actual performance of these online p-site prediction tools on unseen proteins is notably lower than the results reported in their respective research papers.",2,Post-translational modifications (PTMs) have key roles in extending the functional diversity of proteins.
Evaluation of haplotype-aware long-read error correction with hifieval.,37851384,https://pubmed.ncbi.nlm.nih.gov/37851384/,https://doi.org/10.1093/bioinformatics/btad631,[],"The PacBio High-Fidelity (HiFi) sequencing technology produces long reads of >99% in accuracy. It has enabled the development of a new generation of de novo sequence assemblers, which all have sequencing error correction (EC) as the first step. As HiFi is a new data type, this critical step has not been evaluated before. Here, we introduced hifieval, a new command-line tool for measuring over- and under-corrections produced by EC algorithms. We assessed the accuracy of the EC components of existing HiFi assemblers on the CHM13 and the HG002 datasets and further investigated the performance of EC methods in challenging regions such as homopolymer regions, centromeric regions, and segmental duplications. Hifieval will help HiFi assemblers to improve EC and assembly quality in the long run.",1,The PacBio High-Fidelity (HiFi) sequencing technology produces long reads of >99% in accuracy.
Semla: a versatile toolkit for spatially resolved transcriptomics analysis and visualization.,37846051,https://pubmed.ncbi.nlm.nih.gov/37846051/,https://doi.org/10.1093/bioinformatics/btad626,[],"Spatially resolved transcriptomics technologies generate gene expression data with retained positional information from a tissue section, often accompanied by a corresponding histological image. Computational tools should make it effortless to incorporate spatial information into data analyses and present analysis results in their histological context. Here, we present semla, an R package for processing, analysis, and visualization of spatially resolved transcriptomics data generated by the Visium platform, that includes interactive web applications for data exploration and tissue annotation.",1,"Sla is an R package for processing, analysis, and visualization of spatially resolved transcriptomics data."
Comprehensive genomic analysis of ,37841331,https://pubmed.ncbi.nlm.nih.gov/37841331/,https://doi.org/10.1016/j.csbj.2023.09.043,"['Bacillus paralichenformis', 'Core genome', 'Evolution', 'HGT', 'Pan genome', 'Peptides', 'Plant_bacteria interactions', 'Secondary metabolites']",Many ,1,.
Searching similar local 3D micro-environments in protein structure databases with MicroMiner.,37833838,https://pubmed.ncbi.nlm.nih.gov/37833838/,https://doi.org/10.1093/bib/bbad357,"['micro-environment', 'mutation effect prediction', 'mutation modeling', 'protein site', 'protein structure']","The available protein structure data are rapidly increasing. Within these structures, numerous local structural sites depict the details characterizing structure and function. However, searching and analyzing these sites extensively and at scale poses a challenge. We present a new method to search local sites in protein structure databases using residue-defined local 3D micro-environments. We implemented the method in a new tool called MicroMiner and demonstrate the capabilities of residue micro-environment search on the example of structural mutation analysis. Usually, experimental structures for both the wild-type and the mutant are unavailable for comparison. With MicroMiner, we extracted $>255 \times 10^{6}$ amino acid pairs in protein structures from the PDB, exemplifying single mutations' local structural changes for single chains and $>45 \times 10^{6}$ pairs for protein-protein interfaces. We further annotate existing data sets of experimentally measured mutation effects, like $\Delta \Delta G$ measurements, with the extracted structure pairs to combine the mutation effect measurement with the structural change upon mutation. In addition, we show how MicroMiner can bridge the gap between mutation analysis and structure-based drug design tools. MicroMiner is available as a command line tool and interactively on the https://proteins.plus/ webserver.",1,MicroMiner is available as a command line tool and interactively on the https://proteins.plus/ webserver.
disperseNN2: a neural network for estimating dispersal distance from georeferenced polymorphism data.,37817115,https://pubmed.ncbi.nlm.nih.gov/37817115/,https://doi.org/10.1186/s12859-023-05522-7,"['Demographic inference', 'Dispersal', 'Geography', 'Machine learning', 'Population genetics', 'Spatial']","Spatial genetic variation is shaped in part by an organism's dispersal ability. We present a deep learning tool, disperseNN2, for estimating the mean per-generation dispersal distance from georeferenced polymorphism data. Our neural network performs feature extraction on pairs of genotypes, and uses the geographic information that comes with each sample. These attributes led disperseNN2 to outperform a state-of-the-art deep learning method that does not use explicit spatial information: the mean relative absolute error was reduced by 33% and 48% using sample sizes of 10 and 100 individuals, respectively. disperseNN2 is particularly useful for non-model organisms or systems with sparse genomic resources, as it uses unphased, single nucleotide polymorphisms as its input. The software is open source and available from https://github.com/kr-colab/disperseNN2 , with documentation located at https://dispersenn2.readthedocs.io/en/latest/ .",1,DisperseNN2 is a deep learning tool for estimating the mean per-generation dispersal distance from georeferenced polymorphism data.
"Tracking bacteria at high density with FAST, the Feature-Assisted Segmenter/Tracker.",37812642,https://pubmed.ncbi.nlm.nih.gov/37812642/,https://doi.org/10.1371/journal.pcbi.1011524,[],"Most bacteria live attached to surfaces in densely-packed communities. While new experimental and imaging techniques are beginning to provide a window on the complex processes that play out in these communities, resolving the behaviour of individual cells through time and space remains a major challenge. Although a number of different software solutions have been developed to track microorganisms, these typically require users either to tune a large number of parameters or to groundtruth a large volume of imaging data to train a deep learning model-both manual processes which can be very time consuming for novel experiments. To overcome these limitations, we have developed FAST, the Feature-Assisted Segmenter/Tracker, which uses unsupervised machine learning to optimise tracking while maintaining ease of use. Our approach, rooted in information theory, largely eliminates the need for users to iteratively adjust parameters manually and make qualitative assessments of the resulting cell trajectories. Instead, FAST measures multiple distinguishing 'features' for each cell and then autonomously quantifies the amount of unique information each feature provides. We then use these measurements to determine how data from different features should be combined to minimize tracking errors. Comparing our algorithm with a naïve approach that uses cell position alone revealed that FAST produced 4 to 10 fold fewer tracking errors. The modular design of FAST combines our novel tracking method with tools for segmentation, extensive data visualisation, lineage assignment, and manual track correction. It is also highly extensible, allowing users to extract custom information from images and seamlessly integrate it into downstream analyses. FAST therefore enables high-throughput, data-rich analyses with minimal user input. It has been released for use either in Matlab or as a compiled stand-alone application, and is available at https://bit.ly/3vovDHn, along with extensive tutorials and detailed documentation.",1,FAST measures multiple distinguishing 'features' for each cell and then autonomously quantifies the amount of unique information each feature provides.
ScaffoldGVAE: scaffold generation and hopping of drug molecules via a variational autoencoder based on multi-view graph neural networks.,37794460,https://pubmed.ncbi.nlm.nih.gov/37794460/,https://doi.org/10.1186/s13321-023-00766-0,"['Drug design', 'Molecule generation', 'Multi-view graph neural networks', 'Scaffold hopping', 'Variational autoencoder']","In recent years, drug design has been revolutionized by the application of deep learning techniques, and molecule generation is a crucial aspect of this transformation. However, most of the current deep learning approaches do not explicitly consider and apply scaffold hopping strategy when performing molecular generation. In this work, we propose ScaffoldGVAE, a variational autoencoder based on multi-view graph neural networks, for scaffold generation and scaffold hopping of drug molecules. The model integrates several important components, such as node-central and edge-central message passing, side-chain embedding, and Gaussian mixture distribution of scaffolds. To assess the efficacy of our model, we conduct a comprehensive evaluation and comparison with baseline models based on seven general generative model evaluation metrics and four scaffold hopping generative model evaluation metrics. The results demonstrate that ScaffoldGVAE can explore the unseen chemical space and generate novel molecules distinct from known compounds. Especially, the scaffold hopped molecules generated by our model are validated by the evaluation of GraphDTA, LeDock, and MM/GBSA. The case study of generating inhibitors of LRRK2 for the treatment of PD further demonstrates the effectiveness of ScaffoldGVAE in generating novel compounds through scaffold hopping. This novel approach can also be applied to other protein targets of various diseases, thereby contributing to the future development of new drugs. Source codes and data are available at https://github.com/ecust-hc/ScaffoldGVAE .",1,ScaffoldGVAE is a model based on multi-view graph neural networks.
E2EDA: Protein Domain Assembly Based on End-to-End Deep Learning.,37788318,https://pubmed.ncbi.nlm.nih.gov/37788318/,https://doi.org/10.1021/acs.jcim.3c01387,[],"With the development of deep learning, almost all single-domain proteins can be predicted at experimental resolution. However, the structure prediction of multi-domain proteins remains a challenge. Achieving end-to-end protein domain assembly and further improving the accuracy of the full-chain modeling by accurately predicting inter-domain orientation while improving the assembly efficiency will provide significant insights into structure-based drug discovery. In this work, we propose an End-to-End Domain Assembly method based on deep learning, named E2EDA. We first develop RMNet, an EfficientNetV2-based deep learning model that fuses multiple features using an attention mechanism to predict inter-domain rigid motion. Then, the predicted rigid motions are transformed into inter-domain spatial transformations to directly assemble the full-chain model. Finally, the scoring strategy RMscore is designed to select the best model from multiple assembled models. The experimental results show that the average TM-score of the model assembled by E2EDA on the benchmark set (282) is 0.827, which is better than those of other domain assembly methods SADA (0.792) and DEMO (0.730). Meanwhile, on our constructed multi-domain data set from AlphaFold DB, the model reassembled by E2EDA is 7.0% higher in TM-score compared to the full-chain model predicted by AlphaFold2, indicating that E2EDA can capture more accurate inter-domain orientations to improve the quality of the model predicted by AlphaFold2. Furthermore, compared to SADA and AlphaFold2, E2EDA reduced the average runtime on the benchmark by 64.7% and 19.2%, respectively, indicating that E2EDA can significantly improve assembly efficiency through an end-to-end approach. The online server is available at http://zhanglab-bioinf.com/E2EDA.",1,E2EDA is an End-to-End Domain Assembly method based on deep learning.
Surfaces: a software to quantify and visualize interactions within and between proteins and ligands.,37788107,https://pubmed.ncbi.nlm.nih.gov/37788107/,https://doi.org/10.1093/bioinformatics/btad608,[],"Computational methods for the quantification and visualization of the relative contribution of molecular interactions to the stability of biomolecular structures and complexes are fundamental to understand, modulate and engineer biological processes. Here, we present Surfaces, an easy to use, fast and customizable software for quantification and visualization of molecular interactions based on the calculation of surface areas in contact. Surfaces calculations shows equivalent or better correlations with experimental data as computationally expensive methods based on molecular dynamics.",1,"Surfaces is an easy to use, fast and customizable software for quantification and visualization of molecular interactions based on the calculation of surface areas in contact."
Fair and equitable AI in biomedical research and healthcare: Social science perspectives.,37783540,https://pubmed.ncbi.nlm.nih.gov/37783540/,https://doi.org/10.1016/j.artmed.2023.102658,"['Bias', 'Discrimination', 'Health equity', 'Inequalities', 'Medicine']","Artificial intelligence (AI) offers opportunities but also challenges for biomedical research and healthcare. This position paper shares the results of the international conference ""Fair medicine and AI"" (online 3-5 March 2021). Scholars from science and technology studies (STS), gender studies, and ethics of science and technology formulated opportunities, challenges, and research and development desiderata for AI in healthcare. AI systems and solutions, which are being rapidly developed and applied, may have undesirable and unintended consequences including the risk of perpetuating health inequalities for marginalized groups. Socially robust development and implications of AI in healthcare require urgent investigation. There is a particular dearth of studies in human-AI interaction and how this may best be configured to dependably deliver safe, effective and equitable healthcare. To address these challenges, we need to establish diverse and interdisciplinary teams equipped to develop and apply medical AI in a fair, accountable and transparent manner. We formulate the importance of including social science perspectives in the development of intersectionally beneficent and equitable AI for biomedical research and healthcare, in part by strengthening AI health evaluation.",1,Socially robust development and implications of AI in healthcare require urgent investigation.
YASARA Model-Interactive Molecular Modeling from Two Dimensions to Virtual Realities.,37782001,https://pubmed.ncbi.nlm.nih.gov/37782001/,https://doi.org/10.1021/acs.jcim.3c01136,[],"The industry's transition from three-dimensional (3D) glasses to virtual reality (VR) headsets has left modelers stranded without hardware supply, since walking around and waving arms in a virtual world is a great experience but also very tiring when doing time-intensive modeling work. We present a novel software implementation that uses a VR headset while sitting at a desk in front of the normal screen, which is beamed into the virtual reality together with keyboard, mouse, and chair using the headset's cameras and an extra tracker attached to the seat-back. Compared to 3D glasses, this yields a comparably relaxing but much more immersive workplace and provides additional possibilities such as taking molecules into one's hands, standing up, and walking or teleporting through the models. This VR functionality has been combined with a molecular graphics engine based on Vulkan, a next-generation cross-platform application programming interface (API) for GPUs and the successor of the widely used Open Graphics Library (OpenGL). It is built into the YASARA Model program, which includes many features like small and large molecule builders, electron densities, partial surfaces, contact analysis, coordinate manipulation, and animations. Interactive tutorials are provided to guide modelers into VR and familiarize them with the molecular modeling features. YASARA Model is available for Linux, Windows, Android, and MacOS (the latter without VR) with an introductory video at www.YASARA.org/vr.",2,The industry's transition from three-dimensional (3D) glasses to virtual reality (VR) headsets has left modelers stranded without hardware supply.
MMiKG: a knowledge graph-based platform for path mining of microbiota-mental diseases interactions.,37779250,https://pubmed.ncbi.nlm.nih.gov/37779250/,https://doi.org/10.1093/bib/bbad340,"['MGB axis', 'gut microbiota', 'intermediate', 'knowledge graph', 'mental disease']","The microbiota-gut-brain axis denotes a two-way system of interactions between the gut and the brain, comprising three key components: (1) gut microbiota, (2) intermediates and (3) mental ailments. These constituents communicate with one another to induce changes in the host's mood, cognition and demeanor. Knowledge concerning the regulation of the host central nervous system by gut microbiota is fragmented and mostly confined to disorganized or semi-structured unrestricted texts. Such a format hinders the exploration and comprehension of unknown territories or the further advancement of artificial intelligence systems. Hence, we collated crucial information by scrutinizing an extensive body of literature, amalgamated the extant knowledge of the microbiota-gut-brain axis and depicted it in the form of a knowledge graph named MMiKG, which can be visualized on the GraphXR platform and the Neo4j database, correspondingly. By merging various associated resources and deducing prospective connections between gut microbiota and the central nervous system through MMiKG, users can acquire a more comprehensive perception of the pathogenesis of mental disorders and generate novel insights for advancing therapeutic measures. As a free and open-source platform, MMiKG can be accessed at http://yangbiolab.cn:8501/ with no login requirement.",1,The microbiota-gut-brain axis denotes a two-way system of interactions between the gut and the brain.
Ten quick tips for building FAIR workflows.,37768885,https://pubmed.ncbi.nlm.nih.gov/37768885/,https://doi.org/10.1371/journal.pcbi.1011369,[],"Research data is accumulating rapidly and with it the challenge of fully reproducible science. As a consequence, implementation of high-quality management of scientific data has become a global priority. The FAIR (Findable, Accesible, Interoperable and Reusable) principles provide practical guidelines for maximizing the value of research data; however, processing data using workflows-systematic executions of a series of computational tools-is equally important for good data management. The FAIR principles have recently been adapted to Research Software (FAIR4RS Principles) to promote the reproducibility and reusability of any type of research software. Here, we propose a set of 10 quick tips, drafted by experienced workflow developers that will help researchers to apply FAIR4RS principles to workflows. The tips have been arranged according to the FAIR acronym, clarifying the purpose of each tip with respect to the FAIR4RS principles. Altogether, these tips can be seen as practical guidelines for workflow developers who aim to contribute to more reproducible and sustainable computational science, aiming to positively impact the open science and FAIR community.",1,"FAIR (Findable, Accesible, Interoperable and Reusable) principles provide practical guidelines for maximizing the value of research data."
Multimodal analysis and the oncology patient: Creating a hospital system for integrated diagnostics and discovery.,37767106,https://pubmed.ncbi.nlm.nih.gov/37767106/,https://doi.org/10.1016/j.csbj.2023.09.014,"['Artificial Intelligence', 'Computational Oncology', 'Digital Pathology', 'Health data', 'Integrated Diagnostics and Discovery', 'Multimodal Analysis', 'Radiomics']","We propose that an information technology and computational framework that would unify access to hospital digital information silos, and enable integration of this information using machine learning methods, would bring a new paradigm to patient management and research. This is the core principle of Integrated Diagnostics (ID): ",1,"An information technology and computational framework that would unify access to hospital digital information silos, and enable integration of this information using machine learning methods, would bring a new paradigm to patient management"
Designing and development of multi-epitope chimeric vaccine against Helicobacter pylori by exploring its entire immunogenic epitopes: an immunoinformatic approach.,37740175,https://pubmed.ncbi.nlm.nih.gov/37740175/,https://doi.org/10.1186/s12859-023-05454-2,"['Helicobacter pylori', 'Immunoinformatics', 'Infection', 'Multi-epitopes', 'Vaccine']","Helicobacter pylori is a prominent causative agent of gastric ulceration, gastric adenocarcinoma and gastric lymphoma and have been categorised as a group 1 carcinogen by WHO. The treatment of H. pylori with proton pump inhibitors and antibiotics is effective but also leads to increased antibiotic resistance, patient dissatisfaction, and chances of reinfection. Therefore, an effective vaccine remains the most suitable prophylactic option for mass administration against this infection.",1,"Helicobacter pylori is a prominent causative agent of gastric ulceration, gastric adenocarcinoma and gastric lymphoma."
PLPCA: Persistent Laplacian-Enhanced PCA for Microarray Data Analysis.,37738663,https://pubmed.ncbi.nlm.nih.gov/37738663/,https://doi.org/10.1021/acs.jcim.3c01023,[],"Over the years, Principal Component Analysis (PCA) has served as the baseline approach for dimensionality reduction in gene expression data analysis. Its primary objective is to identify a subset of disease-causing genes from a vast pool of thousands of genes. However, PCA possesses inherent limitations that hinder its interpretability, introduce class ambiguity, and fail to capture complex geometric structures in the data. Although these limitations have been partially addressed in the literature by incorporating various regularizers, such as graph Laplacian regularization, existing PCA based methods still face challenges related to multiscale analysis and capturing higher-order interactions in the data. To address these challenges, we propose a novel approach called Persistent Laplacian-enhanced Principal Component Analysis (PLPCA). PLPCA amalgamates the advantages of earlier regularized PCA methods with persistent spectral graph theory, specifically persistent Laplacians derived from algebraic topology. In contrast to graph Laplacians, persistent Laplacians enable multiscale analysis through filtration and can incorporate higher-order simplicial complexes to capture higher-order interactions in the data. We evaluate and validate the performance of PLPCA using ten benchmark microarray data sets that exhibit a wide range of dimensions and data imbalance ratios. Our extensive studies over these data sets demonstrate that PLPCA provides up to 12% improvement to the current state-of-the-art PCA models on five evaluation metrics for classification tasks after dimensionality reduction.",4,Principal Component Analysis (PCA) has served as the baseline approach for dimensionality reduction in gene expression data analysis.
Automatic segmentation of large-scale CT image datasets for detailed body composition analysis.,37723444,https://pubmed.ncbi.nlm.nih.gov/37723444/,https://doi.org/10.1186/s12859-023-05462-2,"['Body composition', 'Computed tomography', 'Deep learning', 'Medical imaging', 'Segmentation']","Body composition (BC) is an important factor in determining the risk of type 2-diabetes and cardiovascular disease. Computed tomography (CT) is a useful imaging technique for studying BC, however manual segmentation of CT images is time-consuming and subjective. The purpose of this study is to develop and evaluate fully automated segmentation techniques applicable to a 3-slice CT imaging protocol, consisting of single slices at the level of the liver, abdomen, and thigh, allowing detailed analysis of numerous tissues and organs.",1,Body composition (BC) is an important factor in determining the risk of type 2-diabetes and cardiovascular disease.
DeepCAC: a deep learning approach on DNA transcription factors classification based on multi-head self-attention and concatenate convolutional neural network.,37723425,https://pubmed.ncbi.nlm.nih.gov/37723425/,https://doi.org/10.1186/s12859-023-05469-9,"['Attention mechanism', 'Bioinformatics', 'Convolutional neural networks', 'DNA transcription factors sequence']","Understanding gene expression processes necessitates the accurate classification and identification of transcription factors, which is supported by high-throughput sequencing technologies. However, these techniques suffer from inherent limitations such as time consumption and high costs. To address these challenges, the field of bioinformatics has increasingly turned to deep learning technologies for analyzing gene sequences. Nevertheless, the pursuit of improved experimental results has led to the inclusion of numerous complex analysis function modules, resulting in models with a growing number of parameters. To overcome these limitations, it is proposed a novel approach for analyzing DNA transcription factor sequences, which is named as DeepCAC. This method leverages deep convolutional neural networks with a multi-head self-attention mechanism. By employing convolutional neural networks, it can effectively capture local hidden features in the sequences. Simultaneously, the multi-head self-attention mechanism enhances the identification of hidden features with long-distant dependencies. This approach reduces the overall number of parameters in the model while harnessing the computational power of sequence data from multi-head self-attention. Through training with labeled data, experiments demonstrate that this approach significantly improves performance while requiring fewer parameters compared to existing methods. Additionally, the effectiveness of our approach  is validated in accurately predicting DNA transcription factor sequences.",1,DeepCAC is a novel approach for analyzing DNA transcription factor sequences. It leverages deep convolutional neural networks with a multi-head self-attention mechanism.
MAVEN: compound mechanism of action analysis and visualisation using transcriptomics and compound structure data in R/Shiny.,37715141,https://pubmed.ncbi.nlm.nih.gov/37715141/,https://doi.org/10.1186/s12859-023-05416-8,"['Causal reasoning', 'Mechanism of action', 'Shiny', 'Systems biology', 'Transcriptomics']","Understanding the Mechanism of Action (MoA) of a compound is an often challenging but equally crucial aspect of drug discovery that can help improve both its efficacy and safety. Computational methods to aid MoA elucidation usually either aim to predict direct drug targets, or attempt to understand modulated downstream pathways or signalling proteins. Such methods usually require extensive coding experience and results are often optimised for further computational processing, making them difficult for wet-lab scientists to perform, interpret and draw hypotheses from.",1," Computational methods to aid MoA elucidation usually either aim to predict direct drug targets, or attempt to understand modulated downstream pathways or signalling proteins."
Mixtures of strategies underlie rodent behavior during reversal learning.,37708113,https://pubmed.ncbi.nlm.nih.gov/37708113/,https://doi.org/10.1371/journal.pcbi.1011430,[],"In reversal learning tasks, the behavior of humans and animals is often assumed to be uniform within single experimental sessions to facilitate data analysis and model fitting. However, behavior of agents can display substantial variability in single experimental sessions, as they execute different blocks of trials with different transition dynamics. Here, we observed that in a deterministic reversal learning task, mice display noisy and sub-optimal choice transitions even at the expert stages of learning. We investigated two sources of the sub-optimality in the behavior. First, we found that mice exhibit a high lapse rate during task execution, as they reverted to unrewarded directions after choice transitions. Second, we unexpectedly found that a majority of mice did not execute a uniform strategy, but rather mixed between several behavioral modes with different transition dynamics. We quantified the use of such mixtures with a state-space model, block Hidden Markov Model (block HMM), to dissociate the mixtures of dynamic choice transitions in individual blocks of trials. Additionally, we found that blockHMM transition modes in rodent behavior can be accounted for by two different types of behavioral algorithms, model-free or inference-based learning, that might be used to solve the task. Combining these approaches, we found that mice used a mixture of both exploratory, model-free strategies and deterministic, inference-based behavior in the task, explaining their overall noisy choice sequences. Together, our combined computational approach highlights intrinsic sources of noise in rodent reversal learning behavior and provides a richer description of behavior than conventional techniques, while uncovering the hidden states that underlie the block-by-block transitions.",3,"In a reversal learning task, mice display noisy and sub-optimal choice transitions even at the expert stages of learning."
Mining the nanotube-forming ,37701018,https://pubmed.ncbi.nlm.nih.gov/37701018/,https://doi.org/10.1016/j.csbj.2023.08.031,"['Antifungal activity', 'Bacillus', 'Biofactory', 'Biosynthesis-related gene clusters', 'Candida albicans', 'Candida auris', 'Comparative genomics', 'Cytotoxicity', 'Genome mining']",There is a global health concern associated with the emergence of the multidrug-resistant (MDR) fungus ,1,There is a global health concern associated with the emergence of the multidrug-resistant (MDR) fungus.
Identification of the H3K36me3 reader LEDGF/p75 in the pancancer landscape and functional exploration in clear cell renal cell carcinoma.,37675289,https://pubmed.ncbi.nlm.nih.gov/37675289/,https://doi.org/10.1016/j.csbj.2023.08.023,"['Clear cell renal cell carcinoma', 'H3K36me3', 'LEDGF/p75', 'Pancancer', 'SETD2']","Lens epithelium-derived growth factor (LEDGF/p75) is a reader of epigenetic marks and a potential target for therapeutic intervention. Its involvement in human immunodeficiency virus (HIV) integration and the development of leukemia driven by MLL (also known as KMT2A) gene fusion make it an attractive candidate for drug development. However, exploration of LEDGF/p75 as an epigenetic reader of H3K36me3 in tumors is limited. Here, for the first time, we analyze the role of LEDGF/p75 in multiple cancers via multiple online databases and in vitro experiments. We used pancancer bulk sequencing data and online tools to analyze correlations of LEDGF/p75 with prognosis, genomic instability, DNA damage repair, prognostic alternative splicing, protein interactions, and tumor immunity. In summary, the present study identified that LEDGF/p75 may serve as a prognostic predictor for tumors such as adrenocortical carcinoma, kidney chromophobe, liver hepatocellular carcinoma, pancreatic adenocarcinoma, skin cutaneous melanoma, and clear cell renal cell carcinoma (ccRCC). In addition, in vitro experiments and gene microarray sequencing were performed to explore the function of LEDGF/p75 in ccRCC, providing new insights into the pathogenesis of the nonmutated SETD2 ccRCC subtype.",1,Lens epithelium-derived growth factor (LEDGF/p75) is a reader of epigenetic marks and a potential target for therapeutic intervention.
Artificial Intelligence framework with traditional computer vision and deep learning approaches for optimal automatic segmentation of left ventricle with scar.,37673578,https://pubmed.ncbi.nlm.nih.gov/37673578/,https://doi.org/10.1016/j.artmed.2023.102610,"['Automatic segmentation', 'Cardiac segmentation', 'Deep learning', 'Left ventricle', 'Machine learning', 'Scars', 'U-net', 'Unsupervised']","Automatic segmentation of the cardiac left ventricle with scars remains a challenging and clinically significant task, as it is essential for patient diagnosis and treatment pathways. This study aimed to develop a novel framework and cost function to achieve optimal automatic segmentation of the left ventricle with scars using LGE-MRI images. To ensure the generalization of the framework, an unbiased validation protocol was established using out-of-distribution (OOD) internal and external validation cohorts, and intra-observation and inter-observer variability ground truths. The framework employs a combination of traditional computer vision techniques and deep learning, to achieve optimal segmentation results. The traditional approach uses multi-atlas techniques, active contours, and k-means methods, while the deep learning approach utilizes various deep learning techniques and networks. The study found that the traditional computer vision technique delivered more accurate results than deep learning, except in cases where there was breath misalignment error. The optimal solution of the framework achieved robust and generalized results with Dice scores of 82.8 ± 6.4% and 72.1 ± 4.6% in the internal and external OOD cohorts, respectively. The developed framework offers a high-performance solution for automatic segmentation of the left ventricle with scars using LGE-MRI. Unlike existing state-of-the-art approaches, it achieves unbiased results across different hospitals and vendors without the need for training or tuning in hospital cohorts. This framework offers a valuable tool for experts to accomplish the task of fully automatic segmentation of the left ventricle with scars based on a single-modality cardiac scan.",1,Automatic segmentation of the cardiac left ventricle with scars remains a challenging and clinically significant task.
MLNAN: Multi-level noise-aware network for low-dose CT imaging implemented with constrained cycle Wasserstein generative adversarial networks.,37673577,https://pubmed.ncbi.nlm.nih.gov/37673577/,https://doi.org/10.1016/j.artmed.2023.102609,"['Constrained cycle GANs', 'Low-dose CT imaging', 'Multi-level noise-aware network', 'Noise normalization', 'Noise-level estimation']","Low-dose CT techniques attempt to minimize the radiation exposure of patients by estimating the high-resolution normal-dose CT images to reduce the risk of radiation-induced cancer. In recent years, many deep learning methods have been proposed to solve this problem by building a mapping function between low-dose CT images and their high-dose counterparts. However, most of these methods ignore the effect of different radiation doses on the final CT images, which results in large differences in the intensity of the noise observable in CT images. What'more, the noise intensity of low-dose CT images exists significantly differences under different medical devices manufacturers. In this paper, we propose a multi-level noise-aware network (MLNAN) implemented with constrained cycle Wasserstein generative adversarial networks to recovery the low-dose CT images under uncertain noise levels. Particularly, the noise-level classification is predicted and reused as a prior pattern in generator networks. Moreover, the discriminator network introduces noise-level determination. Under two dose-reduction strategies, experiments to evaluate the performance of proposed method are conducted on two datasets, including the simulated clinical AAPM challenge datasets and commercial CT datasets from United Imaging Healthcare (UIH). The experimental results illustrate the effectiveness of our proposed method in terms of noise suppression and structural detail preservation compared with several other deep-learning based methods. Ablation studies validate the effectiveness of the individual components regarding the afforded performance improvement. Further research for practical clinical applications and other medical modalities is required in future works.",1,Low-dose CT techniques attempt to minimize the radiation exposure of patients by estimating the high-resolution normal- dose CT images to reduce the risk of radiation-induced cancer.
FDA-approved machine learning algorithms in neuroradiology: A systematic review of the current evidence for approval.,37673576,https://pubmed.ncbi.nlm.nih.gov/37673576/,https://doi.org/10.1016/j.artmed.2023.102607,"['AI', 'FDA approval', 'Machine learning', 'Neuroalgorithms', 'Neuroradiology']","Over the past decade, machine learning (ML) and artificial intelligence (AI) have become increasingly prevalent in the medical field. In the United States, the Food and Drug Administration (FDA) is responsible for regulating AI algorithms as ""medical devices"" to ensure patient safety. However, recent work has shown that the FDA approval process may be deficient. In this study, we evaluate the evidence supporting FDA-approved neuroalgorithms, the subset of machine learning algorithms with applications in the central nervous system (CNS), through a systematic review of the primary literature. Articles covering the 53 FDA-approved algorithms with applications in the CNS published in PubMed, EMBASE, Google Scholar and Scopus between database inception and January 25, 2022 were queried. Initial searches identified 1505 studies, of which 92 articles met the criteria for extraction and inclusion. Studies were identified for 26 of the 53 neuroalgorithms, of which 10 algorithms had only a single peer-reviewed publication. Performance metrics were available for 15 algorithms, external validation studies were available for 24 algorithms, and studies exploring the use of algorithms in clinical practice were available for 7 algorithms. Papers studying the clinical utility of these algorithms focused on three domains: workflow efficiency, cost savings, and clinical outcomes. Our analysis suggests that there is a meaningful gap between the FDA approval of machine learning algorithms and their clinical utilization. There appears to be room for process improvement by implementation of the following recommendations: the provision of compelling evidence that algorithms perform as intended, mandating minimum sample sizes, reporting of a predefined set of performance metrics for all algorithms and clinical application of algorithms prior to widespread use. This work will serve as a baseline for future research into the ideal regulatory framework for AI applications worldwide.",1,"In the past decade, machine learning and artificial intelligence have become increasingly prevalent in the medical field."
Review on deep learning fetal brain segmentation from Magnetic Resonance images.,37673558,https://pubmed.ncbi.nlm.nih.gov/37673558/,https://doi.org/10.1016/j.artmed.2023.102608,"['Brain extraction', 'Deep learning', 'Fetal brain', 'Magnetic resonance imaging', 'Tissue segmentation']","Brain segmentation is often the first and most critical step in quantitative analysis of the brain for many clinical applications, including fetal imaging. Different aspects challenge the segmentation of the fetal brain in magnetic resonance imaging (MRI), such as the non-standard position of the fetus owing to his/her movements during the examination, rapid brain development, and the limited availability of imaging data. In recent years, several segmentation methods have been proposed for automatically partitioning the fetal brain from MR images. These algorithms aim to define regions of interest with different shapes and intensities, encompassing the entire brain, or isolating specific structures. Deep learning techniques, particularly convolutional neural networks (CNNs), have become a state-of-the-art approach in the field because they can provide reliable segmentation results over heterogeneous datasets. Here, we review the deep learning algorithms developed in the field of fetal brain segmentation and categorize them according to their target structures. Finally, we discuss the perceived research gaps in the literature of the fetal domain, suggesting possible future research directions that could impact the management of fetal MR images.",1,"Brain segmentation is often the first and most critical step in quantitative analysis of the brain for many clinical applications, including fetal imaging."
Identifying potential small molecule-miRNA associations via Robust PCA based on γ-norm regularization.,37670501,https://pubmed.ncbi.nlm.nih.gov/37670501/,https://doi.org/10.1093/bib/bbad312,"['association prediction', 'augmented lagrange multiplier method', 'microRNA', 'robust principal component analysis', 'small molecule']","Dysregulation of microRNAs (miRNAs) is closely associated with refractory human diseases, and the identification of potential associations between small molecule (SM) drugs and miRNAs can provide valuable insights for clinical treatment. Existing computational techniques for inferring potential associations suffer from limitations in terms of accuracy and efficiency. To address these challenges, we devise a novel predictive model called RPCA$\Gamma $NR, in which we propose a new Robust principal component analysis (PCA) framework based on $\gamma $-norm and $l_{2,1}$-norm regularization and design an Augmented Lagrange Multiplier method to optimize it, thereby deriving the association scores. The Gaussian Interaction Profile Kernel Similarity is calculated to capture the similarity information of SMs and miRNAs in known associations. Through extensive evaluation, including Cross Validation Experiments, Independent Validation Experiment, Efficiency Analysis, Ablation Experiment, Matrix Sparsity Analysis, and Case Studies, RPCA$\Gamma $NR outperforms state-of-the-art models concerning accuracy, efficiency and robustness. In conclusion, RPCA$\Gamma $NR can significantly streamline the process of determining SM-miRNA associations, thus contributing to advancements in drug development and disease treatment.",1,Dysregulation of microRNAs (miRNAs) is closely associated with refractory human diseases.
3D based generative PROTAC linker design with reinforcement learning.,37670499,https://pubmed.ncbi.nlm.nih.gov/37670499/,https://doi.org/10.1093/bib/bbad323,"['PROTAC linker design', 'generative model', 'reinforcement learning']","Proteolysis targeting chimera (PROTAC), has emerged as an effective modality to selectively degrade disease-related proteins by harnessing the ubiquitin-proteasome system. Due to PROTACs' hetero-bifunctional characteristics, in which a linker joins a warhead binding to a protein of interest (POI), conferring specificity and a E3-ligand binding to an E3 ubiquitin ligase, this could trigger the ubiquitination and transportation of POI to the proteasome, followed by degradation. The rational PROTAC linker design is challenging due to its relatively large molecular weight and the complexity of maintaining the binding mode of warhead and E3-ligand in the binding pockets of counterpart. Conventional linker generation method can only generate linkers in either 1D SMILES or 2D graph, without taking into account the information of ternary structures. Here we propose a novel 3D linker generative model PROTAC-INVENT which can not only generate SMILES of PROTAC but also its 3D putative binding conformation coupled with the target protein and the E3 ligase. The model is trained jointly with the RL approach to bias the generation of PROTAC structures toward pre-defined 2D and 3D based properties. Examples were provided to demonstrate the utility of the model for generating reasonable 3D conformation of PROTACs. On the other hand, our results show that the associated workflow for 3D PROTAC conformation generation can also be used as an efficient docking protocol for PROTACs.",1,Proteolysis targeting chimera (PROTAC) has emerged as an effective modality to selectively degrade disease-related proteins.
Empirical methods for the validation of time-to-event mathematical models taking into account uncertainty and variability: application to EGFR + lung adenocarcinoma.,37667175,https://pubmed.ncbi.nlm.nih.gov/37667175/,https://doi.org/10.1186/s12859-023-05430-w,"['Bootstrap', 'Confidence interval', 'Coverage', 'EGFR\u2009+\u2009lung adenocarcinoma', 'Empirical', 'Joncture', 'Knowledge based model', 'Log-rank', 'Mechanistic model', 'Prediction interval', 'Validation']","Over the past several decades, metrics have been defined to assess the quality of various types of models and to compare their performance depending on their capacity to explain the variance found in real-life data. However, available validation methods are mostly designed for statistical regressions rather than for mechanistic models. To our knowledge, in the latter case, there are no consensus standards, for instance for the validation of predictions against real-world data given the variability and uncertainty of the data. In this work, we focus on the prediction of time-to-event curves using as an application example a mechanistic model of non-small cell lung cancer. We designed four empirical methods to assess both model performance and reliability of predictions: two methods based on bootstrapped versions of parametric statistical tests: log-rank and combined weighted log-ranks (MaxCombo); and two methods based on bootstrapped prediction intervals, referred to here as raw coverage and the juncture metric. We also introduced the notion of observation time uncertainty to take into consideration the real life delay between the moment when an event happens, and the moment when it is observed and reported.",2,There are no consensus standards for the validation of predictions against real-world data given the variability and uncertainty of the data.
Comprehensive Characterization and Global Transcriptome Analysis of Human Fetal Liver Terminal Erythropoiesis.,37657739,https://pubmed.ncbi.nlm.nih.gov/37657739/,https://doi.org/10.1016/j.gpb.2023.07.001,"['Enucleation', 'Human fetal liver', 'Immortalized erythroid cell line', 'Terminal erythropoiesis', 'Transcriptome']","The fetal liver (FL) is the key erythropoietic organ during fetal development, but knowledge on human FL erythropoiesis is very limited. In this study, we sorted primary erythroblasts from FL cells and performed RNA sequencing (RNA-seq) analyses. We found that temporal gene expression patterns reflected changes in function during primary human FL terminal erythropoiesis. Notably, the expression of genes enriched in proteolysis and autophagy was up-regulated in orthochromatic erythroblasts (OrthoEs), suggesting the involvement of these pathways in enucleation. We also performed RNA-seq of in vitro cultured erythroblasts derived from FL CD34",1,The fetal liver (FL) is the key erythropoietic organ during fetal development.
Mining electronic health records using artificial intelligence: Bibliometric and content analyses for current research status and product conversion.,37657713,https://pubmed.ncbi.nlm.nih.gov/37657713/,https://doi.org/10.1016/j.jbi.2023.104480,"['Achievement conversion', 'Artificial intelligence', 'EHRs', 'Information mining', 'Resource conversion rate']","The use of Electronic Health Records is the most important milestone in the digitization and intelligence of the entire medical industry. AI can effectively mine the immense medical information contained in EHRs, potentially assist doctors in reducing many medical errors.",1,The use of Electronic Health Records is the most important milestone in the digitization and intelligence of the entire medical industry.
Multimodal deep learning approaches for single-cell multi-omics data integration.,37651607,https://pubmed.ncbi.nlm.nih.gov/37651607/,https://doi.org/10.1093/bib/bbad313,"['data integration', 'deep learning', 'multi-omics', 'single-cell']","Integrating single-cell multi-omics data is a challenging task that has led to new insights into complex cellular systems. Various computational methods have been proposed to effectively integrate these rapidly accumulating datasets, including deep learning. However, despite the proven success of deep learning in integrating multi-omics data and its better performance over classical computational methods, there has been no systematic study of its application to single-cell multi-omics data integration. To fill this gap, we conducted a literature review to explore the use of multimodal deep learning techniques in single-cell multi-omics data integration, taking into account recent studies from multiple perspectives. Specifically, we first summarized different modalities found in single-cell multi-omics data. We then reviewed current deep learning techniques for processing multimodal data and categorized deep learning-based integration methods for single-cell multi-omics data according to data modality, deep learning architecture, fusion strategy, key tasks and downstream analysis. Finally, we provided insights into using these deep learning models to integrate multi-omics data and better understand single-cell biological mechanisms.",1, Integrating single-cell multi-omics data is a challenging task that has led to new insights into complex cellular systems.
Sequence pre-training-based graph neural network for predicting lncRNA-miRNA associations.,37651605,https://pubmed.ncbi.nlm.nih.gov/37651605/,https://doi.org/10.1093/bib/bbad317,"['ceRNA', 'graph neural network', 'lncRNA', 'miRNA', 'pre-train']","MicroRNAs (miRNAs) silence genes by binding to messenger RNAs, whereas long non-coding RNAs (lncRNAs) act as competitive endogenous RNAs (ceRNAs) that can relieve miRNA silencing effects and upregulate target gene expression. The ceRNA association between lncRNAs and miRNAs has been a research hotspot due to its medical importance, but it is challenging to verify experimentally. In this paper, we propose a novel deep learning scheme, i.e. sequence pre-training-based graph neural network (SPGNN), that combines pre-training and fine-tuning stages to predict lncRNA-miRNA associations from RNA sequences and the existing interactions represented as a graph. First, we utilize a sequence-to-vector technique to generate pre-trained embeddings based on the sequences of all RNAs during the pre-training stage. In the fine-tuning stage, we use Graph Neural Network to learn node representations from the heterogeneous graph constructed using lncRNA-miRNA association information. We evaluate our proposed scheme SPGNN on our newly collected animal lncRNA-miRNA association dataset and demonstrate that combining the $k$-mer technique and Doc2vec model for pre-training with the Simple Graph Convolution Network for fine-tuning is effective in predicting lncRNA-miRNA associations. Our approach outperforms state-of-the-art baselines across various evaluation metrics. We also conduct an ablation study and hyperparameter analysis to verify the effectiveness of each component and parameter of our scheme. The complete code and dataset are available on GitHub: https://github.com/zixwang/SPGNN.",1,MicroRNAs silence genes by binding to messenger RNAs.
Tracking and curating putative SARS-CoV-2 recombinants with RIVET.,37651464,https://pubmed.ncbi.nlm.nih.gov/37651464/,https://doi.org/10.1093/bioinformatics/btad538,[],"Identifying and tracking recombinant strains of SARS-CoV-2 is critical to understanding the evolution of the virus and controlling its spread. But confidently identifying SARS-CoV-2 recombinants from thousands of new genome sequences that are being shared online every day is quite challenging, causing many recombinants to be missed or suffer from weeks of delay in being formally identified while undergoing expert curation.",2,Identifying and tracking recombinant strains of SARS-CoV-2 is critical to understanding the evolution of the virus and controlling its spread.
StepAdd: A personalized mHealth intervention based on social cognitive theory to increase physical activity among type 2 diabetes patients.,37648101,https://pubmed.ncbi.nlm.nih.gov/37648101/,https://doi.org/10.1016/j.jbi.2023.104481,"['Diabetes', 'Intervention personalization', 'Mobile health', 'Physical activity', 'Self-management', 'Social cognitive theory']","Investigate the preliminary efficacy and feasibility of a personalized mobile health (mHealth) intervention based on social cognitive theory (SCT) to promote physical activity among type 2 diabetes patients via self-monitoring, goal setting, and automatic feedback.",2,"A mobile health intervention based on social cognitive theory could promote physical activity among type 2 diabetes patients via self-monitoring, goal setting, and automatic feedback."
"HAPNEST: efficient, large-scale generation and evaluation of synthetic datasets for genotypes and phenotypes.",37647640,https://pubmed.ncbi.nlm.nih.gov/37647640/,https://doi.org/10.1093/bioinformatics/btad535,[],"Existing methods for simulating synthetic genotype and phenotype datasets have limited scalability, constraining their usability for large-scale analyses. Moreover, a systematic approach for evaluating synthetic data quality and a benchmark synthetic dataset for developing and evaluating methods for polygenic risk scores are lacking.",3,"Existing methods for simulating synthetic genotype and phenotype datasets have limited scalability, constraining their usability for large-scale analyses."
Scoring epidemiological forecasts on transformed scales.,37643178,https://pubmed.ncbi.nlm.nih.gov/37643178/,https://doi.org/10.1371/journal.pcbi.1011393,[],"Forecast evaluation is essential for the development of predictive epidemic models and can inform their use for public health decision-making. Common scores to evaluate epidemiological forecasts are the Continuous Ranked Probability Score (CRPS) and the Weighted Interval Score (WIS), which can be seen as measures of the absolute distance between the forecast distribution and the observation. However, applying these scores directly to predicted and observed incidence counts may not be the most appropriate due to the exponential nature of epidemic processes and the varying magnitudes of observed values across space and time. In this paper, we argue that transforming counts before applying scores such as the CRPS or WIS can effectively mitigate these difficulties and yield epidemiologically meaningful and easily interpretable results. Using the CRPS on log-transformed values as an example, we list three attractive properties: Firstly, it can be interpreted as a probabilistic version of a relative error. Secondly, it reflects how well models predicted the time-varying epidemic growth rate. And lastly, using arguments on variance-stabilizing transformations, it can be shown that under the assumption of a quadratic mean-variance relationship, the logarithmic transformation leads to expected CRPS values which are independent of the order of magnitude of the predicted quantity. Applying a transformation of log(x + 1) to data and forecasts from the European COVID-19 Forecast Hub, we find that it changes model rankings regardless of stratification by forecast date, location or target types. Situations in which models missed the beginning of upward swings are more strongly emphasised while failing to predict a downturn following a peak is less severely penalised when scoring transformed forecasts as opposed to untransformed ones. We conclude that appropriate transformations, of which the natural logarithm is only one particularly attractive option, should be considered when assessing the performance of different models in the context of infectious disease incidence.",2,"Common scores to evaluate epidemiological forecasts are the Continuous Ranked Probability Score (CRPS) and the Weighted Interval Score (WIS) However, applying these scores directly to predicted"
Large-scale assessment of pros and cons of autopsy-derived or tumor-matched tissues as the norms for gene expression analysis in cancers.,37635765,https://pubmed.ncbi.nlm.nih.gov/37635765/,https://doi.org/10.1016/j.csbj.2023.07.040,"['Autopsy', 'Cancer research', 'Differential gene expression analysis', 'Healthy tissue controls', 'Molecular pathology', 'Molecular pathways', 'RNA sequencing', 'Tumor matched pathologically normal tissues']","Normal tissues are essential for studying disease-specific differential gene expression. However, healthy human controls are typically available only in postmortal/autopsy settings. In cancer research, fragments of pathologically normal tissue adjacent to tumor site are frequently used as the controls. However, it is largely underexplored how cancers can systematically influence gene expression of the neighboring tissues. Here we performed a comprehensive pan-cancer comparison of molecular profiles of solid tumor-adjacent and autopsy-derived ""healthy"" normal tissues. We found a number of systemic molecular differences related to activation of the immune cells, intracellular transport and autophagy, cellular respiration, telomerase activation, p38 signaling, cytoskeleton remodeling, and reorganization of the extracellular matrix. The tumor-adjacent tissues were deficient in apoptotic signaling and negative regulation of cell growth including G2/M cell cycle transition checkpoint. We also detected an extensive rearrangement of the chemical perception network. Molecular targets of 32 and 37 cancer drugs were over- or underexpressed, respectively, in the tumor-adjacent norms. These processes may be driven by molecular events that are correlated between the paired cancer and adjacent normal tissues, that mostly relate to inflammation and regulation of intracellular molecular pathways such as the p38, MAPK, Notch, and IGF1 signaling. However, using a model of macaque postmortal tissues we showed that for the 30 min - 24-hour time frame at 4ºC, an RNA degradation pattern in lung biosamples resulted in an artifact ""differential"" expression profile for 1140 genes, although no differences could be detected in liver. Thus, such concerns should be addressed in practice.",1,Normal tissues are essential for studying disease-specific differential gene expression. Healthy human controls are typically available only in postmortal/autopsy settings.
A systematic benchmark of machine learning methods for protein-RNA interaction prediction.,37635383,https://pubmed.ncbi.nlm.nih.gov/37635383/,https://doi.org/10.1093/bib/bbad307,"['RNA biology', 'RNA-binding proteins', 'benchmark', 'deep learning']","RNA-binding proteins (RBPs) are central actors of RNA post-transcriptional regulation. Experiments to profile-binding sites of RBPs in vivo are limited to transcripts expressed in the experimental cell type, creating the need for computational methods to infer missing binding information. While numerous machine-learning based methods have been developed for this task, their use of heterogeneous training and evaluation datasets across different sets of RBPs and CLIP-seq protocols makes a direct comparison of their performance difficult. Here, we compile a set of 37 machine learning (primarily deep learning) methods for in vivo RBP-RNA interaction prediction and systematically benchmark a subset of 11 representative methods across hundreds of CLIP-seq datasets and RBPs. Using homogenized sample pre-processing and two negative-class sample generation strategies, we evaluate methods in terms of predictive performance and assess the impact of neural network architectures and input modalities on model performance. We believe that this study will not only enable researchers to choose the optimal prediction method for their tasks at hand, but also aid method developers in developing novel, high-performing methods by introducing a standardized framework for their evaluation.",2, RNA-binding proteins (RBPs) are central actors of RNA post-transcriptional regulation.
Pretrained transformer models for predicting the withdrawal of drugs from the market.,37610328,https://pubmed.ncbi.nlm.nih.gov/37610328/,https://doi.org/10.1093/bioinformatics/btad519,[],"The process of drug discovery is notoriously complex, costing an average of 2.6 billion dollars and taking ∼13 years to bring a new drug to the market. The success rate for new drugs is alarmingly low (around 0.0001%), and severe adverse drug reactions (ADRs) frequently occur, some of which may even result in death. Early identification of potential ADRs is critical to improve the efficiency and safety of the drug development process.",1,The process of drug discovery is notoriously complex. The success rate for new drugs is alarmingly low.
MMDTA: A Multimodal Deep Model for Drug-Target Affinity with a Hybrid Fusion Strategy.,37610162,https://pubmed.ncbi.nlm.nih.gov/37610162/,https://doi.org/10.1021/acs.jcim.3c00866,[],"The prediction of the drug-target affinity (DTA) plays an important role in evaluating molecular druggability. Although deep learning-based models for DTA prediction have been extensively attempted, there are rare reports on multimodal models that leverage various fusion strategies to exploit heterogeneous information from multiple different modalities of drugs and targets. In this study, we proposed a multimodal deep model named MMDTA, which integrated the heterogeneous information from various modalities of drugs and targets using a hybrid fusion strategy to enhance DTA prediction. To achieve this, MMDTA first employed convolutional neural networks (CNNs) and graph convolutional networks (GCNs) to extract diverse heterogeneous information from the sequences and structures of drugs and targets. It then utilized a hybrid fusion strategy to combine and complement the extracted heterogeneous information, resulting in the fused modal information for predicting drug-target affinity through the fully connected (FC) layers. Experimental results demonstrated that MMDTA outperformed the competitive state-of-the-art deep learning models on the widely used benchmark data sets, particularly with a significantly improved key evaluation metric, Root Mean Square Error (RMSE). Furthermore, MMDTA exhibited excellent generalization and practical application performance on multiple different data sets. These findings highlighted MMDTA's accuracy and reliability in predicting the drug-target binding affinity. For researchers interested in the source data and code, they are accessible at http://github.com/dldxzx/MMDTA.",1,The prediction of the drug-target affinity (DTA) plays an important role in evaluating molecular druggability.
HOPEXGB: A Consensual Model for Predicting miRNA/lncRNA-Disease Associations Using a Heterogeneous Disease-miRNA-lncRNA Information Network.,37604142,https://pubmed.ncbi.nlm.nih.gov/37604142/,https://doi.org/10.1021/acs.jcim.3c00856,[],"Predicting disease-related microRNAs (miRNAs) and long noncoding RNAs (lncRNAs) is crucial to find new biomarkers for the prevention, diagnosis, and treatment of complex human diseases. Computational predictions for miRNA/lncRNA-disease associations are of great practical significance, since traditional experimental detection is expensive and time-consuming. In this paper, we proposed a consensual machine-learning technique-based prediction approach to identify disease-related miRNAs and lncRNAs by high-order proximity preserved embedding (HOPE) and eXtreme Gradient Boosting (XGB), named HOPEXGB. By connecting lncRNA, miRNA, and disease nodes based on their correlations and relationships, we first created a heterogeneous disease-miRNA-lncRNA (DML) information network to achieve an effective fusion of information on similarities, correlations, and interactions among miRNAs, lncRNAs, and diseases. In addition, a more rational negative data set was generated based on the similarities of unknown associations with the known ones, so as to effectively reduce the false negative rate in the data set for model construction. By 10-fold cross-validation, HOPE shows better performance than other graph embedding methods. The final consensual HOPEXGB model yields robust performance with a mean prediction accuracy of 0.9569 and also demonstrates high sensitivity and specificity advantages compared to lncRNA/miRNA-specific predictions. Moreover, it is superior to other existing methods and gives promising performance on the external testing data, indicating that integrating the information on lncRNA-miRNA interactions and the similarities of lncRNAs/miRNAs is beneficial for improving the prediction performance of the model. Finally, case studies on lung, stomach, and breast cancers indicate that HOPEXGB could be a powerful tool for preclinical biomarker detection and bioexperiment preliminary screening for the diagnosis and prognosis of cancers. HOPEXGB is publicly available at https://github.com/airpamper/HOPEXGB.",1,"Predicting disease-related microRNAs and long noncoding RNAs (lncRNAs) is crucial to find new biomarkers for the prevention, diagnosis, and treatment"
HimGNN: a novel hierarchical molecular graph representation learning framework for property prediction.,37594313,https://pubmed.ncbi.nlm.nih.gov/37594313/,https://doi.org/10.1093/bib/bbad305,"['deep learning', 'drug discovery', 'graph neural networks', 'molecular property prediction']","Accurate prediction of molecular properties is an important topic in drug discovery. Recent works have developed various representation schemes for molecular structures to capture different chemical information in molecules. The atom and motif can be viewed as hierarchical molecular structures that are widely used for learning molecular representations to predict chemical properties. Previous works have attempted to exploit both atom and motif to address the problem of information loss in single representation learning for various tasks. To further fuse such hierarchical information, the correspondence between learned chemical features from different molecular structures should be considered. Herein, we propose a novel framework for molecular property prediction, called hierarchical molecular graph neural networks (HimGNN). HimGNN learns hierarchical topology representations by applying graph neural networks on atom- and motif-based graphs. In order to boost the representational power of the motif feature, we design a Transformer-based local augmentation module to enrich motif features by introducing heterogeneous atom information in motif representation learning. Besides, we focus on the molecular hierarchical relationship and propose a simple yet effective rescaling module, called contextual self-rescaling, that adaptively recalibrates molecular representations by explicitly modelling interdependencies between atom and motif features. Extensive computational experiments demonstrate that HimGNN can achieve promising performances over state-of-the-art baselines on both classification and regression tasks in molecular property prediction.",2,Accurate prediction of molecular properties is an important topic in drug discovery. Recent works have developed various representation schemes for molecular structures to capture different chemical information in molecules.
iDeLUCS: a deep learning interactive tool for alignment-free clustering of DNA sequences.,37589603,https://pubmed.ncbi.nlm.nih.gov/37589603/,https://doi.org/10.1093/bioinformatics/btad508,[],"We present an interactive Deep Learning-based software tool for Unsupervised Clustering of DNA Sequences (iDeLUCS), that detects genomic signatures and uses them to cluster DNA sequences, without the need for sequence alignment or taxonomic identifiers. iDeLUCS is scalable and user-friendly: its graphical user interface, with support for hardware acceleration, allows the practitioner to fine-tune the different hyper-parameters involved in the training process without requiring extensive knowledge of deep learning. The performance of iDeLUCS was evaluated on a diverse set of datasets: several real genomic datasets from organisms in kingdoms Animalia, Protista, Fungi, Bacteria, and Archaea, three datasets of viral genomes, a dataset of simulated metagenomic reads from microbial genomes, and multiple datasets of synthetic DNA sequences. The performance of iDeLUCS was compared to that of two classical clustering algorithms (k-means++ and GMM) and two clustering algorithms specialized in DNA sequences (MeShClust v3.0 and DeLUCS), using both intrinsic cluster evaluation metrics and external evaluation metrics. In terms of unsupervised clustering accuracy, iDeLUCS outperforms the two classical algorithms by an average of ∼20%, and the two specialized algorithms by an average of ∼12%, on the datasets of real DNA sequences analyzed. Overall, our results indicate that iDeLUCS is a robust clustering method suitable for the clustering of large and diverse datasets of unlabeled DNA sequences.",2,iDeLUCS is an interactive Deep Learning-based software tool for Unsupervised Clustering of DNA Sequences.
Toward the functional interpretation of somatic structural variations: bulk- and single-cell approaches.,37587831,https://pubmed.ncbi.nlm.nih.gov/37587831/,https://doi.org/10.1093/bib/bbad297,"['single-cell whole-genome sequencing', 'somatic structural variation', 'whole-genome sequencing']","Structural variants (SVs) are genomic rearrangements that can take many different forms such as copy number alterations, inversions and translocations. During cell development and aging, somatic SVs accumulate in the genome with potentially neutral, deleterious or pathological effects. Generation of somatic SVs is a key mutational process in cancer development and progression. Despite their importance, the detection of somatic SVs is challenging, making them less studied than somatic single-nucleotide variants. In this review, we summarize recent advances in whole-genome sequencing (WGS)-based approaches for detecting somatic SVs at the tissue and single-cell levels and discuss their advantages and limitations. First, we describe the state-of-the-art computational algorithms for somatic SV calling using bulk WGS data and compare the performance of somatic SV detectors in the presence or absence of a matched-normal control. We then discuss the unique features of cutting-edge single-cell-based techniques for analyzing somatic SVs. The advantages and disadvantages of bulk and single-cell approaches are highlighted, along with a discussion of their sensitivity to copy-neutral SVs, usefulness for functional inferences and experimental and computational costs. Finally, computational approaches for linking somatic SVs to their functional readouts, such as those obtained from single-cell transcriptome and epigenome analyses, are illustrated, with a discussion of the promise of these approaches in health and diseases.",1,Structural variants (SVs) are genomic rearrangements that can take many different forms.
Sequence-Dependent Properties of the RNA Duplex.,37577978,https://pubmed.ncbi.nlm.nih.gov/37577978/,https://doi.org/10.1021/acs.jcim.3c00741,[],"Sequence-dependent properties of the DNA duplex have been accurately described using extensive molecular dynamics simulations. The RNA duplex meanwhile─which is typically represented as a sequence-averaged rigid rod─does not benefit from having equivalent molecular dynamics simulations. In this paper, we present a massive simulation effort using a set of ABC-optimized duplexes from which we derived tetramer-resolution properties of the RNA duplex and a simple mesoscopic model that can represent elastic properties of long RNA duplexes. Despite the extreme chemical similarity between DNA and RNA, the local and global elastic properties of the duplexes are very different. DNA duplexes show a complex and nonelastic pattern of flexibility, for instance, while RNA duplexes behave as an elastic system whose deformations can be represented by simple harmonic potentials. In RNA duplexes (RNA",1," Sequence-dependent properties of the DNA duplex have been accurately described using extensive molecular dynamics simulations. The RNA duplex, meanwhile, does not benefit from equivalent simulations."
Insight on physicochemical properties governing peptide MS1 response in HPLC-ESI-MS/MS: A deep learning approach.,37560124,https://pubmed.ncbi.nlm.nih.gov/37560124/,https://doi.org/10.1016/j.csbj.2023.07.027,"['Absolute quantification', 'Attention mechanism', 'Deep learning', 'ESI-MS', 'MS1 response prediction', 'Quantitative proteomics']","Accurate and absolute quantification of peptides in complex mixtures using quantitative mass spectrometry (MS)-based methods requires foreground knowledge and isotopically labeled standards, thereby increasing analytical expenses, time consumption, and labor, thus limiting the number of peptides that can be accurately quantified. This originates from differential ionization efficiency between peptides and thus, understanding the physicochemical properties that influence the ionization and response in MS analysis is essential for developing less restrictive label-free quantitative methods. Here, we used equimolar peptide pool repository data to develop a deep learning model capable of identifying amino acids influencing the MS1 response. By using an encoder-decoder with an attention mechanism and correlating attention weights with amino acid physicochemical properties, we obtain insight on properties governing the peptide-level MS1 response within the datasets. While the problem cannot be described by one single set of amino acids and properties, distinct patterns were reproducibly obtained. Properties are grouped in three main categories related to peptide hydrophobicity, charge, and structural propensities. Moreover, our model can predict MS1 intensity output under defined conditions based solely on peptide sequence input. Using a refined training dataset, the model predicted log-transformed peptide MS1 intensities with an average error of 9.7 ± 0.5% based on 5-fold cross validation, and outperformed random forest and ridge regression models on both log-transformed and real scale data. This work demonstrates how deep learning can facilitate identification of physicochemical properties influencing peptide MS1 responses, but also illustrates how sequence-based response prediction and label-free peptide-level quantification may impact future workflows within quantitative proteomics.",1,Accurate and absolute quantification of peptides in complex mixtures using quantitative mass spectrometry (MS)-based methods requires foreground knowledge and isotopically labeled standards.
Spatial organisation of the mesoscale connectome: A feature influencing synchrony and metastability of network dynamics.,37552650,https://pubmed.ncbi.nlm.nih.gov/37552650/,https://doi.org/10.1371/journal.pcbi.1011349,[],"Significant research has investigated synchronisation in brain networks, but the bulk of this work has explored the contribution of brain networks at the macroscale. Here we explore the effects of changing network topology on functional dynamics in spatially constrained random networks representing mesoscale neocortex. We use the Kuramoto model to simulate network dynamics and explore synchronisation and critical dynamics of the system as a function of topology in randomly generated networks with a distance-related wiring probability and no preferential attachment term. We show networks which predominantly make short-distance connections smooth out the critical coupling point and show much greater metastability, resulting in a wider range of coupling strengths demonstrating critical dynamics and metastability. We show the emergence of cluster synchronisation in these geometrically-constrained networks with functional organisation occurring along structural connections that minimise the participation coefficient of the cluster. We show that these cohorts of internally synchronised nodes also behave en masse as weakly coupled nodes and show intra-cluster desynchronisation and resynchronisation events related to inter-cluster interaction. While cluster synchronisation appears crucial to healthy brain function, it may also be pathological if it leads to unbreakable local synchronisation which may happen at extreme topologies, with implications for epilepsy research, wider brain function and other domains such as social networks.",1,The study looked at the effects of changing network topology on functional dynamics in spatially constrained random networks representing mesoscale neocortex.
AggBERT: Best in Class Prediction of Hexapeptide Amyloidogenesis with a Semi-Supervised ProtBERT Model.,37552230,https://pubmed.ncbi.nlm.nih.gov/37552230/,https://doi.org/10.1021/acs.jcim.3c00817,[],"The prediction of peptide amyloidogenesis is a challenging problem in the field of protein folding. Large language models, such as the ProtBERT model, have recently emerged as powerful tools in analyzing protein sequences for applications, such as predicting protein structure and function. In this article, we describe the use of a semisupervised and fine-tuned ProtBERT model to predict peptide amyloidogenesis from sequences alone. Our approach, which we call AggBERT, achieved state-of-the-art performance, demonstrating the potential for large language models to improve the accuracy and speed of amyloid fibril prediction over simple heuristics or structure-based approaches. This work highlights the transformative potential of machine learning and large language models in the fields of chemical biology and biomedicine.",1,The prediction of peptide amyloidogenesis is a challenging problem in the field of protein folding.
Streamlining Large Chemical Library Docking with Artificial Intelligence: the PyRMD2Dock Approach.,37552222,https://pubmed.ncbi.nlm.nih.gov/37552222/,https://doi.org/10.1021/acs.jcim.3c00647,[],"The present contribution introduces a novel computational protocol called PyRMD2Dock, which combines the Ligand-Based Virtual Screening (LBVS) tool PyRMD with the popular docking software AutoDock-GPU (AD4-GPU) to enhance the throughput of virtual screening campaigns for drug discovery. By implementing PyRMD2Dock, we demonstrate that it is possible to rapidly screen massive chemical databases and identify those with the highest predicted binding affinity to a target protein. Our benchmarking and screening experiments illustrate the predictive power and speed of PyRMD2Dock and highlight its potential to accelerate the discovery of novel drug candidates. Overall, this study showcases the value of combining AI-powered LBVS tools with docking software to enable effective and high-throughput virtual screening of ultralarge molecular databases in drug discovery. PyRMD and the PyRMD2Dock protocol are freely available on GitHub (https://github.com/cosconatilab/PyRMD) as an open-source tool.",1,PyRMD2Dock combines the Ligand-Based Virtual Screening (LBVS) tool PyRMD with the popular docking software AutoDock-GPU (AD4
HGNNLDA: Predicting lncRNA-Drug Sensitivity Associations via a Dual Channel Hypergraph Neural Network.,37549089,https://pubmed.ncbi.nlm.nih.gov/37549089/,https://doi.org/10.1109/TCBB.2023.3302468,[],"Drug sensitivity is critical for enabling personalized treatment. Many studies have shown that long non-coding RNAs (lncRNAs) are closely related to drug sensitivity because lncRNAs can regulate genes related to drug sensitivity to affect drug efficacy. Exploring lncRNA-drug sensitivity associations has important implications for drug development and disease treatment. However, identifying lncRNA-drug sensitivity associations based on traditional biological approaches is small-scale and time-consuming. In this work, we develop a dual-channel hypergraph neural network-based method named HGNNLDA to infer unknown lncRNA-drug sensitivity associations. To our best knowledge, HGNNLDA is the first computational framework to predict lncRNA-drug sensitivity associations. HGNNLDA applies the hypergraph neural network to obtain high-order neighbor information on the lncRNA hypergraph and the drug hypergraph, respectively, and utilizes a joint update mechanism to generate lncRNA embeddings and drug embeddings. In traditional graphs, an edge contains only two nodes. However, hyperedges in hypergraphs can contain any number of nodes and hypergraphs can well describe the higher-order connectivity of the lncRNA-drug bipartite graphs. The comprehensive experimental results show that HGNNLDA significantly outperforms the other six state-of-the-art models. Case studies on two drugs further illustrate that HGNNLDA is an effective tool to predict lncRNA-drug sensitivity associations.",1,Long non-coding RNAs (lncRNAs) are closely related to drug sensitivity.
Enhancing cryo-EM maps with 3D deep generative networks for assisting protein structure modeling.,37549063,https://pubmed.ncbi.nlm.nih.gov/37549063/,https://doi.org/10.1093/bioinformatics/btad494,[],"The tertiary structures of an increasing number of biological macromolecules have been determined using cryo-electron microscopy (cryo-EM). However, there are still many cases where the resolution is not high enough to model the molecular structures with standard computational tools. If the resolution obtained is near the empirical borderline (3-4.5 Å), improvement in the map quality facilitates structure modeling.",1,The tertiary structures of an increasing number of biological macromolecules have been determined using cryo-electron microscopy.
"A Novel ""Activation Switch"" Motif Common to All Aminergic Receptors.",37540602,https://pubmed.ncbi.nlm.nih.gov/37540602/,https://doi.org/10.1021/acs.jcim.3c00732,"['aminergic receptors', 'conformational analysis', 'cryo-EM structures', 'crystal structures', 'ligand binding pocket', 'receptor activation']","Aminergic receptors are G protein-coupled receptors (GPCRs) that transduce signals from small endogenous biogenic amines to regulate intracellular signaling pathways. Agonist binding in the ligand binding pocket on the extracellular side opens and prepares a cavity on the intracellular face of the receptors to interact with and activate G proteins and β-arrestins. Here, by reviewing and analyzing all available aminergic receptor structures, we seek to identify activation-related conformational changes that are independent of the specific scaffold of the bound agonist, which we define as ""activation conformational changes"" (ACCs). While some common intracellular ACCs have been well-documented, identifying common extracellular ACCs, including those in the ligand binding pocket, is complicated by local adjustments to different ligand scaffolds. Our analysis shows no common ACCs at the extracellular ends of the transmembrane helices. Furthermore, the restricted access to the ligand binding pocket identified previously in some receptors is not universal. Notably, the Trp",2,Aminergic receptors are G protein-coupled receptors that regulate intracellular signaling pathways.
Ionmob: a Python package for prediction of peptide collisional cross-section values.,37540201,https://pubmed.ncbi.nlm.nih.gov/37540201/,https://doi.org/10.1093/bioinformatics/btad486,[],"Including ion mobility separation (IMS) into mass spectrometry proteomics experiments is useful to improve coverage and throughput. Many IMS devices enable linking experimentally derived mobility of an ion to its collisional cross-section (CCS), a highly reproducible physicochemical property dependent on the ion's mass, charge and conformation in the gas phase. Thus, known peptide ion mobilities can be used to tailor acquisition methods or to refine database search results. The large space of potential peptide sequences, driven also by posttranslational modifications of amino acids, motivates an in silico predictor for peptide CCS. Recent studies explored the general performance of varying machine-learning techniques, however, the workflow engineering part was of secondary importance. For the sake of applicability, such a tool should be generic, data driven, and offer the possibility to be easily adapted to individual workflows for experimental design and data processing.",1,Knowing peptide ion mobilities can be used to tailor acquisition methods or to refine database search results.
Modeling suggests that virion production cycles within individual cells is key to understanding acute hepatitis B virus infection kinetics.,37535676,https://pubmed.ncbi.nlm.nih.gov/37535676/,https://doi.org/10.1371/journal.pcbi.1011309,[],"Hepatitis B virus (HBV) infection kinetics in immunodeficient mice reconstituted with humanized livers from inoculation to steady state is highly dynamic despite the absence of an adaptive immune response. To recapitulate the multiphasic viral kinetic patterns, we developed an agent-based model that includes intracellular virion production cycles reflecting the cyclic nature of each individual virus lifecycle. The model fits the data well predicting an increase in production cycles initially starting with a long production cycle of 1 virion per 20 hours that gradually reaches 1 virion per hour after approximately 3-4 days before virion production increases dramatically to reach to a steady state rate of 4 virions per hour per cell. Together, modeling suggests that it is the cyclic nature of the virus lifecycle combined with an initial slow but increasing rate of HBV production from each cell that plays a role in generating the observed multiphasic HBV kinetic patterns in humanized mice.",1,Hepatitis B virus (HBV) infection kinetics in immunodeficient mice reconstituted with humanized livers from inoculation to steady state is highly dynamic
KOunt: a reproducible KEGG orthologue abundance workflow.,37535671,https://pubmed.ncbi.nlm.nih.gov/37535671/,https://doi.org/10.1093/bioinformatics/btad483,[],"Accurate gene prediction is essential for successful metagenome analysis. We present KOunt, a Snakemake pipeline, that precisely quantifies KEGG orthologue abundance.",2,Snakemake pipeline precisely quantifies KEGG orthologue abundance.
Exploitation of surrogate variables in random forests for unbiased analysis of mutual impact and importance of features.,37522865,https://pubmed.ncbi.nlm.nih.gov/37522865/,https://doi.org/10.1093/bioinformatics/btad471,[],"Random forest is a popular machine learning approach for the analysis of high-dimensional data because it is flexible and provides variable importance measures for the selection of relevant features. However, the complex relationships between the features are usually not considered for the selection and thus also neglected for the characterization of the analysed samples.",1,Random forest is a popular machine learning approach for the analysis of high-dimensional data. It is flexible and provides variable importance measures for the selection of relevant features.
Towards advanced bioprocess optimization: A multiscale modelling approach.,37520284,https://pubmed.ncbi.nlm.nih.gov/37520284/,https://doi.org/10.1016/j.csbj.2023.07.003,"['Bioprocess control', 'CHO cells', 'Digital twin', 'Metabolic optimization', 'Process systems']","Mammalian cells produce up to 80 % of the commercially available therapeutic proteins, with Chinese Hamster Ovary (CHO) cells being the primary production host. Manufacturing involves a train of reactors, the last of which is typically run in fed-batch mode, where cells grow and produce the required protein. The feeding strategy is decided a priori, from either past operations or the design of experiments and rarely considers the current state of the process. This work proposes a Model Predictive Control (MPC) formulation based on a hybrid kinetic-stoichiometric reactor model to provide optimal feeding policies in real-time, which is agnostic to the culture, hence transferable across CHO cell culture systems. The benefits of the proposed controller formulation are demonstrated through a comparison between an open-loop simulation and closed-loop optimization, using a digital twin as an emulator of the process.",1,Mammalian cells produce up to 80% of the commercially available therapeutic proteins. Chinese Hamster Ovary (CHO) cells are the primary production host.
Autophagy and biotransformation affect sorafenib resistance in hepatocellular carcinoma.,37520282,https://pubmed.ncbi.nlm.nih.gov/37520282/,https://doi.org/10.1016/j.csbj.2023.07.005,"['Autophagy', 'Biotransformation', 'HCC', 'PI3K/AKT/mTOR', 'Proteomics', 'Sorafenib resistance']","As sorafenib is a first-line drug for treating advanced hepatocellular carcinoma, sorafenib resistance has historically attracted attention. However, most of this attention has been focused on a series of mechanisms related to drug resistance arising after sorafenib treatment. In this study, we used proteomic techniques to explore the potential mechanisms by which pretreatment factors affect sorafenib resistance. The degree of redundant pathway PI3K/AKT activation, biotransformation capacity, and autophagy level in hepatocellular carcinoma patients prior to sorafenib treatment might affect their sensitivity to sorafenib, in which ADH1A and STING1 are key molecules. These three factors could interact mechanistically to promote tumor cell survival, might be malignant features of tumor cells, and are associated with hepatocellular carcinoma prognosis. Our study suggests possible avenues of therapeutic intervention for patients with sorafenib-resistance and the potential application of immunotherapy with the aim of improving the survival of such patients.",2,Sorafenib is a first-line drug for treating advanced hepatocellular carcinoma.
iGRLDTI: an improved graph representation learning method for predicting drug-target interactions over heterogeneous biological information network.,37505483,https://pubmed.ncbi.nlm.nih.gov/37505483/,https://doi.org/10.1093/bioinformatics/btad451,[],"The task of predicting drug-target interactions (DTIs) plays a significant role in facilitating the development of novel drug discovery. Compared with laboratory-based approaches, computational methods proposed for DTI prediction are preferred due to their high-efficiency and low-cost advantages. Recently, much attention has been attracted to apply different graph neural network (GNN) models to discover underlying DTIs from heterogeneous biological information network (HBIN). Although GNN-based prediction methods achieve better performance, they are prone to encounter the over-smoothing simulation when learning the latent representations of drugs and targets with their rich neighborhood information in HBIN, and thereby reduce the discriminative ability in DTI prediction.",12,The task of predicting drug-target interactions (DTIs) plays a significant role in facilitating the development of novel drug discovery.
AtacAnnoR: a reference-based annotation tool for single cell ATAC-seq data.,37497729,https://pubmed.ncbi.nlm.nih.gov/37497729/,https://doi.org/10.1093/bib/bbad268,"['bioinformatics software', 'cell type annotation', 'scATAC-seq', 'scRNA-seq', 'single-cell']","Here, we present AtacAnnoR, a two-round annotation method for scATAC-seq data using well-annotated scRNA-seq data as reference. We evaluate AtacAnnoR's performance against six competing methods on 11 benchmark datasets. Our results show that AtacAnnoR achieves the highest mean accuracy and the highest mean balanced accuracy and performs particularly well when unpaired scRNA-seq data are used as the reference. Furthermore, AtacAnnoR implements a 'Combine and Discard' strategy to further improve annotation accuracy when annotations of multiple references are available. AtacAnnoR has been implemented in an R package and can be directly integrated into currently popular scATAC-seq analysis pipelines.",1,AtacAnnoR has been implemented in an R package and can be directly integrated into currently popular scATAC-seq analysis pipelines.
PredPS: Attention-based graph neural network for predicting stability of compounds in human plasma.,37484492,https://pubmed.ncbi.nlm.nih.gov/37484492/,https://doi.org/10.1016/j.csbj.2023.07.008,"['ADME', 'Artificial intelligence', 'Attention analysis', 'Drug discovery', 'Graph neural network', 'Machine learning', 'Pharmacokinetic property', 'Plasma stability']","Stability of compounds in the human plasma is crucial for maintaining sufficient systemic drug exposure and considered an essential factor in the early stages of drug discovery and development. The rapid degradation of compounds in the plasma can result in poor in vivo efficacy. Currently, there are no open-source software programs for predicting human plasma stability. In this study, we developed an attention-based graph neural network, PredPS to predict the plasma stability of compounds in human plasma using in-house and open-source datasets. The PredPS outperformed the two machine learning and two deep learning algorithms that were used for comparison indicating its stability-predicting efficiency. PredPS achieved an area under the receiver operating characteristic curve of 90.1%, accuracy of 83.5%, sensitivity of 82.3%, and specificity of 84.6% when evaluated using 5-fold cross-validation. In the early stages of drug discovery, PredPS could be a helpful method for predicting the human plasma stability of compounds. Saving time and money can be accomplished by adopting an in silico-based plasma stability prediction model at the high-throughput screening stage. The source code for PredPS is available at https://bitbucket.org/krict-ai/predps and the PredPS web server is available at https://predps.netlify.app.",3,"Stability of compounds in the human plasma is crucial for maintaining sufficient systemic drug exposure. Currently, there are no open-source software programs for predicting human plasma stability."
Drug repurposing screens to identify potential drugs for chronic kidney disease by targeting prostaglandin E2 receptor.,37484490,https://pubmed.ncbi.nlm.nih.gov/37484490/,https://doi.org/10.1016/j.csbj.2023.07.007,"['Autophagy', 'Chronic kidney disease', 'Drug repurposing', 'Fibrosis', 'Inflammasome']","Renal inflammation and fibrosis are significantly correlated with the deterioration of kidney function and result in chronic kidney disease (CKD). However, current therapies only delay disease progression and have limited treatment effects. Hence, the development of innovative therapeutic approaches to mitigate the progression of CKD has become an attractive issue. To date, the incidence of CKD is still increasing, and the biomarkers of the pathophysiologic processes of CKD are not clear. Therefore, the identification of novel therapeutic targets associated with the progression of CKD is an attractive issue. It is a critical necessity to discover new therapeutics as nephroprotective strategies to stop CKD progression. In this research, we focus on targeting a prostaglandin E",1,Renal inflammation and fibrosis are significantly correlated with the deterioration of kidney function and result in chronic kidney disease (CKD) Current therapies only delay disease progression and have limited treatment effects
"Explainable AI for Bioinformatics: Methods, Tools and Applications.",37478371,https://pubmed.ncbi.nlm.nih.gov/37478371/,https://doi.org/10.1093/bib/bbad236,"['NLP', 'bioinformatics', 'deep learning', 'explainable AI', 'interpretable machine learning', 'machine learning']","Artificial intelligence (AI) systems utilizing deep neural networks and machine learning (ML) algorithms are widely used for solving critical problems in bioinformatics, biomedical informatics and precision medicine. However, complex ML models that are often perceived as opaque and black-box methods make it difficult to understand the reasoning behind their decisions. This lack of transparency can be a challenge for both end-users and decision-makers, as well as AI developers. In sensitive areas such as healthcare, explainability and accountability are not only desirable properties but also legally required for AI systems that can have a significant impact on human lives. Fairness is another growing concern, as algorithmic decisions should not show bias or discrimination towards certain groups or individuals based on sensitive attributes. Explainable AI (XAI) aims to overcome the opaqueness of black-box models and to provide transparency in how AI systems make decisions. Interpretable ML models can explain how they make predictions and identify factors that influence their outcomes. However, the majority of the state-of-the-art interpretable ML methods are domain-agnostic and have evolved from fields such as computer vision, automated reasoning or statistics, making direct application to bioinformatics problems challenging without customization and domain adaptation. In this paper, we discuss the importance of explainability and algorithmic transparency in the context of bioinformatics. We provide an overview of model-specific and model-agnostic interpretable ML methods and tools and outline their potential limitations. We discuss how existing interpretable ML methods can be customized and fit to bioinformatics research problems. Further, through case studies in bioimaging, cancer genomics and text mining, we demonstrate how XAI methods can improve transparency and decision fairness. Our review aims at providing valuable insights and serving as a starting point for researchers wanting to enhance explainability and decision transparency while solving bioinformatics problems. GitHub: https://github.com/rezacsedu/XAI-for-bioinformatics.",2, Explainable AI (XAI) aims to overcome the opaqueness of black-box models and to provide transparency in how AI systems make decisions.
Position-Specific Enrichment Ratio Matrix scores predict antibody variant properties from deep sequencing data.,37478351,https://pubmed.ncbi.nlm.nih.gov/37478351/,https://doi.org/10.1093/bioinformatics/btad446,[],"Deep sequencing of antibody and related protein libraries after phage or yeast-surface display sorting is widely used to identify variants with increased affinity, specificity, and/or improvements in key biophysical properties. Conventional approaches for identifying optimal variants typically use the frequencies of observation in enriched libraries or the corresponding enrichment ratios. However, these approaches disregard the vast majority of deep sequencing data and often fail to identify the best variants in the libraries.",3,"Deep sequencing of antibody and related protein libraries is widely used to identify variants with increased affinity, specificity, and/or improvements in key biophysical properties."
Ten simple rules for scientists engaging in science communication.,37471282,https://pubmed.ncbi.nlm.nih.gov/37471282/,https://doi.org/10.1371/journal.pcbi.1011251,[],,2,
PINNED: identifying characteristics of druggable human proteins using an interpretable neural network.,37468968,https://pubmed.ncbi.nlm.nih.gov/37468968/,https://doi.org/10.1186/s13321-023-00735-7,"['AlphaFold', 'Dark genome', 'Drug target', 'Druggability', 'Interpretable', 'Machine learning', 'Neural network', 'Protein', 'Protein pocket', 'Proteome']","The identification of human proteins that are amenable to pharmacologic modulation without significant off-target effects remains an important unsolved challenge. Computational methods have been devised to identify features which distinguish between ""druggable"" and ""undruggable"" proteins, finding that protein sequence, tissue and cellular localization, biological role, and position in the protein-protein interaction network are all important discriminant factors. However, many prior efforts to automate the assessment of protein druggability suffer from low performance or poor interpretability. We developed a neural network-based machine learning model capable of generating druggability sub-scores based on each of four distinct categories, combining them to form an overall druggability score. The model achieves an excellent performance in separating drugged and undrugged proteins in the human proteome, with an area under the receiver operating characteristic (AUC) of 0.95. Our use of multiple sub-scores allows the assessment of potential protein targets of interest based on distinct contributors to druggability, leading to a more interpretable and holistic model to identify novel targets.",1,The identification of human proteins that are amenable to pharmacologic modulation without significant off-target effects remains an important unsolved challenge.
MitoHiFi: a python pipeline for mitochondrial genome assembly from PacBio high fidelity reads.,37464285,https://pubmed.ncbi.nlm.nih.gov/37464285/,https://doi.org/10.1186/s12859-023-05385-y,"['DToL', 'Docker', 'Heteroplasmy', 'HiFi', 'Long reads', 'MitoHiFi', 'Mitogenome', 'Python', 'Singularity']"," PacBio high fidelity (HiFi) sequencing reads are both long (15-20 kb) and highly accurate (> Q20). Because of these properties, they have revolutionised genome assembly leading to more accurate and contiguous genomes. In eukaryotes the mitochondrial genome is sequenced alongside the nuclear genome often at very high coverage. A dedicated tool for mitochondrial genome assembly using HiFi reads is still missing.",123,PacBio high fidelity (HiFi) sequencing reads are both long (15-20 kb) and highly accurate.
Molecular Dynamics and Machine Learning Give Insights on the Flexibility-Activity Relationships in Tyrosine Kinome.,37462363,https://pubmed.ncbi.nlm.nih.gov/37462363/,https://doi.org/10.1021/acs.jcim.3c00738,[],"Tyrosine kinases are a subfamily of kinases with critical roles in cellular machinery. Dysregulation of their active or inactive forms is associated with diseases like cancer. This study aimed to holistically understand their flexibility-activity relationships, focusing on pockets and fluctuations. We studied 43 different tyrosine kinases by collecting 120 μs of molecular dynamics simulations, pocket and residue fluctuation analysis, and a complementary machine learning approach. We found that the inactive forms often have increased flexibility, particularly at the DFG motif level. Noteworthy, thanks to these long simulations combined with a decision tree, we identified a semiquantitative fluctuation threshold of the DGF+3 residue over which the kinase has a higher probability to be in the inactive form.",1,Tyrosine kinases are a subfamily of kinases with critical roles in cellular machinery. Dysregulation of their active or inactive forms is associated with diseases like cancer.
Continuous action with a neurobiologically inspired computational approach reveals the dynamics of selection history.,37459378,https://pubmed.ncbi.nlm.nih.gov/37459378/,https://doi.org/10.1371/journal.pcbi.1011283,[],"Everyday perception-action interaction often requires selection of a single goal from multiple possibilities. According to a recent framework of attentional control, object selection is guided not only by the well-established factors of perceptual salience and current goals but also by selection history. Yet, underlying mechanisms linking selection history and visually-guided actions are poorly understood. To examine such interplay and disentangle the impact of target and distractor history on action selection, we employed a priming-of-popout (PoP) paradigm combined with continuous tracking of reaching movements and computational modeling. Participants reached an odd-colored target among homogeneous distractors while we systematically manipulated the sequence of target and distractor colors from one trial to the next. We observed that current reach movements were significantly influenced by the interaction between attraction by the prior target feature and repulsion by the prior distractor feature. With principal component regression, we found that inhibition led by prior distractors influenced reach target selection earlier than facilitation led by the prior target. In parallel, our newly developed computational model validated that current reach target selection can be explained best by the mechanism postulating the preceded impact of previous distractors followed by a previous target. Such converging empirical and computational evidence suggests that the prior selection history triggers a dynamic interplay between target facilitation and distractor inhibition to guide goal-directed action successfully. This, in turn, highlights the necessity of an explicitly integrated approach to determine how visual attentional selection links with adaptive actions in a complex environment.",1,The study looked at the impact of target and distractor history on action selection.
Sequential mutations in exponentially growing populations.,37428805,https://pubmed.ncbi.nlm.nih.gov/37428805/,https://doi.org/10.1371/journal.pcbi.1011289,[],"Stochastic models of sequential mutation acquisition are widely used to quantify cancer and bacterial evolution. Across manifold scenarios, recurrent research questions are: how many cells are there with n alterations, and how long will it take for these cells to appear. For exponentially growing populations, these questions have been tackled only in special cases so far. Here, within a multitype branching process framework, we consider a general mutational path where mutations may be advantageous, neutral or deleterious. In the biologically relevant limiting regimes of large times and small mutation rates, we derive probability distributions for the number, and arrival time, of cells with n mutations. Surprisingly, the two quantities respectively follow Mittag-Leffler and logistic distributions regardless of n or the mutations' selective effects. Our results provide a rapid method to assess how altering the fundamental division, death, and mutation rates impacts the arrival time, and number, of mutant cells. We highlight consequences for mutation rate inference in fluctuation assays.",1,Stochastic models of sequential mutation acquisition are widely used to quantify cancer and bacterial evolution.
MOKPE: drug-target interaction prediction via manifold optimization based kernel preserving embedding.,37407927,https://pubmed.ncbi.nlm.nih.gov/37407927/,https://doi.org/10.1186/s12859-023-05401-1,"['Drug repurposing', 'Drug–target interaction prediction', 'Kernel methods', 'Machine learning', 'Manifold optimization']","In many applications of bioinformatics, data stem from distinct heterogeneous sources. One of the well-known examples is the identification of drug-target interactions (DTIs), which is of significant importance in drug discovery. In this paper, we propose a novel framework, manifold optimization based kernel preserving embedding (MOKPE), to efficiently solve the problem of modeling heterogeneous data. Our model projects heterogeneous drug and target data into a unified embedding space by preserving drug-target interactions and drug-drug, target-target similarities simultaneously.",1,"In many applications of bioinformatics, data stem from distinct heterogeneous sources."
Large-scale predicting protein functions through heterogeneous feature fusion.,37401369,https://pubmed.ncbi.nlm.nih.gov/37401369/,https://doi.org/10.1093/bib/bbad243,"['data mining', 'feature fusion', 'graph neural network', 'protein function prediction']","As the volume of protein sequence and structure data grows rapidly, the functions of the overwhelming majority of proteins cannot be experimentally determined. Automated annotation of protein function at a large scale is becoming increasingly important. Existing computational prediction methods are typically based on expanding the relatively small number of experimentally determined functions to large collections of proteins with various clues, including sequence homology, protein-protein interaction, gene co-expression, etc. Although there has been some progress in protein function prediction in recent years, the development of accurate and reliable solutions still has a long way to go. Here we exploit AlphaFold predicted three-dimensional structural information, together with other non-structural clues, to develop a large-scale approach termed PredGO to annotate Gene Ontology (GO) functions for proteins. We use a pre-trained language model, geometric vector perceptrons and attention mechanisms to extract heterogeneous features of proteins and fuse these features for function prediction. The computational results demonstrate that the proposed method outperforms other state-of-the-art approaches for predicting GO functions of proteins in terms of both coverage and accuracy. The improvement of coverage is because the number of structures predicted by AlphaFold is greatly increased, and on the other hand, PredGO can extensively use non-structural information for functional prediction. Moreover, we show that over 205 000 ($\sim $100%) entries in UniProt for human are annotated by PredGO, over 186 000 ($\sim $90%) of which are based on predicted structure. The webserver and database are available at http://predgo.denglab.org/.",2,"As the volume of protein sequence and structure data grows rapidly, the functions of the overwhelming majority of proteins cannot be experimentally determined."
Augmenting Polymer Datasets by Iterative Rearrangement.,37390494,https://pubmed.ncbi.nlm.nih.gov/37390494/,https://doi.org/10.1021/acs.jcim.3c00144,[],"One of the biggest obstacles to successful polymer property prediction is an effective representation that accurately captures the sequence of repeat units in a polymer. Motivated by the success of data augmentation in computer vision and natural language processing, we explore augmenting polymer data by iteratively rearranging the molecular representation while preserving the correct connectivity, revealing additional substructural information that is not present in a single representation. We evaluate the effects of this technique on the performance of machine learning models trained on three polymer datasets and compare them to common molecular representations. Data augmentation does not yield significant improvements in machine learning property prediction performance compared to equivalent (non-augmented) representations. In datasets where the target property is primarily influenced by the polymer sequence rather than experimental parameters, this data augmentation technique provides molecular embedding with more information to improve property prediction accuracy.",1,Data augmentation does not yield significant improvements in machine learning property prediction performance compared to equivalent (non-augmented) representations.
Supervised learning and model analysis with compositional data.,37390111,https://pubmed.ncbi.nlm.nih.gov/37390111/,https://doi.org/10.1371/journal.pcbi.1011240,[],"Supervised learning, such as regression and classification, is an essential tool for analyzing modern high-throughput sequencing data, for example in microbiome research. However, due to the compositionality and sparsity, existing techniques are often inadequate. Either they rely on extensions of the linear log-contrast model (which adjust for compositionality but cannot account for complex signals or sparsity) or they are based on black-box machine learning methods (which may capture useful signals, but lack interpretability due to the compositionality). We propose KernelBiome, a kernel-based nonparametric regression and classification framework for compositional data. It is tailored to sparse compositional data and is able to incorporate prior knowledge, such as phylogenetic structure. KernelBiome captures complex signals, including in the zero-structure, while automatically adapting model complexity. We demonstrate on par or improved predictive performance compared with state-of-the-art machine learning methods on 33 publicly available microbiome datasets. Additionally, our framework provides two key advantages: (i) We propose two novel quantities to interpret contributions of individual components and prove that they consistently estimate average perturbation effects of the conditional mean, extending the interpretability of linear log-contrast coefficients to nonparametric models. (ii) We show that the connection between kernels and distances aids interpretability and provides a data-driven embedding that can augment further analysis. KernelBiome is available as an open-source Python package on PyPI and at https://github.com/shimenghuang/KernelBiome.",1,KernelBiome is a kernel-based nonparametric regression and classification framework.
UNADON: transformer-based model to predict genome-wide chromosome spatial position.,37387176,https://pubmed.ncbi.nlm.nih.gov/37387176/,https://doi.org/10.1093/bioinformatics/btad246,[],"The spatial positioning of chromosomes relative to functional nuclear bodies is intertwined with genome functions such as transcription. However, the sequence patterns and epigenomic features that collectively influence chromatin spatial positioning in a genome-wide manner are not well understood.",1,The spatial positioning of chromosomes relative to functional nuclear bodies is intertwined with genome functions such as transcription.
TSignal: a transformer model for signal peptide prediction.,37387131,https://pubmed.ncbi.nlm.nih.gov/37387131/,https://doi.org/10.1093/bioinformatics/btad228,[],"Signal peptides (SPs) are short amino acid segments present at the N-terminus of newly synthesized proteins that facilitate protein translocation into the lumen of the endoplasmic reticulum, after which they are cleaved off. Specific regions of SPs influence the efficiency of protein translocation, and small changes in their primary structure can abolish protein secretion altogether. The lack of conserved motifs across SPs, sensitivity to mutations, and variability in the length of the peptides make SP prediction a challenging task that has been extensively pursued over the years.",1,Signal peptides (SPs) are short amino acid segments present at the N-terminus of newly synthesized proteins.
SpatialSort: a Bayesian model for clustering and cell population annotation of spatial proteomics data.,37387130,https://pubmed.ncbi.nlm.nih.gov/37387130/,https://doi.org/10.1093/bioinformatics/btad242,[],"Recent advances in spatial proteomics technologies have enabled the profiling of dozens of proteins in thousands of single cells in situ. This has created the opportunity to move beyond quantifying the composition of cell types in tissue, and instead probe the spatial relationships between cells. However, most current methods for clustering data from these assays only consider the expression values of cells and ignore the spatial context. Furthermore, existing approaches do not account for prior information about the expected cell populations in a sample.",2,Recent advances in spatial proteomics technologies have enabled the profiling of dozens of proteins in thousands of single cells in situ.
iAMPCN: a deep-learning approach for identifying antimicrobial peptides and their functional activities.,37369638,https://pubmed.ncbi.nlm.nih.gov/37369638/,https://doi.org/10.1093/bib/bbad240,"['antimicrobial peptides', 'bioinformatics', 'deep learning', 'functional activities', 'machine learning', 'sequence analysis']","Antimicrobial peptides (AMPs) are short peptides that play crucial roles in diverse biological processes and have various functional activities against target organisms. Due to the abuse of chemical antibiotics and microbial pathogens' increasing resistance to antibiotics, AMPs have the potential to be alternatives to antibiotics. As such, the identification of AMPs has become a widely discussed topic. A variety of computational approaches have been developed to identify AMPs based on machine learning algorithms. However, most of them are not capable of predicting the functional activities of AMPs, and those predictors that can specify activities only focus on a few of them. In this study, we first surveyed 10 predictors that can identify AMPs and their functional activities in terms of the features they employed and the algorithms they utilized. Then, we constructed comprehensive AMP datasets and proposed a new deep learning-based framework, iAMPCN (identification of AMPs based on CNNs), to identify AMPs and their related 22 functional activities. Our experiments demonstrate that iAMPCN significantly improved the prediction performance of AMPs and their corresponding functional activities based on four types of sequence features. Benchmarking experiments on the independent test datasets showed that iAMPCN outperformed a number of state-of-the-art approaches for predicting AMPs and their functional activities. Furthermore, we analyzed the amino acid preferences of different AMP activities and evaluated the model on datasets of varying sequence redundancy thresholds. To facilitate the community-wide identification of AMPs and their corresponding functional types, we have made the source codes of iAMPCN publicly available at https://github.com/joy50706/iAMPCN/tree/master. We anticipate that iAMPCN can be explored as a valuable tool for identifying potential AMPs with specific functional activities for further experimental validation.",6,Antimicrobial peptides (AMPs) are short peptides that play crucial roles in diverse biological processes and have various functional activities against target organisms.
Hierarchical graph transformer with contrastive learning for protein function prediction.,37369035,https://pubmed.ncbi.nlm.nih.gov/37369035/,https://doi.org/10.1093/bioinformatics/btad410,[],"In recent years, high-throughput sequencing technologies have made large-scale protein sequences accessible. However, their functional annotations usually rely on low-throughput and pricey experimental studies. Computational prediction models offer a promising alternative to accelerate this process. Graph neural networks have shown significant progress in protein research, but capturing long-distance structural correlations and identifying key residues in protein graphs remains challenging.",3,High-throughput sequencing technologies have made large-scale protein sequences accessible. Computational prediction models offer a promising alternative to accelerate this process.
"MolBook UNIPI─Create, Manage, Analyze, and Share Your Chemical Data for Free.",37358197,https://pubmed.ncbi.nlm.nih.gov/37358197/,https://doi.org/10.1021/acs.jcim.3c00278,[],"Here, we present MolBook UNIPI, freely available and user-friendly software specifically designed for medicinal chemists as a powerful tool for the easy management of virtual libraries of chemical compounds. With MolBook UNIPI, it is possible to create, store, handle, and share molecular databases in a very simple and intuitive way. The software allows users to rapidly generate libraries of bioactive ligands, building blocks, or commercial compounds by either manually creating single molecules or automatically importing compounds from public databases and pre-existing libraries. MolBook UNIPI databases can be enriched with all kinds of data and can be filtered based on molecular structures or properties, allowing the desired molecules, along with their structures and features, to be easily accessible in just a few clicks. Moreover, new molecular properties and potential toxicological effects of compounds can be rapidly and reliably predicted. Notably, all of these functions can be easily mastered even by inexperienced users, with no prior cheminformatics knowledge or programming skills, which makes MolBook UNIPI an invaluable tool for medicinal chemists. MolBook UNIPI can be downloaded free of charge from the project web page https://molbook.farm.unipi.it/.",5,MolBook UNIPI is free software designed for medicinal chemists.
Taxonomy of hybrid architectures involving rule-based reasoning and machine learning in clinical decision systems: A scoping review.,37355025,https://pubmed.ncbi.nlm.nih.gov/37355025/,https://doi.org/10.1016/j.jbi.2023.104428,"['Artificial intelligence', 'Clinical decision systems', 'Clinical rules', 'Hybrid architectures', 'Machine learning', 'Rule-based systems']","As the application of Artificial Intelligence (AI) technologies increases in the healthcare sector, the industry faces a need to combine medical knowledge, often expressed as clinical rules, with advances in machine learning (ML), which offer high prediction accuracy at the expense of transparency of decision making.",1,"As the application of Artificial Intelligence (AI) technologies increases in the healthcare sector, the industry faces a need to combine medical knowledge with advances in machine learning."
DeepASDPred: a CNN-LSTM-based deep learning method for Autism spectrum disorders risk RNA identification.,37349705,https://pubmed.ncbi.nlm.nih.gov/37349705/,https://doi.org/10.1186/s12859-023-05378-x,"['ASD risk RNA', 'Deep learning', 'DeepASDPred', 'K-mer feature extraction']","Autism spectrum disorders (ASD) are a group of neurodevelopmental disorders characterized by difficulty communicating with society and others, behavioral difficulties, and a brain that processes information differently than normal. Genetics has a strong impact on ASD associated with early onset and distinctive signs. Currently, all known ASD risk genes are able to encode proteins, and some de novo mutations disrupting protein-coding genes have been demonstrated to cause ASD. Next-generation sequencing technology enables high-throughput identification of ASD risk RNAs. However, these efforts are time-consuming and expensive, so an efficient computational model for ASD risk gene prediction is necessary.",1,Next-generation sequencing technology enables high-throughput identification of ASD risk RNAs.
Assumptions on decision making and environment can yield multiple steady states in microbial community models.,37349675,https://pubmed.ncbi.nlm.nih.gov/37349675/,https://doi.org/10.1186/s12859-023-05325-w,"['Flux balance analysis', 'Game theory', 'Microbial communities']","Microbial community simulations using genome scale metabolic networks (GSMs) are relevant for many application areas, such as the analysis of the human microbiome. Such simulations rely on assumptions about the culturing environment, affecting if the culture may reach a metabolically stationary state with constant microbial concentrations. They also require assumptions on decision making by the microbes: metabolic strategies can be in the interest of individual community members or of the whole community. However, the impact of such common assumptions on community simulation results has not been investigated systematically.",1,"Microbial community simulations using genome scale metabolic networks (GSMs) are relevant for many application areas, such as the analysis of the human microbiome."
Comparative Performance of Computer Simulation Models of Intrinsically Disordered Proteins at Different Levels of Coarse-Graining.,37339604,https://pubmed.ncbi.nlm.nih.gov/37339604/,https://doi.org/10.1021/acs.jcim.3c00113,[],"Coarse-graining is commonly used to decrease the computational cost of simulations. However, coarse-grained models are also considered to have lower transferability, with lower accuracy for systems outside the original scope of parametrization. Here, we benchmark a bead-necklace model and a modified Martini 2 model, both coarse-grained models, for a set of intrinsically disordered proteins, with the different models having different degrees of coarse-graining. The SOP-IDP model has earlier been used for this set of proteins; thus, those results are included in this study to compare how models with different levels of coarse-graining compare. The sometimes naive expectation of the least coarse-grained model performing best does not hold true for the experimental pool of proteins used here. Instead, it showed the least good agreement, indicating that one should not necessarily trust the otherwise intuitive notion of a more advanced model inherently being better in model choice.",1,Coarse-graining is commonly used to decrease the computational cost of simulations.
BioSeq-Diabolo: Biological sequence similarity analysis using Diabolo.,37339155,https://pubmed.ncbi.nlm.nih.gov/37339155/,https://doi.org/10.1371/journal.pcbi.1011214,[],"As the key for biological sequence structure and function prediction, disease diagnosis and treatment, biological sequence similarity analysis has attracted more and more attentions. However, the exiting computational methods failed to accurately analyse the biological sequence similarities because of the various data types (DNA, RNA, protein, disease, etc) and their low sequence similarities (remote homology). Therefore, new concepts and techniques are desired to solve this challenging problem. Biological sequences (DNA, RNA and protein sequences) can be considered as the sentences of ""the book of life"", and their similarities can be considered as the biological language semantics (BLS). In this study, we are seeking the semantics analysis techniques derived from the natural language processing (NLP) to comprehensively and accurately analyse the biological sequence similarities. 27 semantics analysis methods derived from NLP were introduced to analyse biological sequence similarities, bringing new concepts and techniques to biological sequence similarity analysis. Experimental results show that these semantics analysis methods are able to facilitate the development of protein remote homology detection, circRNA-disease associations identification and protein function annotation, achieving better performance than the other state-of-the-art predictors in the related fields. Based on these semantics analysis methods, a platform called BioSeq-Diabolo has been constructed, which is named after a popular traditional sport in China. The users only need to input the embeddings of the biological sequence data. BioSeq-Diabolo will intelligently identify the task, and then accurately analyse the biological sequence similarities based on biological language semantics. BioSeq-Diabolo will integrate different biological sequence similarities in a supervised manner by using Learning to Rank (LTR), and the performance of the constructed methods will be evaluated and analysed so as to recommend the best methods for the users. The web server and stand-alone package of BioSeq-Diabolo can be accessed at http://bliulab.net/BioSeq-Diabolo/server/.",8,"Biological sequences (DNA, RNA and protein sequences) can be considered as the sentences of ""the book of life"" Biological sequence similarity analysis is the key for biological sequence structure and function"
What remains from living cells in bacterial lysate-based cell-free systems.,37333859,https://pubmed.ncbi.nlm.nih.gov/37333859/,https://doi.org/10.1016/j.csbj.2023.05.025,"['Adaptation', 'Cell-free', 'E. coli', 'Homeostasis', 'Microfluidics', 'Prototyping', 'Spatial organization']","Because they mimic cells while offering an accessible and controllable environment, lysate-based cell-free systems (CFS) have emerged as valuable biotechnology tools for synthetic biology. Historically used to uncover fundamental mechanisms of life, CFS are nowadays used for a multitude of purposes, including protein production and prototyping of synthetic circuits. Despite the conservation of fundamental functions in CFS like transcription and translation, RNAs and certain membrane-embedded or membrane-bound proteins of the host cell are lost when preparing the lysate. As a result, CFS largely lack some essential properties of living cells, such as the ability to adapt to changing conditions, to maintain homeostasis and spatial organization. Regardless of the application, shedding light on the black-box of the bacterial lysate is necessary to fully exploit the potential of CFS. Most measurements of the activity of synthetic circuits in CFS and ",1,Lysate-based cell-free systems (CFS) have emerged as valuable biotechnology tools for synthetic biology.
Biologically informed variational autoencoders allow predictive modeling of genetic and drug-induced perturbations.,37326971,https://pubmed.ncbi.nlm.nih.gov/37326971/,https://doi.org/10.1093/bioinformatics/btad387,[],"Variational autoencoders (VAEs) have rapidly increased in popularity in biological applications and have already successfully been used on many omic datasets. Their latent space provides a low-dimensional representation of input data, and VAEs have been applied, e.g. for clustering of single-cell transcriptomic data. However, due to their non-linear nature, the patterns that VAEs learn in the latent space remain obscure. Hence, the lower-dimensional data embedding cannot directly be related to input features.",1, Variational autoencoders (VAEs) have rapidly increased in popularity in biological applications.
PLANET: A Multi-objective Graph Neural Network Model for Protein-Ligand Binding Affinity Prediction.,37319418,https://pubmed.ncbi.nlm.nih.gov/37319418/,https://doi.org/10.1021/acs.jcim.3c00253,[],"Predicting protein-ligand binding affinity is a central issue in drug design. Various deep learning models have been published in recent years, where many of them rely on 3D protein-ligand complex structures as input and tend to focus on the single task of reproducing binding affinity. In this study, we have developed a graph neural network model called PLANET (Protein-Ligand Affinity prediction NETwork). This model takes the graph-represented 3D structure of the binding pocket on the target protein and the 2D chemical structure of the ligand molecule as input. It was trained through a multi-objective process with three related tasks, including deriving the protein-ligand binding affinity, protein-ligand contact map, and ligand distance matrix. Besides the protein-ligand complexes with known binding affinity data retrieved from the PDBbind database, a large number of non-binder decoys were also added to the training data for deriving the final model of PLANET. When tested on the CASF-2016 benchmark, PLANET exhibited a scoring power comparable to the best result yielded by other deep learning models as well as a reasonable ranking power and docking power. In virtual screening trials conducted on the DUD-E benchmark, PLANET's performance was notably better than several deep learning and machine learning models. As on the LIT-PCBA benchmark, PLANET achieved comparable accuracy as the conventional docking program Glide, but it only spent less than 1% of Glide's computation time to finish the same job because PLANET did not need exhaustive conformational sampling. Considering the decent accuracy and efficiency of PLANET in binding affinity prediction, it may become a useful tool for conducting large-scale virtual screening.",8,Predicting protein-ligand binding affinity is a central issue in drug design.
Drug Design in the Exascale Era: A Perspective from Massively Parallel QM/MM Simulations.,37319347,https://pubmed.ncbi.nlm.nih.gov/37319347/,https://doi.org/10.1021/acs.jcim.3c00557,[],The initial phases of drug discovery - ,3,The initial phases of drug discovery -  the initial stages of drug discovery.
MedKPL: A heterogeneous knowledge enhanced prompt learning framework for transferable diagnosis.,37315832,https://pubmed.ncbi.nlm.nih.gov/37315832/,https://doi.org/10.1016/j.jbi.2023.104417,"['Knowledge Integration', 'Natural Language Processing', 'Prompt Learning', 'Text Classification']","Artificial Intelligence (AI) based diagnosis systems have emerged as powerful tools to reform traditional medical care. Each clinician now wants to have his own intelligent diagnostic partner to expand the range of services he can provide. However, the implementation of intelligent decision support systems based on clinical note has been hindered by the lack of extensibility of end-to-end AI diagnosis algorithms. When reading a clinical note, expert clinicians make inferences with relevant medical knowledge, which serve as prompts for making accurate diagnoses. Therefore, external medical knowledge is commonly employed as an augmentation for medical text classification tasks. Existing methods, however, cannot integrate knowledge from various knowledge sources as prompts nor can fully utilize explicit and implicit knowledge. To address these issues, we propose a Medical Knowledge-enhanced Prompt Learning (MedKPL) diagnostic framework for transferable clinical note classification. Firstly, to overcome the heterogeneity of knowledge sources, such as knowledge graphs or medical QA databases, MedKPL uniform the knowledge relevant to the disease into text sequences of fixed format. Then, MedKPL integrates medical knowledge into the prompt designed for context representation. Therefore, MedKPL can integrate knowledge into the models to enhance diagnostic performance and effectively transfer to new diseases by using relevant disease knowledge. The results of our experiments on two medical datasets demonstrate that our method yields superior medical text classification results and performs better in cross-departmental transfer tasks under few-shot or even zero-shot settings. These findings demonstrate that our MedKPL framework has the potential to improve the interpretability and transferability of current diagnostic systems.",1,Artificial Intelligence (AI) based diagnosis systems have emerged as powerful tools to reform traditional medical care.
"kboolnet: a toolkit for the verification, validation, and visualization of reaction-contingency (rxncon) models.",37308855,https://pubmed.ncbi.nlm.nih.gov/37308855/,https://doi.org/10.1186/s12859-023-05329-6,"['Boolean networks', 'Cell signaling', 'Computational modeling', 'Network biology', 'Rxncon']","Computational models of cell signaling networks are extremely useful tools for the exploration of underlying system behavior and prediction of response to various perturbations. By representing signaling cascades as executable Boolean networks, the previously developed rxncon (""reaction-contingency"") formalism and associated Python package enable accurate and scalable modeling of signal transduction even in large (thousands of components) biological systems. The models are split into reactions, which generate states, and contingencies, that impinge on reactions; this avoids the so-called ""combinatorial explosion"" of system size. Boolean description of the biological system compensates for the poor availability of kinetic parameters which are necessary for quantitative models. Unfortunately, few tools are available to support rxncon model development, especially for large, intricate systems.",1,"The rxncon (""reaction-contingency"") formalism and associated Python package enable accurate and scalable modeling of signal transduction."
Detecting patterns of accessory genome coevolution in Staphylococcus aureus using data from thousands of genomes.,37296404,https://pubmed.ncbi.nlm.nih.gov/37296404/,https://doi.org/10.1186/s12859-023-05363-4,"['Genetic interaction', 'Genomics', 'Horizontal gene transfer', 'Microbial genomics', 'Software', 'Staphylococcus aureus']","Bacterial genomes exhibit widespread horizontal gene transfer, resulting in highly variable genome content that complicates the inference of genetic interactions. In this study, we develop a method for detecting coevolving genes from large datasets of bacterial genomes based on pairwise comparisons of closely related individuals, analogous to a pedigree study in eukaryotic populations. We apply our method to pairs of genes from the Staphylococcus aureus accessory genome of over 75,000 annotated gene families using a database of over 40,000 whole genomes. We find many pairs of genes that appear to be gained or lost in a coordinated manner, as well as pairs where the gain of one gene is associated with the loss of the other. These pairs form networks of rapidly coevolving genes, primarily consisting of genes involved in virulence, mechanisms of horizontal gene transfer, and antibiotic resistance, particularly the SCCmec complex. While we focus on gene gain and loss, our method can also detect genes that tend to acquire substitutions in tandem, or genotype-phenotype or phenotype-phenotype coevolution. Finally, we present the R package DeCoTUR that allows for the computation of our method.",3,"Bacterial genomes exhibit widespread horizontal gene transfer, resulting in highly variable genome content. We find many pairs of genes that appear to be gained or lost in a coordinated manner."
Finding motifs using DNA images derived from sparse representations.,37294804,https://pubmed.ncbi.nlm.nih.gov/37294804/,https://doi.org/10.1093/bioinformatics/btad378,[],"Motifs play a crucial role in computational biology, as they provide valuable information about the binding specificity of proteins. However, conventional motif discovery methods typically rely on simple combinatoric or probabilistic approaches, which can be biased by heuristics such as substring-masking for multiple motif discovery. In recent years, deep neural networks have become increasingly popular for motif discovery, as they are capable of capturing complex patterns in data. Nonetheless, inferring motifs from neural networks remains a challenging problem, both from a modeling and computational standpoint, despite the success of these networks in supervised learning tasks.",1,"Motifs play a crucial role in computational biology, as they provide valuable information about the binding specificity of proteins."
Large-Scale Modeling of Sparse Protein Kinase Activity Data.,37294674,https://pubmed.ncbi.nlm.nih.gov/37294674/,https://doi.org/10.1021/acs.jcim.3c00132,[],"Protein kinases are a protein family that plays an important role in several complex diseases such as cancer and cardiovascular and immunological diseases. Protein kinases have conserved ATP binding sites, which when targeted can lead to similar activities of inhibitors against different kinases. This can be exploited to create multitarget drugs. On the other hand, selectivity (lack of similar activities) is desirable in order to avoid toxicity issues. There is a vast amount of protein kinase activity data in the public domain, which can be used in many different ways. Multitask machine learning models are expected to excel for these kinds of data sets because they can learn from implicit correlations between tasks (in this case activities against a variety of kinases). However, multitask modeling of sparse data poses two major challenges: (i) creating a balanced train-test split without data leakage and (ii) handling missing data. In this work, we construct a protein kinase benchmark set composed of two balanced splits without data leakage, using random and dissimilarity-driven cluster-based mechanisms, respectively. This data set can be used for benchmarking and developing protein kinase activity prediction models. Overall, the performance on the dissimilarity-driven cluster-based split is lower than on random split-based sets for all models, indicating poor generalizability of models. Nevertheless, we show that multitask deep learning models, on this very sparse data set, outperform single-task deep learning and tree-based models. Finally, we demonstrate that data imputation does not improve the performance of (multitask) models on this benchmark set.",2,Protein kinases are a protein family that plays an important role in several complex diseases such as cancer and cardiovascular and immunological diseases.
Hebbian learning with elasticity explains how the spontaneous motor tempo affects music performance synchronization.,37285380,https://pubmed.ncbi.nlm.nih.gov/37285380/,https://doi.org/10.1371/journal.pcbi.1011154,[],"A musician's spontaneous rate of movement, called spontaneous motor tempo (SMT), can be measured while spontaneously playing a simple melody. Data shows that the SMT influences the musician's tempo and synchronization. In this study we present a model that captures these phenomena. We review the results from three previously-published studies: solo musical performance with a pacing metronome tempo that is different from the SMT, solo musical performance without a metronome at a tempo that is faster or slower than the SMT, and duet musical performance between musicians with matching or mismatching SMTs. These studies showed, respectively, that the asynchrony between the pacing metronome and the musician's tempo grew as a function of the difference between the metronome tempo and the musician's SMT, musicians drifted away from the initial tempo toward the SMT, and the absolute asynchronies were smaller if musicians had matching SMTs. We hypothesize that the SMT constantly acts as a pulling force affecting musical actions at a tempo different from a musician's SMT. To test our hypothesis, we developed a model consisting of a non-linear oscillator with Hebbian tempo learning and a pulling force to the model's spontaneous frequency. While the model's spontaneous frequency emulates the SMT, elastic Hebbian learning allows for frequency learning to match a stimulus' frequency. To test our hypothesis, we first fit model parameters to match the data in the first of the three studies and asked whether this same model would explain the data the remaining two studies without further tuning. Results showed that the model's dynamics allowed it to explain all three experiments with the same set of parameters. Our theory offers a dynamical-systems explanation of how an individual's SMT affects synchronization in realistic music performance settings, and the model also enables predictions about performance settings not yet tested.",3,"A musician's spontaneous rate of movement, called spontaneous motor tempo (SMT), can be measured while spontaneously playing a simple melody."
AIRRSHIP: simulating human B cell receptor repertoire sequences.,37279738,https://pubmed.ncbi.nlm.nih.gov/37279738/,https://doi.org/10.1093/bioinformatics/btad365,[],"Adaptive Immune Receptor Repertoire Sequencing is a rapidly developing field that has advanced understanding of the role of the adaptive immune system in health and disease. Numerous tools have been developed to analyse the complex data produced by this technique but work to compare their accuracy and reliability has been limited. Thorough, systematic assessment of their performance is dependent on the ability to produce high quality simulated datasets with known ground truth. We have developed AIRRSHIP, a flexible and fast Python package that produces synthetic human B cell receptor sequences. AIRRSHIP uses a comprehensive set of reference data to replicate key mechanisms in the immunoglobulin recombination process, with a particular focus on junctional complexity. Repertoires generated by AIRRSHIP are highly similar to published data and all steps in the sequence generation process are recorded. These data can be used to not only determine the accuracy of repertoire analysis tools but can also, by tuning of the large number of user-controllable parameters, give insight into factors that contribute to inaccuracies in results.",1, AIRRSHIP is a flexible and fast Python package that produces synthetic human B cell receptor sequences.
JUMP: replicability analysis of high-throughput experiments with applications to spatial transcriptomic studies.,37279733,https://pubmed.ncbi.nlm.nih.gov/37279733/,https://doi.org/10.1093/bioinformatics/btad366,[],Replicability is the cornerstone of scientific research. The current statistical method for high-dimensional replicability analysis either cannot control the false discovery rate (FDR) or is too conservative.,1,The current statistical method for high-dimensional replicability analysis either cannot control the false discovery rate (FDR) or is too conservative.
Estimating fine age structure and time trends in human contact patterns from coarse contact data: The Bayesian rate consistency model.,37276210,https://pubmed.ncbi.nlm.nih.gov/37276210/,https://doi.org/10.1371/journal.pcbi.1011191,[],"Since the emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), large-scale social contact surveys are now longitudinally measuring the fundamental changes in human interactions in the face of the pandemic and non-pharmaceutical interventions. Here, we present a model-based Bayesian approach that can reconstruct contact patterns at 1-year resolution even when the age of the contacts is reported coarsely by 5 or 10-year age bands. This innovation is rooted in population-level consistency constraints in how contacts between groups must add up, which prompts us to call the approach presented here the Bayesian rate consistency model. The model can also quantify time trends and adjust for reporting fatigue emerging in longitudinal surveys through the use of computationally efficient Hilbert Space Gaussian process priors. We illustrate estimation accuracy on simulated data as well as social contact data from Europe and Africa for which the exact age of contacts is reported, and then apply the model to social contact data with coarse information on the age of contacts that were collected in Germany during the COVID-19 pandemic from April to June 2020 across five longitudinal survey waves. We estimate the fine age structure in social contacts during the early stages of the pandemic and demonstrate that social contact intensities rebounded in an age-structured, non-homogeneous manner. The Bayesian rate consistency model provides a model-based, non-parametric, computationally tractable approach for estimating the fine structure and longitudinal trends in social contacts and is applicable to contemporary survey data with coarsely reported age of contacts as long as the exact age of survey participants is reported.",2,Bayesian approach can reconstruct contact patterns at 1-year resolution. This innovation is rooted in population-level consistency constraints in how contacts between groups must add up.
A mixed-effects stochastic model reveals clonal dominance in gene therapy safety studies.,37268887,https://pubmed.ncbi.nlm.nih.gov/37268887/,https://doi.org/10.1186/s12859-023-05269-1,"['-Leaping', 'Clonal dominance', 'E-M algorithm', 'Gene therapy', 'Mixed-effects models', 'Stochastic reaction networks']","Mathematical models of haematopoiesis can provide insights on abnormal cell expansions (clonal dominance), and in turn can guide safety monitoring in gene therapy clinical applications. Clonal tracking is a recent high-throughput technology that can be used to quantify cells arising from a single haematopoietic stem cell ancestor after a gene therapy treatment. Thus, clonal tracking data can be used to calibrate the stochastic differential equations describing clonal population dynamics and hierarchical relationships in vivo.",1,Clonal tracking is a recent high-throughput technology that can be used to quantify cells arising from a single haematopoietic stem cell ancestor after a gene therapy treatment
Disproportionate impacts of COVID-19 in a large US city.,37262052,https://pubmed.ncbi.nlm.nih.gov/37262052/,https://doi.org/10.1371/journal.pcbi.1011149,[],"COVID-19 has disproportionately impacted individuals depending on where they live and work, and based on their race, ethnicity, and socioeconomic status. Studies have documented catastrophic disparities at critical points throughout the pandemic, but have not yet systematically tracked their severity through time. Using anonymized hospitalization data from March 11, 2020 to June 1, 2021 and fine-grain infection hospitalization rates, we estimate the time-varying burden of COVID-19 by age group and ZIP code in Austin, Texas. During this 15-month period, we estimate an overall 23.7% (95% CrI: 22.5-24.8%) infection rate and 29.4% (95% CrI: 28.0-31.0%) case reporting rate. Individuals over 65 were less likely to be infected than younger age groups (11.2% [95% CrI: 10.3-12.0%] vs 25.1% [95% CrI: 23.7-26.4%]), but more likely to be hospitalized (1,965 per 100,000 vs 376 per 100,000) and have their infections reported (53% [95% CrI: 49-57%] vs 28% [95% CrI: 27-30%]). We used a mixed effect poisson regression model to estimate disparities in infection and reporting rates as a function of social vulnerability. We compared ZIP codes ranking in the 75th percentile of vulnerability to those in the 25th percentile, and found that the more vulnerable communities had 2.5 (95% CrI: 2.0-3.0) times the infection rate and only 70% (95% CrI: 60%-82%) the reporting rate compared to the less vulnerable communities. Inequality persisted but declined significantly over the 15-month study period. Our results suggest that further public health efforts are needed to mitigate local COVID-19 disparities and that the CDC's social vulnerability index may serve as a reliable predictor of risk on a local scale when surveillance data are limited.",1,"CVID-19 has disproportionately impacted individuals depending on where they live and work, and based on their race, ethnicity, and socioeconomic status."
MRGCN: cancer subtyping with multi-reconstruction graph convolutional network using full and partial multi-omics dataset.,37255323,https://pubmed.ncbi.nlm.nih.gov/37255323/,https://doi.org/10.1093/bioinformatics/btad353,[],"Cancer is a molecular complex and heterogeneous disease. Each type of cancer is usually composed of several subtypes with different treatment responses and clinical outcomes. Therefore, subtyping is a crucial step in cancer diagnosis and therapy. The rapid advances in high-throughput sequencing technologies provide an increasing amount of multi-omics data, which benefits our understanding of cancer genetic architecture, and yet poses new challenges in multi-omics data integration.",3,Cancer is a molecular complex and heterogeneous disease. Each type of cancer is usually composed of several subtypes with different treatment responses and clinical outcomes.
Nonlinear data fusion over Entity-Relation graphs for Drug-Target Interaction prediction.,37255310,https://pubmed.ncbi.nlm.nih.gov/37255310/,https://doi.org/10.1093/bioinformatics/btad348,[],"The prediction of reliable Drug-Target Interactions (DTIs) is a key task in computer-aided drug design and repurposing. Here, we present a new approach based on data fusion for DTI prediction built on top of the NXTfusion library, which generalizes the Matrix Factorization paradigm by extending it to the nonlinear inference over Entity-Relation graphs.",1,The prediction of reliable Drug-Target Interactions is a key task in computer-aided drug design and repurposing.
The ACPYPE web server for small-molecule MD topology generation.,37252824,https://pubmed.ncbi.nlm.nih.gov/37252824/,https://doi.org/10.1093/bioinformatics/btad350,[],The generation of parameter files for molecular dynamics (MD) simulations of small molecules that are suitable for force fields commonly applied to proteins and nucleic acids is often challenging. The ACPYPE software and website aid the generation of such parameter files.,2,The ACPYPE software and website aid the generation of such parameter files.
IEPAPI: a method for immune epitope prediction by incorporating antigen presentation and immunogenicity.,37232386,https://pubmed.ncbi.nlm.nih.gov/37232386/,https://doi.org/10.1093/bib/bbad171,"['antigen presentation', 'cancer immunotherapy', 'deep learning', 'immunogenicity', 'neoantigen', 'transformer']","CD8+ T cells can recognize peptides presented by class I human leukocyte antigen (HLA-I) of nucleated cells. Exploring this immune mechanism is essential for identifying T-cell vaccine targets in cancer immunotherapy. Over the past decade, the wealth of data generated by experiments has spawned many computational approaches for predicting HLA-I binding, antigen presentation and T-cell immune responses. Nevertheless, existing HLA-I binding and antigen presentation prediction approaches suffer from low precision due to the absence of T-cell receptor (TCR) recognition. Direct modeling of T-cell immune responses is less effective as TCR recognition's mechanism still remains underexplored. Therefore, directly applying these existing methods to screen cancer neoantigens is still challenging. Here, we propose a novel immune epitope prediction method termed IEPAPI by effectively incorporating antigen presentation and immunogenicity. First, IEPAPI employs a transformer-based feature extraction block to acquire representations of peptides and HLA-I proteins. Second, IEPAPI integrates the prediction of antigen presentation prediction into the input of immunogenicity prediction branch to simulate the connection between the biological processes in the T-cell immune response. Quantitative comparison results on an independent antigen presentation test dataset exhibit that IEPAPI outperformed the current state-of-the-art approaches NetMHCpan4.1 and mhcflurry2.0 on 100 (25/25) and 76% (19/25) of the HLA subtypes, respectively. Furthermore, IEPAPI demonstrates the best precision on two independent neoantigen datasets when compared with existing approaches, suggesting that IEPAPI provides a vital tool for T-cell vaccine design.",1,CD8+ T cells can recognize peptides presented by class I human leukocyte antigen (HLA-I) of nucleated cells.
Integrating massive RNA-seq data to elucidate transcriptome dynamics in Drosophila melanogaster.,37232385,https://pubmed.ncbi.nlm.nih.gov/37232385/,https://doi.org/10.1093/bib/bbad177,"['computational methods', 'data integration and quality control', 'gene expression dynamics', 'massively parallel sequencing', 'sequence read archive']","The volume of ribonucleic acid (RNA)-seq data has increased exponentially, providing numerous new insights into various biological processes. However, due to significant practical challenges, such as data heterogeneity, it is still difficult to ensure the quality of these data when integrated. Although some quality control methods have been developed, sample consistency is rarely considered and these methods are susceptible to artificial factors. Here, we developed MassiveQC, an unsupervised machine learning-based approach, to automatically download and filter large-scale high-throughput data. In addition to the read quality used in other tools, MassiveQC also uses the alignment and expression quality as model features. Meanwhile, it is user-friendly since the cutoff is generated from self-reporting and is applicable to multimodal data. To explore its value, we applied MassiveQC to Drosophila RNA-seq data and generated a comprehensive transcriptome atlas across 28 tissues from embryogenesis to adulthood. We systematically characterized fly gene expression dynamics and found that genes with high expression dynamics were likely to be evolutionarily young and expressed at late developmental stages, exhibiting high nonsynonymous substitution rates and low phenotypic severity, and they were involved in simple regulatory programs. We also discovered that human and Drosophila had strong positive correlations in gene expression in orthologous organs, revealing the great potential of the Drosophila system for studying human development and disease.",2,MassiveQC is an unsupervised machine learning-based approach to automatically download and filter large-scale high-throughput data.
Recent trends in RNA informatics: a review of machine learning and deep learning for RNA secondary structure prediction and RNA drug discovery.,37232359,https://pubmed.ncbi.nlm.nih.gov/37232359/,https://doi.org/10.1093/bib/bbad186,"['RNA informatics', 'RNA secondary structure prediction', 'RNA-based therapeutics']","Computational analysis of RNA sequences constitutes a crucial step in the field of RNA biology. As in other domains of the life sciences, the incorporation of artificial intelligence and machine learning techniques into RNA sequence analysis has gained significant traction in recent years. Historically, thermodynamics-based methods were widely employed for the prediction of RNA secondary structures; however, machine learning-based approaches have demonstrated remarkable advancements in recent years, enabling more accurate predictions. Consequently, the precision of sequence analysis pertaining to RNA secondary structures, such as RNA-protein interactions, has also been enhanced, making a substantial contribution to the field of RNA biology. Additionally, artificial intelligence and machine learning are also introducing technical innovations in the analysis of RNA-small molecule interactions for RNA-targeted drug discovery and in the design of RNA aptamers, where RNA serves as its own ligand. This review will highlight recent trends in the prediction of RNA secondary structure, RNA aptamers and RNA drug discovery using machine learning, deep learning and related technologies, and will also discuss potential future avenues in the field of RNA informatics.",6, Computational analysis of RNA sequences constitutes a crucial step in the field of RNA biology.
The MAPK/ERK channel capacity exceeds 6 bit/hour.,37216347,https://pubmed.ncbi.nlm.nih.gov/37216347/,https://doi.org/10.1371/journal.pcbi.1011155,[],"Living cells utilize signaling pathways to sense, transduce, and process information. As the extracellular stimulation often has rich temporal characteristics which may govern dynamic cellular responses, it is important to quantify the rate of information flow through the signaling pathways. In this study, we used an epithelial cell line expressing a light-activatable FGF receptor and an ERK activity reporter to assess the ability of the MAPK/ERK pathway to transduce signal encoded in a sequence of pulses. By stimulating the cells with random light pulse trains, we demonstrated that the MAPK/ERK channel capacity is at least 6 bits per hour. The input reconstruction algorithm detects the light pulses with 1-min accuracy 5 min after their occurrence. The high information transmission rate may enable the pathway to coordinate multiple processes including cell movement and respond to rapidly varying stimuli such as chemoattracting gradients created by other cells.",1,"Living cells utilize signaling pathways to sense, transduce, and process information."
Fast and versatile sequence-independent protein docking for nanomaterials design using RPXDock.,37216343,https://pubmed.ncbi.nlm.nih.gov/37216343/,https://doi.org/10.1371/journal.pcbi.1010680,[],"Computationally designed multi-subunit assemblies have shown considerable promise for a variety of applications, including a new generation of potent vaccines. One of the major routes to such materials is rigid body sequence-independent docking of cyclic oligomers into architectures with point group or lattice symmetries. Current methods for docking and designing such assemblies are tailored to specific classes of symmetry and are difficult to modify for novel applications. Here we describe RPXDock, a fast, flexible, and modular software package for sequence-independent rigid-body protein docking across a wide range of symmetric architectures that is easily customizable for further development. RPXDock uses an efficient hierarchical search and a residue-pair transform (RPX) scoring method to rapidly search through multidimensional docking space. We describe the structure of the software, provide practical guidelines for its use, and describe the available functionalities including a variety of score functions and filtering tools that can be used to guide and refine docking results towards desired configurations.",3, RPXDock uses an efficient hierarchical search and a residue-pair transform (RPX) scoring method to rapidly search through multidimensional docking space.
On a mechanistic impact of transmembrane tetramerization in the pathological activation of RTKs.,37216019,https://pubmed.ncbi.nlm.nih.gov/37216019/,https://doi.org/10.1016/j.csbj.2023.04.021,"['Model membranes', 'Molecular dynamics simulations', 'Pathological mutations', 'Protein oligomerization', 'Signal transduction', 'Structure prediction']","Constitutive activation of receptor tyrosine kinases (RTKs) via different mutations has a strong impact on the development of severe human disorders, including cancer. Here we propose a putative activation scenario of RTKs, whereby transmembrane (TM) mutations can also promote higher-order oligomerization of the receptors that leads to the subsequent ligand-free activation. We illustrate this scenario using a computational modelling framework comprising sequence-based structure prediction and all-atom 1 µs molecular dynamics (MD) simulations in a lipid membrane for a previously characterised oncogenic TM mutation V536E in platelet-derived growth factor receptor alpha (PDGFRA). We show that in the course of MD simulations the mutant TM tetramer retains stable and compact configuration strengthened by tight protein-protein interactions, while the wild type TM tetramer demonstrates looser packing and a tendency to dissociate. Moreover, the mutation affects the characteristic motions of mutated TM helical segments by introducing additional non-covalent crosslinks in the middle of the TM tetramer, which operate as mechanical hinges. This leads to dynamic decoupling of the C-termini from the rigidified N-terminal parts and facilitates more pronounced possible displacement between the C-termini of the mutant TM helical regions that can provide more freedom for mutual rearrangement of the kinase domains located downstream. Our results for the V536E mutation in the context of PDGFRA TM tetramer allow for the possibility that the effect of oncogenic TM mutations can go beyond alternating the structure and dynamics of TM dimeric states and might also promote the formation of higher-order oligomers directly contributing to ligand-independent signalling effectuated by PDGFRA and other RTKs.",1,"Constantutive activation of receptor tyrosine kinases (RTKs) via different mutations has a strong impact on the development of severe human disorders, including cancer."
Deep cross-modal feature learning applied to predict acutely decompensated heart failure using in-home collected electrocardiography and transthoracic bioimpedance.,37210152,https://pubmed.ncbi.nlm.nih.gov/37210152/,https://doi.org/10.1016/j.artmed.2023.102548,"['Deep learning', 'ECG analysis', 'Heart failure', 'Wearable device']","Deep learning has been successfully applied to ECG data to aid in the accurate and more rapid diagnosis of acutely decompensated heart failure (ADHF). Previous applications focused primarily on classifying known ECG patterns in well-controlled clinical settings. However, this approach does not fully capitalize on the potential of deep learning, which directly learns important features without relying on a priori knowledge. In addition, deep learning applications to ECG data obtained from wearable devices have not been well studied, especially in the field of ADHF prediction.",2,Deep learning has been successfully applied to ECG data to aid in the accurate and more rapid diagnosis of acutely decompensated heart failure (ADHF) Previous applications focused primarily on classifying
Comprehensive analysis of glycoprotein VI-mediated platelet activation signaling pathway for predicting pan-cancer survival and response to anti-PD-1 immunotherapy.,37206616,https://pubmed.ncbi.nlm.nih.gov/37206616/,https://doi.org/10.1016/j.csbj.2023.04.002,"['CD40L-GPVI', 'EMMPRIN-GPVI', 'Glycoprotein VI-mediated platelet activation signaling pathway', 'Immune checkpoint blockade therapy', 'Platelets']","Platelets play a vital role in cancer and immunity. However, few comprehensive studies have been conducted on the role of platelet-related signaling pathways in various cancers and their responses to immune checkpoint blockade (ICB) therapy. In the present study, we focused on the glycoprotein VI-mediated platelet activation (GMPA) signaling pathway and comprehensively evaluated its roles in 19 types of cancers listed in The Cancer Genome Atlas (TCGA) and the Gene Expression Omnibus (GEO). Cox regression and meta-analyses showed that for all 19 types of cancers, patients with high GMPA scores tended to have a good prognosis. Furthermore, the GMPA signature score could serve as an independent prognostic factor for patients with skin cutaneous melanoma (SKCM). The GMPA signature was linked to tumor immunity in all 19 types of cancers, and was correlated with SKCM tumor histology. Compared to other signature scores, the GMPA signature scores for on-treatment samples were more robust predictors of the response to anti-PD-1 blockade in metastatic melanoma. Moreover, the GMPA signature scores were significantly negatively correlated with EMMPRIN (CD147) and positively correlated with CD40LG expression at the transcriptomic level in most cancer patient samples from the TCGA cohort and on-treatment samples from anti-PD1 therapy cohorts. The results of this study provide an important theoretical basis for the use of GMPA signatures, as well as GPVI-EMMPRIN and GPVI-CD40LG pathways, to predict the responses of cancer patients to various types of ICB therapy.",3,Few studies have been conducted on the role of platelet-related signaling pathways in various cancers and their responses to immune checkpoint blockade (ICB) therapy.
Integrating multiple traits for improving polygenic risk prediction in disease and pharmacogenomics GWAS.,37200155,https://pubmed.ncbi.nlm.nih.gov/37200155/,https://doi.org/10.1093/bib/bbad181,"['Cauchy Combination Test', 'genetic correlation', 'multiple traits', 'polygenic risk score', 'principal component analysis']","Polygenic risk score (PRS) has been recently developed for predicting complex traits and drug responses. It remains unknown whether multi-trait PRS (mtPRS) methods, by integrating information from multiple genetically correlated traits, can improve prediction accuracy and power for PRS analysis compared with single-trait PRS (stPRS) methods. In this paper, we first review commonly used mtPRS methods and find that they do not directly model the underlying genetic correlations among traits, which has been shown to be useful in guiding multi-trait association analysis in the literature. To overcome this limitation, we propose a mtPRS-PCA method to combine PRSs from multiple traits with weights obtained from performing principal component analysis (PCA) on the genetic correlation matrix. To accommodate various genetic architectures covering different effect directions, signal sparseness and across-trait correlation structures, we further propose an omnibus mtPRS method (mtPRS-O) by combining P values from mtPRS-PCA, mtPRS-ML (mtPRS based on machine learning) and stPRSs using Cauchy Combination Test. Our extensive simulation studies show that mtPRS-PCA outperforms other mtPRS methods in both disease and pharmacogenomics (PGx) genome-wide association studies (GWAS) contexts when traits are similarly correlated, with dense signal effects and in similar effect directions, and mtPRS-O is consistently superior to most other methods due to its robustness under various genetic architectures. We further apply mtPRS-PCA, mtPRS-O and other methods to PGx GWAS data from a randomized clinical trial in the cardiovascular domain and demonstrate performance improvement of mtPRS-PCA in both prediction accuracy and patient stratification as well as the robustness of mtPRS-O in PRS association test.",1,Polygenic risk score (PRS) has been recently developed for predicting complex traits and drug responses.
Integrative Approach to Dissect the Drug Resistance Mechanism of the H172Y Mutation of SARS-CoV-2 Main Protease.,37199464,https://pubmed.ncbi.nlm.nih.gov/37199464/,https://doi.org/10.1021/acs.jcim.3c00344,[],"Nirmatrelvir is an orally available inhibitor of SARS-CoV-2 main protease (Mpro) and the main ingredient of Paxlovid, a drug approved by the U.S. Food and Drug Administration for high-risk COVID-19 patients. Recently, a rare natural mutation, H172Y, was found to significantly reduce nirmatrelvir's inhibitory activity. As the COVID-19 cases skyrocket in China and the selective pressure of antiviral therapy builds in the US, there is an urgent need to characterize and understand how the H172Y mutation confers drug resistance. Here, we investigated the H172Y Mpro's conformational dynamics, folding stability, catalytic efficiency, and inhibitory activity using all-atom constant pH and fixed-charge molecular dynamics simulations, alchemical and empirical free energy calculations, artificial neural networks, and biochemical experiments. Our data suggest that the mutation significantly weakens the S1 pocket interactions with the N-terminus and perturbs the conformation of the oxyanion loop, leading to a decrease in the thermal stability and catalytic efficiency. Importantly, the perturbed S1 pocket dynamics weaken the nirmatrelvir binding in the P1 position, which explains the decreased inhibitory activity of nirmatrelvir. Our work demonstrates the predictive power of the combined simulation and artificial intelligence approaches, and together with biochemical experiments, they can be used to actively surveil continually emerging mutations of SARS-CoV-2 Mpro and assist the optimization of antiviral drugs. The presented approach, in general, can be applied to characterize mutation effects on any protein drug targets.",1,"Nirmatrelvir is an orally available inhibitor of SARS-CoV-2 main protease (Mpro) It is the main ingredient of Paxlovid, a drug"
scAnno: a deconvolution strategy-based automatic cell type annotation tool for single-cell RNA-sequencing data sets.,37183449,https://pubmed.ncbi.nlm.nih.gov/37183449/,https://doi.org/10.1093/bib/bbad179,"['cell type-specific genes', 'deconvolution', 'logistic regression', 'scRNA-seq data annotation']","Undoubtedly, single-cell RNA sequencing (scRNA-seq) has changed the research landscape by providing insights into heterogeneous, complex and rare cell populations. Given that more such data sets will become available in the near future, their accurate assessment with compatible and robust models for cell type annotation is a prerequisite. Considering this, herein, we developed scAnno (scRNA-seq data annotation), an automated annotation tool for scRNA-seq data sets primarily based on the single-cell cluster levels, using a joint deconvolution strategy and logistic regression. We explicitly constructed a reference profile for human (30 cell types and 50 human tissues) and a reference profile for mouse (26 cell types and 50 mouse tissues) to support this novel methodology (scAnno). scAnno offers a possibility to obtain genes with high expression and specificity in a given cell type as cell type-specific genes (marker genes) by combining co-expression genes with seed genes as a core. Of importance, scAnno can accurately identify cell type-specific genes based on cell type reference expression profiles without any prior information. Particularly, in the peripheral blood mononuclear cell data set, the marker genes identified by scAnno showed cell type-specific expression, and the majority of marker genes matched exactly with those included in the CellMarker database. Besides validating the flexibility and interpretability of scAnno in identifying marker genes, we also proved its superiority in cell type annotation over other cell type annotation tools (SingleR, scPred, CHETAH and scmap-cluster) through internal validation of data sets (average annotation accuracy: 99.05%) and cross-platform data sets (average annotation accuracy: 95.56%). Taken together, we established the first novel methodology that utilizes a deconvolution strategy for automated cell typing and is capable of being a significant application in broader scRNA-seq analysis. scAnno is available at https://github.com/liuhong-jia/scAnno.",3,"ScRNA-seq has changed the research landscape by providing insights into heterogeneous, complex and rare cell populations."
,37181662,https://pubmed.ncbi.nlm.nih.gov/37181662/,https://doi.org/10.1016/j.csbj.2023.04.009,"['Brillouin microscopy', 'Corneal biomechanics', 'Corneal visualization scheimpflug technology', 'Elastography', 'Ocular response analyzer', 'Optical coherence elastography', 'Young’s modulus']","Clinical measurement of corneal biomechanics can aid in the early diagnosis, progression tracking, and treatment evaluation of ocular diseases. Over the past two decades, interdisciplinary collaborations between investigators in optical engineering, analytical biomechanical modeling, and clinical research has expanded our knowledge of corneal biomechanics. These advances have led to innovations in testing methods (",2," Clinical measurement of corneal biomechanics can aid in the early diagnosis, progression tracking, and treatment evaluation of ocular diseases."
AIONER: all-in-one scheme-based biomedical named entity recognition using deep learning.,37171899,https://pubmed.ncbi.nlm.nih.gov/37171899/,https://doi.org/10.1093/bioinformatics/btad310,[],"Biomedical named entity recognition (BioNER) seeks to automatically recognize biomedical entities in natural language text, serving as a necessary foundation for downstream text mining tasks and applications such as information extraction and question answering. Manually labeling training data for the BioNER task is costly, however, due to the significant domain expertise required for accurate annotation. The resulting data scarcity causes current BioNER approaches to be prone to overfitting, to suffer from limited generalizability, and to address a single entity type at a time (e.g. gene or disease).",3,Biomedical named entity recognition (BioNER) seeks to automatically recognize biomedical entities in natural language text. Manually labeling training data for the BioNER task is costly.
ViralConsensus: a fast and memory-efficient tool for calling viral consensus genome sequences directly from read alignment data.,37171896,https://pubmed.ncbi.nlm.nih.gov/37171896/,https://doi.org/10.1093/bioinformatics/btad317,[],"In viral molecular epidemiology, reconstruction of consensus genomes from sequence data is critical for tracking mutations and variants of concern. However, as the number of samples that are sequenced grows rapidly, compute resources needed to reconstruct consensus genomes can become prohibitively large.",2,"In viral molecular epidemiology, reconstruction of consensus genomes from sequence data is critical for tracking mutations and variants of concern."
NanoPack2: population-scale evaluation of long-read sequencing data.,37171891,https://pubmed.ncbi.nlm.nih.gov/37171891/,https://doi.org/10.1093/bioinformatics/btad311,[],"Increases in the cohort size in long-read sequencing projects necessitate more efficient software for quality assessment and processing of sequencing data from Oxford Nanopore Technologies and Pacific Biosciences. Here, we describe novel tools for summarizing experiments, filtering datasets, visualizing phased alignments results, and updates to the NanoPack software suite.",28,Oxford Nanopore Technologies and Pacific Biosciences developed NanoPack software.
Enhancing Hit Discovery in Virtual Screening through Absolute Protein-Ligand Binding Free-Energy Calculations.,37167486,https://pubmed.ncbi.nlm.nih.gov/37167486/,https://doi.org/10.1021/acs.jcim.3c00013,[],"In the hit identification stage of drug discovery, a diverse chemical space needs to be explored to identify initial hits. Contrary to empirical scoring functions, absolute protein-ligand binding free-energy perturbation (ABFEP) provides a theoretically more rigorous and accurate description of protein-ligand binding thermodynamics and could, in principle, greatly improve the hit rates in virtual screening. In this work, we describe an implementation of an accurate and reliable ABFEP method in FEP+. We validated the ABFEP method on eight congeneric compound series binding to eight protein receptors including both neutral and charged ligands. For ligands with net charges, the alchemical ion approach is adopted to avoid artifacts in electrostatic potential energy calculations. The calculated binding free energies correlate with experimental results with a weighted average of ",9,Absolute protein-ligand binding free-energy perturbation (ABFEP) provides a theoretically more rigorous and accurate description of protein- ligand binding thermodynamics.
Low Rank Matrix Factorization Algorithm Based on Multi-Graph Regularization for Detecting Drug-Disease Association.,37159322,https://pubmed.ncbi.nlm.nih.gov/37159322/,https://doi.org/10.1109/TCBB.2023.3274587,[],"Detecting potential associations between drugs and diseases plays an indispensable role in drug development, which has also become a research hotspot in recent years. Compared with traditional methods, some computational approaches have the advantages of fast speed and low cost, which greatly accelerate the progress of predicting the drug-disease association. In this study, we propose a novel similarity-based method of low-rank matrix decomposition based on multi-graph regularization. On the basis of low-rank matrix factorization with L",1,Detecting potential associations between drugs and diseases plays an indispensable role in drug development.
OWSum: algorithmic odor prediction and insight into structure-odor relationships.,37150811,https://pubmed.ncbi.nlm.nih.gov/37150811/,https://doi.org/10.1186/s13321-023-00722-y,"['Odor prediction', 'Olfaction', 'Structure-odor relationships']","We derived and implemented a linear classification algorithm for the prediction of a molecule's odor, called Olfactory Weighted Sum (OWSum). Our approach relies solely on structural patterns of the molecules as features for algorithmic treatment and uses conditional probabilities combined with tf-idf values. In addition to the prediction of molecular odor, OWSum provides insights into properties of the dataset and allows to understand how algorithmic classifications are reached by quantitatively assigning structural patterns to odors. This provides chemists with an intuitive understanding of underlying interactions. To deal with ambiguities of the natural language used to describe odor, we introduced descriptor overlap as a metric for the quantification of semantic overlap between descriptors. Thus, grouping of descriptors and derivation of higher-level descriptors becomes possible. Our approach poses a large leap forward in our capabilities to understand and predict molecular features.",1,Olfactory Weighted Sum (OWSum) is a linear classification algorithm for the prediction of a molecule's odor.
ATTIC is an integrated approach for predicting A-to-I RNA editing sites in three species.,37150785,https://pubmed.ncbi.nlm.nih.gov/37150785/,https://doi.org/10.1093/bib/bbad170,"['A-to-I editing', 'RNA modification', 'ensemble learning', 'feature selection', 'machine learning']","A-to-I editing is the most prevalent RNA editing event, which refers to the change of adenosine (A) bases to inosine (I) bases in double-stranded RNAs. Several studies have revealed that A-to-I editing can regulate cellular processes and is associated with various human diseases. Therefore, accurate identification of A-to-I editing sites is crucial for understanding RNA-level (i.e. transcriptional) modifications and their potential roles in molecular functions. To date, various computational approaches for A-to-I editing site identification have been developed; however, their performance is still unsatisfactory and needs further improvement. In this study, we developed a novel stacked-ensemble learning model, ATTIC (A-To-I ediTing predICtor), to accurately identify A-to-I editing sites across three species, including Homo sapiens, Mus musculus and Drosophila melanogaster. We first comprehensively evaluated 37 RNA sequence-derived features combined with 14 popular machine learning algorithms. Then, we selected the optimal base models to build a series of stacked ensemble models. The final ATTIC framework was developed based on the optimal models improved by the feature selection strategy for specific species. Extensive cross-validation and independent tests illustrate that ATTIC outperforms state-of-the-art tools for predicting A-to-I editing sites. We also developed a web server for ATTIC, which is publicly available at http://web.unimelb-bioinfortools.cloud.edu.au/ATTIC/. We anticipate that ATTIC can be utilized as a useful tool to accelerate the identification of A-to-I RNA editing events and help characterize their roles in post-transcriptional regulation.",3,A-to-I editing is the most prevalent RNA editing event.
CosTaL: an accurate and scalable graph-based clustering algorithm for high-dimensional single-cell data analysis.,37150778,https://pubmed.ncbi.nlm.nih.gov/37150778/,https://doi.org/10.1093/bib/bbad157,"['Clustering', 'Flow Cytometry', 'Graph-based clustering', 'Mass Cytometry', 'Single-cell RNA sequencing', 'k nearest neighbors']","With the aim of analyzing large-sized multidimensional single-cell datasets, we are describing a method for Cosine-based Tanimoto similarity-refined graph for community detection using Leiden's algorithm (CosTaL). As a graph-based clustering method, CosTaL transforms the cells with high-dimensional features into a weighted k-nearest-neighbor (kNN) graph. The cells are represented by the vertices of the graph, while an edge between two vertices in the graph represents the close relatedness between the two cells. Specifically, CosTaL builds an exact kNN graph using cosine similarity and uses the Tanimoto coefficient as the refining strategy to re-weight the edges in order to improve the effectiveness of clustering. We demonstrate that CosTaL generally achieves equivalent or higher effectiveness scores on seven benchmark cytometry datasets and six single-cell RNA-sequencing datasets using six different evaluation metrics, compared with other state-of-the-art graph-based clustering methods, including PhenoGraph, Scanpy and PARC. As indicated by the combined evaluation metrics, Costal has high efficiency with small datasets and acceptable scalability for large datasets, which is beneficial for large-scale analysis.",2,CosTaL builds an exact kNN graph using cosine similarity and uses the Tanimoto coefficient as the refining strategy to re-weight the edges.
Interaction of the Inhibitory Peptides ShK and HmK with the Voltage-Gated Potassium Channel K,37143234,https://pubmed.ncbi.nlm.nih.gov/37143234/,https://doi.org/10.1021/acs.jcim.2c01237,[],Peptide toxins that adopt the ShK fold can inhibit the voltage-gated potassium channel K,2,Peptide toxins that adopt the ShK fold can inhibit the voltage-gated potassium channel K.
Machine learning-assisted medium optimization revealed the discriminated strategies for improved production of the foreign and native metabolites.,37138901,https://pubmed.ncbi.nlm.nih.gov/37138901/,https://doi.org/10.1016/j.csbj.2023.04.020,"['Aromatic compound', 'Bacterial growth', 'Machine learning', 'Medium', 'Production', 'Synthetic pathway', 'Transcriptome']","The composition of medium components is crucial for achieving the best performance of synthetic construction in genetically engineered cells. Which and how medium components determine the performance, e.g., productivity, remain poorly investigated. To address the questions, a comparative survey with two genetically engineered ",1,The composition of medium components is crucial for achieving the best performance of synthetic construction in genetically engineered cells.
The impact of pathogenic and artificial mutations on Claudin-5 selectivity from molecular dynamics simulations.,37138900,https://pubmed.ncbi.nlm.nih.gov/37138900/,https://doi.org/10.1016/j.csbj.2023.04.001,"['BBB paracellular proteins', 'Claudin-based paracellular models', 'Molecular dynamics', 'Paracellular permeability', 'Protein complexes', 'Structural modeling', 'Tight junctions']","Tight-junctions (TJs) are multi-protein complexes between adjacent endothelial or epithelial cells. In the blood-brain-barrier (BBB), they seal the paracellular space and the Claudin-5 (Cldn5) protein forms their backbone. Despite the fundamental role in brain homeostasis, little is known on Cldn5-based TJ assemblies. Different structural models were suggested, with Cldn5 protomers generating paracellular pores that restrict the passage of ions and small molecules. Recently, the first Cldn5 pathogenic mutation, G60R, was identified and shown to induce Cl",3,TJs are multi-protein complexes between adjacent endothelial or epithelial cells.
MBECS: Microbiome Batch Effects Correction Suite.,37138207,https://pubmed.ncbi.nlm.nih.gov/37138207/,https://doi.org/10.1186/s12859-023-05252-w,"['Batch effects', 'Bioconductor', 'Microbiome', 'R-package', 'phyloseq']","Despite the availability of batch effect correcting algorithms (BECA), no comprehensive tool that combines batch correction and evaluation of the results exists for microbiome datasets. This work outlines the Microbiome Batch Effects Correction Suite development that integrates several BECAs and evaluation metrics into a software package for the statistical computation framework R.",1,Microbiome Batch Effects Correction Suite development that integrates several BECAs and evaluation metrics into a software package for R.
BUSZ: compressed BUS files.,37129540,https://pubmed.ncbi.nlm.nih.gov/37129540/,https://doi.org/10.1093/bioinformatics/btad295,[],"We describe a compression scheme for BUS files and an implementation of the algorithm in the BUStools software. Our compression algorithm yields smaller file sizes than gzip, at significantly faster compression and decompression speeds. We evaluated our algorithm on 533 BUS files from scRNA-seq experiments with a total size of 1TB. Our compression is 2.2× faster than the fastest gzip option 35% slower than the fastest zstd option and results in 1.5× smaller files than both methods. This amounts to an 8.3× reduction in the file size, resulting in a compressed size of 122GB for the dataset.",1,"Our compression algorithm yields smaller file sizes than gzip, at significantly faster compression and decompression speeds."
Faster and more accurate pathogenic combination predictions with VarCoPP2.0.,37127601,https://pubmed.ncbi.nlm.nih.gov/37127601/,https://doi.org/10.1186/s12859-023-05291-3,"['Balanced random forest', 'Oligogenic diseases', 'Pathogenicity predictor', 'Variant combinations']","The prediction of potentially pathogenic variant combinations in patients remains a key task in the field of medical genetics for the understanding and detection of oligogenic/multilocus diseases. Models tailored towards such cases can help shorten the gap of missing diagnoses and can aid researchers in dealing with the high complexity of the derived data. The predictor VarCoPP (Variant Combinations Pathogenicity Predictor) that was published in 2019 and identified potentially pathogenic variant combinations in gene pairs (bilocus variant combinations), was the first important step in this direction. Despite its usefulness and applicability, several issues still remained that hindered a better performance, such as its False Positive (FP) rate, the quality of its training set and its complex architecture.",2,The prediction of potentially pathogenic variant combinations in patients remains a key task in the field of medical genetics for the understanding and detection of oligogenic/multilocus diseases.
Analysis of microbiota-host communication mediated by butyrate in Atlantic salmon.,37122632,https://pubmed.ncbi.nlm.nih.gov/37122632/,https://doi.org/10.1016/j.csbj.2023.03.050,"['Atlantic salmon', 'Butyrate', 'Microbiota']","Butyrate is a microbiota-produced metabolite, sensed by host short-chain fatty acid receptors FFAR2 (Gpr43), FFAR3 (Gpr41), HCAR2 (Gpr109A), and Histone deacetylase (HDAC) that promotes microbiota-host crosstalk. Butyrate influences energy uptake, developmental and immune response in mammals. This microbial metabolite is produced by around 79 anaerobic genera present in the mammalian gut, yet little is known about the role of butyrate in the host-microbiota interaction in salmonid fish. To further our knowledge of this interaction, we analyzed the intestinal microbiota and genome of Atlantic salmon (",2,"Butyrate is a microbiota-produced metabolite, sensed by host short-chain fatty acid receptors. Butyrate influences energy uptake, developmental and immune response in mammals."
Matching single cells across modalities with contrastive learning and optimal transport.,37122067,https://pubmed.ncbi.nlm.nih.gov/37122067/,https://doi.org/10.1093/bib/bbad130,"['contrastive learning', 'modality matching', 'optimal transport', 'single-cell data integration']","Understanding the interactions between the biomolecules that govern cellular behaviors remains an emergent question in biology. Recent advances in single-cell technologies have enabled the simultaneous quantification of multiple biomolecules in the same cell, opening new avenues for understanding cellular complexity and heterogeneity. Still, the resulting multimodal single-cell datasets present unique challenges arising from the high dimensionality and multiple sources of acquisition noise. Computational methods able to match cells across different modalities offer an appealing alternative towards this goal. In this work, we propose MatchCLOT, a novel method for modality matching inspired by recent promising developments in contrastive learning and optimal transport. MatchCLOT uses contrastive learning to learn a common representation between two modalities and applies entropic optimal transport as an approximate maximum weight bipartite matching algorithm. Our model obtains state-of-the-art performance on two curated benchmarking datasets and an independent test dataset, improving the top scoring method by 26.1% while preserving the underlying biological structure of the multimodal data. Importantly, MatchCLOT offers high gains in computational time and memory that, in contrast to existing methods, allows it to scale well with the number of cells. As single-cell datasets become increasingly large, MatchCLOT offers an accurate and efficient solution to the problem of modality matching.",2,MatchCLOT uses contrastive learning to learn a common representation between two modalities and applies entropic optimal transport as an approximate maximum weight bipartite matching algorithm.
A robust phenotype-driven likelihood ratio analysis approach assisting interpretable clinical diagnosis of rare diseases.,37105510,https://pubmed.ncbi.nlm.nih.gov/37105510/,https://doi.org/10.1016/j.jbi.2023.104372,"['Differential diagnosis', 'Likelihood ratio', 'Phenotype', 'Rare diseases', 'Visualization']","Phenotype-based prioritization of candidate genes and diseases has become a well-established approach for multi-omics diagnostics of rare diseases. Most current algorithms exploit semantic analysis and probabilistic statistics based on Human Phenotype Ontology and are commonly superior to naive search methods. However, these algorithms are mostly less interpretable and do not perform well in real clinical scenarios due to noise and imprecision of query terms, and the fact that individuals may not display all phenotypes of the disease they belong to. We present a Phenotype-driven Likelihood Ratio analysis approach (PheLR) assisting interpretable clinical diagnosis of rare diseases. With a likelihood ratio paradigm, PheLR estimates the posterior probability of candidate diseases and how much a phenotypic feature contributes to the prioritization result. Benchmarked using simulated and realistic patients, PheLR shows significant advantages over current approaches and is robust to noise and inaccuracy. To facilitate clinical practice and visualized differential diagnosis, PheLR is implemented as an online web tool (https://phelr.nbscn.org).",1,Phenotype-based prioritization of candidate genes and diseases has become a well-established approach for multi-omics diagnostics of rare diseases.
DGH-GO: dissecting the genetic heterogeneity of complex diseases using gene ontology.,37101154,https://pubmed.ncbi.nlm.nih.gov/37101154/,https://doi.org/10.1186/s12859-023-05290-4,"['Dimension reduction', 'Functionally similarities', 'Gene ontology', 'Genetic heterogeneity', 'Neurodevelopmental disorders', 'Semantic similarity', 'Unsupervised learning']","Complex diseases such as neurodevelopmental disorders (NDDs) exhibit multiple etiologies. The multi-etiological nature of complex-diseases emerges from distinct but functionally similar group of genes. Different diseases sharing genes of such groups show related clinical outcomes that further restrict our understanding of disease mechanisms, thus, limiting the applications of personalized medicine approaches to complex genetic disorders.",1, Complex diseases such as neurodevelopmental disorders (NDDs) exhibit multiple etiologies.
Recent Advances in Assembly of Complex Plant Genomes.,37100237,https://pubmed.ncbi.nlm.nih.gov/37100237/,https://doi.org/10.1016/j.gpb.2023.04.004,"['Assembly algorithm', 'Complex plant genome', 'Haplotype-resolved assembly', 'Sequencing technology', 'Telomere-to-telomere genome']","Over the past 20 years, tremendous advances in sequencing technologies and computational algorithms have spurred plant genomic research into a thriving era with hundreds of genomes decoded already, ranging from those of nonvascular plants to those of flowering plants. However, complex plant genome assembly is still challenging and remains difficult to fully resolve with conventional sequencing and assembly methods due to high heterozygosity, highly repetitive sequences, or high ploidy characteristics of complex genomes. Herein, we summarize the challenges of and advances in complex plant genome assembly, including feasible experimental strategies, upgrades to sequencing technology, existing assembly methods, and different phasing algorithms. Moreover, we list actual cases of complex genome projects for readers to refer to and draw upon to solve future problems related to complex genomes. Finally, we expect that the accurate, gapless, telomere-to-telomere, and fully phased assembly of complex plant genomes could soon become routine.",3, complex plant genome assembly is still challenging and remains difficult to fully resolve with conventional sequencing and assembly methods.
Contextualized medication information extraction using Transformer-based deep learning architectures.,37100106,https://pubmed.ncbi.nlm.nih.gov/37100106/,https://doi.org/10.1016/j.jbi.2023.104370,"['Clinical natural language processing', 'Deep learning', 'Medication information extraction', 'Named entity recognition', 'Text classification']",To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.,1,To develop a natural language processing (NLP) system to extract medications and contextual information.
Benchmarking of analytical combinations for COVID-19 outcome prediction using single-cell RNA sequencing data.,37096588,https://pubmed.ncbi.nlm.nih.gov/37096588/,https://doi.org/10.1093/bib/bbad159,"['COVID-19', 'benchmark', 'disease outcome prediction', 'patient analysis', 'single-cell']","The advances of single-cell transcriptomic technologies have led to increasing use of single-cell RNA sequencing (scRNA-seq) data in large-scale patient cohort studies. The resulting high-dimensional data can be summarized and incorporated into patient outcome prediction models in several ways; however, there is a pressing need to understand the impact of analytical decisions on such model quality. In this study, we evaluate the impact of analytical choices on model choices, ensemble learning strategies and integrate approaches on patient outcome prediction using five scRNA-seq COVID-19 datasets. First, we examine the difference in performance between using single-view feature space versus multi-view feature space. Next, we survey multiple learning platforms from classical machine learning to modern deep learning methods. Lastly, we compare different integration approaches when combining datasets is necessary. Through benchmarking such analytical combinations, our study highlights the power of ensemble learning, consistency among different learning methods and robustness to dataset normalization when using multiple datasets as the model input.",2,The advances of single-cell transcriptomic technologies have led to increasing use of scRNA-seq data in large-scale patient cohort studies.
An automatic immunofluorescence pattern classification framework for HEp-2 image based on supervised learning.,37088980,https://pubmed.ncbi.nlm.nih.gov/37088980/,https://doi.org/10.1093/bib/bbad144,"['HEp-2 image', 'anti-nuclear antibody (ANA)', 'automatic classification', 'immunofluorescence pattern', 'supervised learning']","Immunofluorescence patterns of anti-nuclear antibodies (ANAs) on human epithelial cell (HEp-2) substrates are important biomarkers for the diagnosis of autoimmune diseases. There are growing clinical requirements for an automatic readout and classification of ANA immunofluorescence patterns for HEp-2 images following the taxonomy recommended by the International Consensus on Antinuclear Antibody Patterns (ICAP). In this study, a comprehensive collection of HEp-2 specimen images covering a broad range of ANA patterns was established and manually annotated by experienced laboratory experts. By utilizing a supervised learning methodology, an automatic immunofluorescence pattern classification framework for HEp-2 specimen images was developed. The framework consists of a module for HEp-2 cell detection and cell-level feature extraction, followed by an image-level classifier that is capable of recognizing all 14 classes of ANA immunofluorescence patterns as recommended by ICAP. Performance analysis indicated an accuracy of 92.05% on the validation dataset and 87% on an independent test dataset, which has surpassed the performance of human examiners on the same test dataset. The proposed framework is expected to contribute to the automatic ANA pattern recognition in clinical laboratories to facilitate efficient and precise diagnosis of autoimmune diseases.",1,Immunofluorescence patterns of anti-nuclear antibodies (ANAs) on human epithelial cell (HEp-2) substrates are important biomarkers for the diagnosis of autoimmune
FAS: assessing the similarity between proteins using multi-layered feature architectures.,37084276,https://pubmed.ncbi.nlm.nih.gov/37084276/,https://doi.org/10.1093/bioinformatics/btad226,[],"Protein sequence comparison is a fundamental element in the bioinformatics toolkit. When sequences are annotated with features such as functional domains, transmembrane domains, low complexity regions or secondary structure elements, the resulting feature architectures allow better informed comparisons. However, many existing schemes for scoring architecture similarities cannot cope with features arising from multiple annotation sources. Those that do fall short in the resolution of overlapping and redundant feature annotations.",1,Protein sequence comparison is a fundamental element in the bioinformatics toolkit.
Predicting the pathogenicity of missense variants using features derived from AlphaFold2.,37084271,https://pubmed.ncbi.nlm.nih.gov/37084271/,https://doi.org/10.1093/bioinformatics/btad280,[],"Missense variants are a frequent class of variation within the coding genome, and some of them cause Mendelian diseases. Despite advances in computational prediction, classifying missense variants into pathogenic or benign remains a major challenge in the context of personalized medicine. Recently, the structure of the human proteome was derived with unprecedented accuracy using the artificial intelligence system AlphaFold2. This raises the question of whether AlphaFold2 wild-type structures can improve the accuracy of computational pathogenicity prediction for missense variants.",11,Missense variants are a frequent class of variation within the coding genome. Some of them cause Mendelian diseases.
Validation of genetic variants from NGS data using deep convolutional neural networks.,37081386,https://pubmed.ncbi.nlm.nih.gov/37081386/,https://doi.org/10.1186/s12859-023-05255-7,"['Machine learning', 'Next-generation sequencing', 'Somatic variants']","Accurate somatic variant calling from next-generation sequencing data is one most important tasks in personalised cancer therapy. The sophistication of the available technologies is ever-increasing, yet, manual candidate refinement is still a necessary step in state-of-the-art processing pipelines. This limits reproducibility and introduces a bottleneck with respect to scalability. We demonstrate that the validation of genetic variants can be improved using a machine learning approach resting on a Convolutional Neural Network, trained using existing human annotation. In contrast to existing approaches, we introduce a way in which contextual data from sequencing tracks can be included into the automated assessment. A rigorous evaluation shows that the resulting model is robust and performs on par with trained researchers following published standard operating procedure.",1,  manual candidate refinement is still a necessary step in state-of-the-art processing pipelines.
Using traditional machine learning and deep learning methods for on- and off-target prediction in CRISPR/Cas9: a review.,37080758,https://pubmed.ncbi.nlm.nih.gov/37080758/,https://doi.org/10.1093/bib/bbad131,"['CRISPR-Cas9', 'Deep Learning', 'Genome Editing', 'Machine Learning', 'Off-Targets', 'On-Targets']","CRISPR/Cas9 (Clustered Regularly Interspaced Short Palindromic Repeats and CRISPR-associated protein 9) is a popular and effective two-component technology used for targeted genetic manipulation. It is currently the most versatile and accurate method of gene and genome editing, which benefits from a large variety of practical applications. For example, in biomedicine, it has been used in research related to cancer, virus infections, pathogen detection, and genetic diseases. Current CRISPR/Cas9 research is based on data-driven models for on- and off-target prediction as a cleavage may occur at non-target sequence locations. Nowadays, conventional machine learning and deep learning methods are applied on a regular basis to accurately predict on-target knockout efficacy and off-target profile of given single-guide RNAs (sgRNAs). In this paper, we present an overview and a comparative analysis of traditional machine learning and deep learning models used in CRISPR/Cas9. We highlight the key research challenges and directions associated with target activity prediction. We discuss recent advances in the sgRNA-DNA sequence encoding used in state-of-the-art on- and off-target prediction models. Furthermore, we present the most popular deep learning neural network architectures used in CRISPR/Cas9 prediction models. Finally, we summarize the existing challenges and discuss possible future investigations in the field of on- and off-target prediction. Our paper provides valuable support for academic and industrial researchers interested in the application of machine learning methods in the field of CRISPR/Cas9 genome editing.",3,CRISPR/Cas9 is the most versatile and accurate method of gene and genome editing.
Decoding CRISPR-Cas PAM recognition with UniDesign.,37078688,https://pubmed.ncbi.nlm.nih.gov/37078688/,https://doi.org/10.1093/bib/bbad133,"['CRISPR–Cas', 'PAM', 'UniDesign', 'computational protein design', 'gene editing']","The critical first step in Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)-associated (CRISPR-Cas) protein-mediated gene editing is recognizing a preferred protospacer adjacent motif (PAM) on target DNAs by the protein's PAM-interacting amino acids (PIAAs). Thus, accurate computational modeling of PAM recognition is useful in assisting CRISPR-Cas engineering to relax or tighten PAM requirements for subsequent applications. Here, we describe a universal computational protein design framework (UniDesign) for designing protein-nucleic acid interactions. As a proof of concept, we applied UniDesign to decode the PAM-PIAA interactions for eight Cas9 and two Cas12a proteins. We show that, given native PIAAs, the UniDesign-predicted PAMs are largely identical to the natural PAMs of all Cas proteins. In turn, given natural PAMs, the computationally redesigned PIAA residues largely recapitulated the native PIAAs (74% and 86% in terms of identity and similarity, respectively). These results demonstrate that UniDesign faithfully captures the mutual preference between natural PAMs and native PIAAs, suggesting it is a useful tool for engineering CRISPR-Cas and other nucleic acid-interacting proteins. UniDesign is open-sourced at https://github.com/tommyhuangthu/UniDesign.",1,UniDesign is a universal computational protein design framework for designing protein-nucleic acid interactions.
"Machine learning in metastatic cancer research: Potentials, possibilities, and prospects.",37077177,https://pubmed.ncbi.nlm.nih.gov/37077177/,https://doi.org/10.1016/j.csbj.2023.03.046,"['Cancer metastasis', 'Data inequality', 'Deep learning', 'Early detection', 'Machine learning', 'Metastatic cancer']","Cancer has received extensive recognition for its high mortality rate, with metastatic cancer being the top cause of cancer-related deaths. Metastatic cancer involves the spread of the primary tumor to other body organs. As much as the early detection of cancer is essential, the timely detection of metastasis, the identification of biomarkers, and treatment choice are valuable for improving the quality of life for metastatic cancer patients. This study reviews the existing studies on classical machine learning (ML) and deep learning (DL) in metastatic cancer research. Since the majority of metastatic cancer research data are collected in the formats of PET/CT and MRI image data, deep learning techniques are heavily involved. However, its black-box nature and expensive computational cost are notable concerns. Furthermore, existing models could be overestimated for their generality due to the non-diverse population in clinical trial datasets. Therefore, research gaps are itemized; follow-up studies should be carried out on metastatic cancer using machine learning and deep learning tools with data in a symmetric manner.",1,Metastatic cancer involves the spread of the primary tumor to other body organs.
Large-Scale Docking in the Cloud.,37071086,https://pubmed.ncbi.nlm.nih.gov/37071086/,https://doi.org/10.1021/acs.jcim.3c00031,[],"Molecular docking is a pragmatic approach to exploit protein structures for new ligand discovery, but the growing size of available chemical space is increasingly challenging to screen on in-house computer clusters. We have therefore developed AWS-DOCK, a protocol for running UCSF DOCK in the AWS cloud. Our approach leverages the low cost and scalability of cloud resources combined with a low-molecule-cost docking engine to screen billions of molecules efficiently. We benchmarked our system by screening 50 million HAC 22 molecules against the DRD4 receptor with an average CPU time of around 1 s per molecule. We saw up to 3-fold variations in cost between AWS availability zones. Docking 4.5 billion lead-like molecules, a 7 week calculation on our 1000-core lab cluster, runs in about a week depending on accessible CPUs, in AWS for around $25,000, less than the cost of two new nodes. The cloud docking protocol is described in easy-to-follow steps and may be sufficiently general to be used for other docking programs. All the tools to enable AWS-DOCK are available free to everyone, while DOCK 3.8 is free for academic research.",2,AWS-DOCK is a protocol for running UCSF DOCK in the AWS cloud.
Exploring QSAR models for activity-cliff prediction.,37069675,https://pubmed.ncbi.nlm.nih.gov/37069675/,https://doi.org/10.1186/s13321-023-00708-w,"['Activity cliff prediction', 'Activity cliffs', 'Binding affinity prediction', 'Deep learning', 'Extended-connectivity fingerprints', 'Graph isomorphism networks', 'Machine learning', 'Molecular representation', 'Physicochemical descriptors', 'QSAR modelling']","Pairs of similar compounds that only differ by a small structural modification but exhibit a large difference in their binding affinity for a given target are known as activity cliffs (ACs). It has been hypothesised that QSAR models struggle to predict ACs and that ACs thus form a major source of prediction error. However, the AC-prediction power of modern QSAR methods and its quantitative relationship to general QSAR-prediction performance is still underexplored. We systematically construct nine distinct QSAR models by combining three molecular representation methods (extended-connectivity fingerprints, physicochemical-descriptor vectors and graph isomorphism networks) with three regression techniques (random forests, k-nearest neighbours and multilayer perceptrons); we then use each resulting model to classify pairs of similar compounds as ACs or non-ACs and to predict the activities of individual molecules in three case studies: dopamine receptor D2, factor Xa, and SARS-CoV-2 main protease.",1,Pairs of similar compounds that only differ by a small structural modification but exhibit a large difference in their binding affinity for a given target are known as activity cliffs (ACs)
Biomedical data analyses facilitated by open cheminformatics workflows.,37069670,https://pubmed.ncbi.nlm.nih.gov/37069670/,https://doi.org/10.1186/s13321-023-00718-8,[],,1,
Recurrent predictive coding models for associative memory employing covariance learning.,37058541,https://pubmed.ncbi.nlm.nih.gov/37058541/,https://doi.org/10.1371/journal.pcbi.1010719,[],"The computational principles adopted by the hippocampus in associative memory (AM) tasks have been one of the most studied topics in computational and theoretical neuroscience. Recent theories suggested that AM and the predictive activities of the hippocampus could be described within a unitary account, and that predictive coding underlies the computations supporting AM in the hippocampus. Following this theory, a computational model based on classical hierarchical predictive networks was proposed and was shown to perform well in various AM tasks. However, this fully hierarchical model did not incorporate recurrent connections, an architectural component of the CA3 region of the hippocampus that is crucial for AM. This makes the structure of the model inconsistent with the known connectivity of CA3 and classical recurrent models such as Hopfield Networks, which learn the covariance of inputs through their recurrent connections to perform AM. Earlier PC models that learn the covariance information of inputs explicitly via recurrent connections seem to be a solution to these issues. Here, we show that although these models can perform AM, they do it in an implausible and numerically unstable way. Instead, we propose alternatives to these earlier covariance-learning predictive coding networks, which learn the covariance information implicitly and plausibly, and can use dendritic structures to encode prediction errors. We show analytically that our proposed models are perfectly equivalent to the earlier predictive coding model learning covariance explicitly, and encounter no numerical issues when performing AM tasks in practice. We further show that our models can be combined with hierarchical predictive coding networks to model the hippocampo-neocortical interactions. Our models provide a biologically plausible approach to modelling the hippocampal network, pointing to a potential computational mechanism during hippocampal memory formation and recall, which employs both predictive coding and covariance learning based on the recurrent network structure of the hippocampus.",3,The computational principles adopted by the hippocampus in associative memory (AM) tasks have been one of the most studied topics in computational and theoretical neuroscience.
Investigation of chemical structure recognition by encoder-decoder models in learning progress.,37046349,https://pubmed.ncbi.nlm.nih.gov/37046349/,https://doi.org/10.1186/s13321-023-00713-z,"['Descriptor', 'Encoder–decoder model']","Descriptor generation methods using latent representations of encoder-decoder (ED) models with SMILES as input are useful because of the continuity of descriptor and restorability to the structure. However, it is not clear how the structure is recognized in the learning progress of ED models. In this work, we created ED models of various learning progress and investigated the relationship between structural information and learning progress. We showed that compound substructures were learned early in ED models by monitoring the accuracy of downstream tasks and input-output substructure similarity using substructure-based descriptors, which suggests that existing evaluation methods based on the accuracy of downstream tasks may not be sensitive enough to evaluate the performance of ED models with SMILES as descriptor generation methods. On the other hand, we showed that structure restoration was time-consuming, and in particular, insufficient learning led to the estimation of a larger structure than the actual one. It can be inferred that determining the endpoint of the structure is a difficult task for the model. To our knowledge, this is the first study to link the learning progress of SMILES by ED model to chemical structures for a wide range of chemicals.",3,Descriptor generation methods using latent representations of encoder-decoder (ED) models with SMILES as input are useful because of the continuity of descriptor and restorability
"nRCFV: a new, dataset-size-independent metric to quantify compositional heterogeneity in nucleotide and amino acid datasets.",37046225,https://pubmed.ncbi.nlm.nih.gov/37046225/,https://doi.org/10.1186/s12859-023-05270-8,"['Bioinformatics software', 'Compositional heterogeneity', 'Phylogenetics']","Compositional heterogeneity-when the proportions of nucleotides and amino acids are not broadly similar across the dataset-is a cause of a great number of phylogenetic artefacts. Whilst a variety of methods can identify it post-hoc, few metrics exist to quantify compositional heterogeneity prior to the computationally intensive task of phylogenetic tree reconstruction. Here we assess the efficacy of one such existing, widely used, metric: Relative Composition Frequency Variability (RCFV), using both real and simulated data.",5,Compositional heterogeneity is when proportions of nucleotides and amino acids are not broadly similar across the dataset.
Accurate flux predictions using tissue-specific gene expression in plant metabolic modeling.,37040081,https://pubmed.ncbi.nlm.nih.gov/37040081/,https://doi.org/10.1093/bioinformatics/btad186,[],"The accurate prediction of complex phenotypes such as metabolic fluxes in living systems is a grand challenge for systems biology and central to efficiently identifying biotechnological interventions that can address pressing industrial needs. The application of gene expression data to improve the accuracy of metabolic flux predictions using mechanistic modeling methods such as flux balance analysis (FBA) has not been previously demonstrated in multi-tissue systems, despite their biotechnological importance. We hypothesized that a method for generating metabolic flux predictions informed by relative expression levels between tissues would improve prediction accuracy.",4,The accurate prediction of complex phenotypes is a grand challenge for systems biology.
On Ternary Complex Stability in Protein Degradation: In Silico Molecular Glue Binding Affinity Calculations.,37037192,https://pubmed.ncbi.nlm.nih.gov/37037192/,https://doi.org/10.1021/acs.jcim.2c01386,[],"Molecular glues are small molecules that simultaneously bind to two proteins, creating a chemically induced protein-protein interface. CELMoDs (cereblon E3 ligase modulators) are a class of molecular glues that promote recruitment of neosubstrate proteins to the E3 ubiquitin ligase cereblon (CRBN) for poly-Lys48-ubiquitination and proteasomal degradation. Ternary complex structures of clinical CELMoDs CC-885 and CC-90009 bound to CRBN and neosubstrate G1 to S phase transition protein 1 (GSPT1) have been experimentally determined. Although cellular degradation is a downstream event, dependent not only on the affinity of the glue CELMoD in the ternary complex, we test the applicability of established structure-based drug design principles to predict binding affinity of CELMoDs to the protein-protein neointerface and correlation to measured cellular degradation for the neosubstrates GSPT1 and zinc finger Aiolos (IKZF3). For a congeneric series of CELMoDs, which have a similar sequence of binding events and resultant binding modes, we conclude that well-established structure-based methods that measure in silico ternary complex stabilities can predict relative degradation potency by CELMoDs.",1,"Molecular glues are small molecules that simultaneously bind to two proteins, creating a chemically induced protein-protein interface."
Prediction of Thermogravimetric Data in Bromine Captured from Brominated Flame Retardants (BFRs) in e-Waste Treatment Using Machine Learning Approaches.,37036888,https://pubmed.ncbi.nlm.nih.gov/37036888/,https://doi.org/10.1021/acs.jcim.3c00183,[],The principal objective in the treatment of e-waste is to capture the bromine released from the brominated flame retardants (BFRs) added to the polymeric constituents of printed circuits boards (PCBs) and to produce pure bromine-free hydrocarbons. Metal oxides such as calcium hydroxide (Ca(OH),1,The principal objective in the treatment of e-waste is to capture the bromine released from brominated flame retardants.
In-silico EEG biomarkers of reduced inhibition in human cortical microcircuits in depression.,37036854,https://pubmed.ncbi.nlm.nih.gov/37036854/,https://doi.org/10.1371/journal.pcbi.1010986,[],"Reduced cortical inhibition by somatostatin-expressing (SST) interneurons has been strongly associated with treatment-resistant depression. However, due to technical limitations it is impossible to establish experimentally in humans whether the effects of reduced SST interneuron inhibition on microcircuit activity have signatures detectable in clinically-relevant brain signals such as electroencephalography (EEG). To overcome these limitations, we simulated resting-state activity and EEG using detailed models of human cortical microcircuits with normal (healthy) or reduced SST interneuron inhibition (depression), and found that depression microcircuits exhibited increased theta, alpha and low beta power (4-16 Hz). The changes in depression involved a combination of an aperiodic broadband and periodic theta components. We then demonstrated the specificity of the EEG signatures of reduced SST interneuron inhibition by showing they were distinct from those corresponding to reduced parvalbumin-expressing (PV) interneuron inhibition. Our study thus links SST interneuron inhibition level to distinct features in EEG simulated from detailed human microcircuits, which can serve to better identify mechanistic subtypes of depression using EEG, and non-invasively monitor modulation of cortical inhibition.",5, reduced cortical inhibition by somatostatin-expressing (SST) interneurons has been strongly associated with treatment-resistant depression.
Machine learning for synergistic network pharmacology: a comprehensive overview.,37031957,https://pubmed.ncbi.nlm.nih.gov/37031957/,https://doi.org/10.1093/bib/bbad120,"['artificial intelligence', 'deep learning', 'drug discovery', 'machine learning', 'network pharmacology']","Network pharmacology is an emerging area of systematic drug research that attempts to understand drug actions and interactions with multiple targets. Network pharmacology has changed the paradigm from 'one-target one-drug' to highly potent 'multi-target drug'. Despite that, this synergistic approach is currently facing many challenges particularly mining effective information such as drug targets, mechanism of action, and drug and organism interaction from massive, heterogeneous data. To overcome bottlenecks in multi-target drug discovery, computational algorithms are highly welcomed by scientific community. Machine learning (ML) and especially its subfield deep learning (DL) have seen impressive advances. Techniques developed within these fields are now able to analyze and learn from huge amounts of data in disparate formats. In terms of network pharmacology, ML can improve discovery and decision making from big data. Opportunities to apply ML occur in all stages of network pharmacology research. Examples include screening of biologically active small molecules, target identification, metabolic pathways identification, protein-protein interaction network analysis, hub gene analysis and finding binding affinity between compounds and target proteins. This review summarizes the premier algorithmic concepts of ML in network pharmacology and forecasts future opportunities, potential applications as well as several remaining challenges of implementing ML in network pharmacology. To our knowledge, this study provides the first comprehensive assessment of ML approaches in network pharmacology, and we hope that it encourages additional efforts toward the development and acceptance of network pharmacology in the pharmaceutical industry.",9,Network pharmacology is an emerging area of systematic drug research that attempts to understand drug actions and interactions with multiple targets.
High-Density Electroencephalography and Speech Signal Based Deep Framework for Clinical Depression Diagnosis.,37028339,https://pubmed.ncbi.nlm.nih.gov/37028339/,https://doi.org/10.1109/TCBB.2023.3257175,[],"Depression is a mental disorder characterized by persistent depressed mood or loss of interest in performing activities, causing significant impairment in daily routine. Possible causes include psychological, biological, and social sources of distress. Clinical depression is the more-severe form of depression, also known as major depression or major depressive disorder. Recently, electroencephalography and speech signals have been used for early diagnosis of depression; however, they focus on moderate or severe depression. We have combined audio spectrogram and multiple frequencies of EEG signals to improve diagnostic performance. To do so, we have fused different levels of speech and EEG features to generate descriptive features and applied vision transformers and various pre-trained networks on the speech and EEG spectrum. We have conducted extensive experiments on Multimodal Open Dataset for Mental-disorder Analysis (MODMA) dataset, which showed significant improvement in performance in depression diagnosis (0.972, 0.973 and 0.973 precision, recall and F1 score respectively) for patients at the mild stage. Besides, we provided a web-based framework using Flask and provided the source code publicly.",2, Depression is a mental disorder characterized by persistent depressed mood or loss of interest in performing activities. Electroencephalography and speech signals have been used for early diagnosis of depression.
SGDA: Towards 3D Universal Pulmonary Nodule Detection via Slice Grouped Domain Attention.,37028322,https://pubmed.ncbi.nlm.nih.gov/37028322/,https://doi.org/10.1109/TCBB.2023.3253713,[],"Lung cancer is the leading cause of cancer death worldwide. The best solution for lung cancer is to diagnose the pulmonary nodules in the early stage, which is usually accomplished with the aid of thoracic computed tomography (CT). As deep learning thrives, convolutional neural networks (CNNs) have been introduced into pulmonary nodule detection to help doctors in this labor-intensive task and demonstrated to be very effective. However, the current pulmonary nodule detection methods are usually domain-specific, and cannot satisfy the requirement of working in diverse real-world scenarios. To address this issue, we propose a slice grouped domain attention (SGDA) module to enhance the generalization capability of the pulmonary nodule detection networks. This attention module works in the axial, coronal, and sagittal directions. In each direction, we divide the input feature into groups, and for each group, we utilize a universal adapter bank to capture the feature subspaces of the domains spanned by all pulmonary nodule datasets. Then the bank outputs are combined from the perspective of domain to modulate the input group. Extensive experiments demonstrate that SGDA enables substantially better multi-domain pulmonary nodule detection performance compared with the state-of-the-art multi-domain learning methods.",1,Lung cancer is the leading cause of cancer death worldwide. The best solution for lung cancer is to diagnose the pulmonary nodules in the early stage.
Comparison of Methods for Biological Sequence Clustering.,37028305,https://pubmed.ncbi.nlm.nih.gov/37028305/,https://doi.org/10.1109/TCBB.2023.3253138,[],"Recent advances in sequencing technology have considerably promoted genomics research by providing high-throughput sequencing economically. This great advancement has resulted in a huge amount of sequencing data. Clustering analysis is powerful to study and probe the large-scale sequence data. A number of available clustering methods have been developed in the last decade. Despite numerous comparison studies being published, we noticed that they have two main limitations: only traditional alignment-based clustering methods are compared and the evaluation metrics heavily rely on labeled sequence data. In this study, we present a comprehensive benchmark study for sequence clustering methods. Specifically, i) alignment-based clustering algorithms including classical (e.g., CD-HIT, UCLUST, VSEARCH) and recently proposed methods (e.g., MMseq2, Linclust, edClust) are assessed; ii) two alignment-free methods (e.g., LZW-Kernel and Mash) are included to compare with alignment-based methods; and iii) different evaluation measures based on the true labels (supervised metrics) and the input data itself (unsupervised metrics) are applied to quantify their clustering results. The aims of this study are to help biological analyzers in choosing one reasonable clustering algorithm for processing their collected sequences, and furthermore, motivate algorithm designers to develop more efficient sequence clustering approaches.",1,Clustering analysis is powerful to study and probe the large-scale sequence data. A number of available clustering methods have been developed in the last decade.
Microbe-Disease Association Prediction Using RGCN Through Microbe-Drug-Disease Network.,37027603,https://pubmed.ncbi.nlm.nih.gov/37027603/,https://doi.org/10.1109/TCBB.2023.3247035,[],"Accumulating evidence has shown that microbes play significant roles in human health and diseases. Therefore, identifying microbe-disease associations is conducive to disease prevention. In this article, a predictive method called TNRGCN is designed for microbe-disease associations based on Microbe-Drug-Disease Network and Relation Graph Convolutional Network (RGCN). First, considering that indirect links between microbes and diseases will be increased by introducing drug related associations, we construct a Microbe-Drug-Disease tripartite network through data processing from four databases including Human Microbe-Disease Association Database (HMDAD), Disbiome Database, Microbe-Drug Association Database (MDAD) and Comparative Toxicoge-nomics Database (CTD). Second, we construct similarity networks for microbes, diseases and drugs via microbe function similarity, disease semantic similarity and Gaussian interaction profile kernel similarity, respectively. Based on the similarity networks, Principal Component Analysis (PCA) is utilized to extract main features of nodes. These features will be input into the RGCN as initial features. Finally, based on the tripartite network and initial features, we design two-layer RGCN to predict microbe-disease associations. Experimental results indicate that TNRGCN achieves best performance in cross validation compared with other methods. Meanwhile, case studies for Type 2 diabetes (T2D), Bipolar disorder and Autism demonstrate the favorable effectiveness of TNRGCN in association prediction.",3,Accumulating evidence has shown that microbes play significant roles in human health and diseases. Identifying microbe-disease associations is conducive to disease prevention.
Delayed skeletal muscle repair following inflammatory damage in simulated agent-based models of muscle regeneration.,37023170,https://pubmed.ncbi.nlm.nih.gov/37023170/,https://doi.org/10.1371/journal.pcbi.1011042,[],"Healthy skeletal muscle undergoes repair in response to mechanically localised strains during activities such as exercise. The ability of cells to transduce the external stimuli into a cascade of cell signalling responses is important to the process of muscle repair and regeneration. In chronic myopathies such as Duchenne muscular dystrophy and inflammatory myopathies, muscle is often subject to chronic necrosis and inflammation that perturbs tissue homeostasis and leads to non-localised, widespread damage across the tissue. Here we present an agent-based model that simulates muscle repair in response to both localised eccentric contractions similar to what would be experienced during exercise, and non-localised widespread inflammatory damage that is present in chronic disease. Computational modelling of muscle repair allows for in silico exploration of phenomena related to muscle disease. In our model, widespread inflammation led to delayed clearance of tissue damage, and delayed repair for recovery of initial fibril counts at all damage levels. Macrophage recruitment was delayed and significantly higher in widespread compared to localised damage. At higher damage percentages of 10%, widespread damage led to impaired muscle regeneration and changes in muscle geometry that represented alterations commonly observed in chronic myopathies, such as fibrosis. This computational work offers insight into the progression and aetiology of inflammatory muscle diseases, and suggests a focus on the muscle regeneration cascade in understanding the progression of muscle damage in inflammatory myopathies.",2,Computational modelling of muscle repair allows for in silico exploration of phenomena related to muscle disease.
Pleiotropy promotes the evolution of inducible immune responses in a model of host-pathogen coevolution.,37022993,https://pubmed.ncbi.nlm.nih.gov/37022993/,https://doi.org/10.1371/journal.pcbi.1010445,[],"Components of immune systems face significant selective pressure to efficiently use organismal resources, mitigate infection, and resist parasitic manipulation. A theoretically optimal immune defense balances investment in constitutive and inducible immune components depending on the kinds of parasites encountered, but genetic and dynamic constraints can force deviation away from theoretical optima. One such potential constraint is pleiotropy, the phenomenon where a single gene affects multiple phenotypes. Although pleiotropy can prevent or dramatically slow adaptive evolution, it is prevalent in the signaling networks that compose metazoan immune systems. We hypothesized that pleiotropy is maintained in immune signaling networks despite slowed adaptive evolution because it provides some other advantage, such as forcing network evolution to compensate in ways that increase host fitness during infection. To study the effects of pleiotropy on the evolution of immune signaling networks, we used an agent-based modeling approach to evolve a population of host immune systems infected by simultaneously co-evolving parasites. Four kinds of pleiotropic restrictions on evolvability were incorporated into the networks, and their evolutionary outcomes were compared to, and competed against, non-pleiotropic networks. As the networks evolved, we tracked several metrics of immune network complexity, relative investment in inducible and constitutive defenses, and features associated with the winners and losers of competitive simulations. Our results suggest non-pleiotropic networks evolve to deploy highly constitutive immune responses regardless of parasite prevalence, but some implementations of pleiotropy favor the evolution of highly inducible immunity. These inducible pleiotropic networks are no less fit than non-pleiotropic networks and can out-compete non-pleiotropic networks in competitive simulations. These provide a theoretical explanation for the prevalence of pleiotropic genes in immune systems and highlight a mechanism that could facilitate the evolution of inducible immune responses.",1,The authors say pleiotropy is prevalent in the signaling networks that compose metazoan immune systems.
Recent progress toward understanding the role of ZIP14 in regulating systemic manganese homeostasis.,37020930,https://pubmed.ncbi.nlm.nih.gov/37020930/,https://doi.org/10.1016/j.csbj.2023.03.039,"['Manganese', 'Nutrition', 'SLC39A14', 'ZIP14']","ZIP14 is a metal transporter essential for the regulation of body manganese homeostasis. The physiological functions of ZIP14 have been uncovered mainly through two lines of in vivo studies that examined the phenotypes of ZIP14 loss, including studies of humans with ",1,ZIP14 is a metal transporter essential for the regulation of body manganese homeostasis.
Knowledge Adaptive Multi-Way Matching Network for Biomedical Named Entity Recognition via Machine Reading Comprehension.,37018273,https://pubmed.ncbi.nlm.nih.gov/37018273/,https://doi.org/10.1109/TCBB.2022.3233856,[],"Rapid and effective utilization of biomedical literature is paramount to combat diseases like COVID19. Biomedical named entity recognition (BioNER) is a fundamental task in text mining that can help physicians accelerate knowledge discovery to curb the spread of the COVID-19 epidemic. Recent approaches have shown that casting entity extraction as the machine reading comprehension task can significantly improve model performance. However, two major drawbacks impede higher success in identifying entities (1) ignoring the use of domain knowledge to capture the context beyond sentences and (2) lacking the ability to deeper understand the intent of questions. In this paper, to remedy this, we introduce and explore external domain knowledge which cannot be implicitly learned in text sequence. Previous works have focused more on text sequence and explored little of the domain knowledge. To better incorporate domain knowledge, a multi-way matching reader mechanism is devised to model representations of interaction between sequence, question and knowledge retrieved from Unified Medical Language System (UMLS). Benefiting from these, our model can better understand the intent of questions in complex contexts. Experimental results indicate that incorporating domain knowledge can help to obtain competitive results across 10 BioNER datasets, achieving absolute improvement of up to 2.02% in the f1 score.",1,Rapid and effective utilization of biomedical literature is paramount to combat diseases like COVID19.
ICOR: improving codon optimization with recurrent neural networks.,37016283,https://pubmed.ncbi.nlm.nih.gov/37016283/,https://doi.org/10.1186/s12859-023-05246-8,"['Codon optimization', 'Genetic design', 'Machine learning', 'Synthetic biology']","In protein sequences-as there are 61 sense codons but only 20 standard amino acids-most amino acids are encoded by more than one codon. Although such synonymous codons do not alter the encoded amino acid sequence, their selection can dramatically affect the expression of the resulting protein. Codon optimization of synthetic DNA sequences is important for heterologous expression. However, existing solutions are primarily based on choosing high-frequency codons only, neglecting the important effects of rare codons. In this paper, we propose a novel recurrent-neural-network based codon optimization tool, ICOR, that aims to learn codon usage bias on a genomic dataset of Escherichia coli. We compile a dataset of over 7,000 non-redundant, high-expression, robust genes which are used for deep learning. The model uses a bidirectional long short-term memory-based architecture, allowing for the sequential context of codon usage in genes to be learned. Our tool can predict synonymous codons for synthetic genes toward optimal expression in Escherichia coli.",3,Most amino acids are encoded by more than one codon.
ChemGAPP: a tool for chemical genomics analysis and phenotypic profiling.,37014365,https://pubmed.ncbi.nlm.nih.gov/37014365/,https://doi.org/10.1093/bioinformatics/btad171,[],"High-throughput chemical genomic screens produce informative datasets, providing valuable insights into unknown gene function on a genome-wide level. However, there is currently no comprehensive analytic package publicly available. We developed ChemGAPP to bridge this gap. ChemGAPP integrates various steps in a streamlined and user-friendly format, including rigorous quality control measures to curate screening data.",1, ChemGAPP integrates various steps in a streamlined and user-friendly format.
AGAT-PPIS: a novel protein-protein interaction site predictor based on augmented graph attention network with initial residual and identity mapping.,37013942,https://pubmed.ncbi.nlm.nih.gov/37013942/,https://doi.org/10.1093/bib/bbad122,"['deep learning', 'graph neural network', 'initial residual and identity mapping', 'protein–protein interaction site prediction']","Identifying protein-protein interaction (PPI) site is an important step in understanding biological activity, apprehending pathological mechanism and designing novel drugs. Developing reliable computational methods for predicting PPI site as screening tools contributes to reduce lots of time and expensive costs for conventional experiments, but how to improve the accuracy is still challenging. We propose a PPI site predictor, called Augmented Graph Attention Network Protein-Protein Interacting Site (AGAT-PPIS), based on AGAT with initial residual and identity mapping, in which eight AGAT layers are connected to mine node embedding representation deeply. AGAT is our augmented version of graph attention network, with added edge features. Besides, extra node features and edge features are introduced to provide more structural information and increase the translation and rotation invariance of the model. On the benchmark test set, AGAT-PPIS significantly surpasses the state-of-the-art method by 8% in Accuracy, 17.1% in Precision, 11.8% in F1-score, 15.1% in Matthews Correlation Coefficient (MCC), 8.1% in Area Under the Receiver Operating Characteristic curve (AUROC), 14.5% in Area Under the Precision-Recall curve (AUPRC), respectively.",2,Identifying protein-protein interaction (PPI) site is an important step in understanding biological activity.
A data-driven group emergency decision-making method based on interval-valued intuitionistic hesitant fuzzy sets and its application in COVID-19 pandemic.,37009545,https://pubmed.ncbi.nlm.nih.gov/37009545/,https://doi.org/10.1016/j.asoc.2023.110213,"['Bonferroni mean operator', 'Corona Virus Disease 2019', 'Group emergency decision making', 'Interval-valued intuitionistic hesitant fuzzy set', 'TF–IDF algorithm']","The outbreak of Corona Virus Disease 2019 (COVID-19) makes people more concerned about the validity and timeliness of emergency decision making. When an emergency occurs, it is difficult for decision makers (DMs) to give accurate assessment information in the early stage due to the urgency of time, the incompleteness of information, and the limitations of DMs' cognition and knowledge. Hence, we use interval-valued intuitionistic hesitant fuzzy sets rather than exact numbers to better characterize the fuzziness and uncertainty of emergencies. In addition, the Internet has become a major platform for the public to express their opinions or concerns, so we can collect the user-generated content on social media to help DMs determine appropriate emergency decision-making criteria which are the premise and basis of scientific decisions. However, there is likely to be some correlation between the obtained criteria. To this end, we first extend the Bonferroni mean (BM) operator to the interval-valued intuitionistic hesitant fuzzy environment, and propose three interval-valued intuitionistic hesitant fuzzy BM operators to capture the interrelation of fuzzy input variables, including an interval-valued intuitionistic hesitant fuzzy BM operator, a simplified interval-valued intuitionistic hesitant fuzzy BM operator, and a simplified interval-valued intuitionistic hesitant fuzzy weighted BM (SIVIHFWBM) operator. Then, a new group emergency decision-making method based on the SIVIHFWBM operator and social media data is proposed, and the specific steps of ranking all emergency plans are put forward. Moreover, our method is applied to evaluate emergency plans for the prevention and control of COVID-19. Finally, the effectiveness and feasibility of the method are verified by the sensitivity analysis, validity test, and comparative analysis.",1,The outbreak of Corona Virus Disease 2019 (COVID-19) makes people more concerned about the validity and timeliness of emergency decision making.
Benchmarking the Drude Polarizable Force Field Using the r(GACC) Tetranucleotide.,36996447,https://pubmed.ncbi.nlm.nih.gov/36996447/,https://doi.org/10.1021/acs.jcim.3c00250,[],"Polarizable force fields, in particular, the Drude polarizable force field (Drude FF), may hold the key to more accurately modeling biomolecules with molecular dynamics simulations by explicitly accounting for atomic polarizability. Previous work has shown promising results in simulating duplex nucleic acids and protein structures with excellent agreement with experimental values. However, benchmarking the Drude polarizable force field with highly flexible, single-stranded structures has yet to be achieved. In this work, the r(GACC) tetranucleotide is simulated over a multimicrosecond time scale, starting with various different initial conformations. Despite the starting conformation, including starting from the expected dominant A-form major conformation, the experimental structural distribution is not matched. In fact, the major NMR conformation is never resampled. Instead, the r(GACC) tetranucleotide becomes stabilized in anomalous structures that are inconsistent with the NMR data and that favor base-pairing and electrostatic interactions over base stacking. These structures are maintained for lengthy time scales (>1 μs) themselves, suggesting a misbalance of forces in the Drude polarizable force field itself. This model system is suggestive of the fact that currently the Drude polarizable force field does not appear to produce the sensitive balance of forces required to accurately model other single-stranded or noncanonical RNA structures.",1,"Polarizable force fields, in particular, the Drude polarizable force field (Drude FF), may hold the key to more accurately modeling biomolecules with molecular dynamics simulations."
"Network models of protein phosphorylation, acetylation, and ubiquitination connect metabolic and cell signaling pathways in lung cancer.",36996232,https://pubmed.ncbi.nlm.nih.gov/36996232/,https://doi.org/10.1371/journal.pcbi.1010690,[],"We analyzed large-scale post-translational modification (PTM) data to outline cell signaling pathways affected by tyrosine kinase inhibitors (TKIs) in ten lung cancer cell lines. Tyrosine phosphorylated, lysine ubiquitinated, and lysine acetylated proteins were concomitantly identified using sequential enrichment of post translational modification (SEPTM) proteomics. Machine learning was used to identify PTM clusters that represent functional modules that respond to TKIs. To model lung cancer signaling at the protein level, PTM clusters were used to create a co-cluster correlation network (CCCN) and select protein-protein interactions (PPIs) from a large network of curated PPIs to create a cluster-filtered network (CFN). Next, we constructed a Pathway Crosstalk Network (PCN) by connecting pathways from NCATS BioPlanet whose member proteins have PTMs that co-cluster. Interrogating the CCCN, CFN, and PCN individually and in combination yields insights into the response of lung cancer cells to TKIs. We highlight examples where cell signaling pathways involving EGFR and ALK exhibit crosstalk with BioPlanet pathways: Transmembrane transport of small molecules; and Glycolysis and gluconeogenesis. These data identify known and previously unappreciated connections between receptor tyrosine kinase (RTK) signal transduction and oncogenic metabolic reprogramming in lung cancer. Comparison to a CFN generated from a previous multi-PTM analysis of lung cancer cell lines reveals a common core of PPIs involving heat shock/chaperone proteins, metabolic enzymes, cytoskeletal components, and RNA-binding proteins. Elucidation of points of crosstalk among signaling pathways employing different PTMs reveals new potential drug targets and candidates for synergistic attack through combination drug therapy.",5,We analyzed large-scale post-translational modification (PTM) data to outline cell signaling pathways affected by tyrosine kinase inhibitors (TKIs) in ten lung
Sensitivity of the RNA Structure to Ion Conditions as Probed by Molecular Dynamics Simulations of Common Canonical RNA Duplexes.,36989143,https://pubmed.ncbi.nlm.nih.gov/36989143/,https://doi.org/10.1021/acs.jcim.2c01438,[],"RNA molecules play a key role in countless biochemical processes. RNA interactions, which are of highly diverse nature, are determined by the fact that RNA is a highly negatively charged polyelectrolyte, which leads to intimate interactions with an ion atmosphere. Although RNA molecules are formally single-stranded, canonical (Watson-Crick) duplexes are key components of folded RNAs. A double-stranded (ds) RNA is also important for the design of RNA-based nanostructures and assemblies. Despite the fact that the description of canonical dsRNA is considered the least problematic part of RNA modeling, the imperfect shape and flexibility of dsRNA can lead to imbalances in the simulations of larger RNAs and RNA-containing assemblies. We present a comprehensive set of molecular dynamics (MD) simulations of four canonical A-RNA duplexes. Our focus was directed toward the characterization of the influence of varying ion concentrations and of the size of the solvation box. We compared several water models and four RNA force fields. The simulations showed that the A-RNA shape was most sensitive to the RNA force field, with some force fields leading to a reduced inclination of the A-RNA duplexes. The ions and water models played a minor role. The effect of the box size was negligible, and even boxes with a small fraction of the bulk solvent outside the RNA hydration sphere were sufficient for the simulation of the dsRNA.",3, RNA molecules play a key role in countless biochemical processes.
Con-AAE: contrastive cycle adversarial autoencoders for single-cell multi-omics alignment and integration.,36975610,https://pubmed.ncbi.nlm.nih.gov/36975610/,https://doi.org/10.1093/bioinformatics/btad162,[],"We have entered the multi-omics era and can measure cells from different aspects. Hence, we can get a more comprehensive view by integrating or matching data from different spaces corresponding to the same object. However, it is particularly challenging in the single-cell multi-omics scenario because such data are very sparse with extremely high dimensions. Though some techniques can be used to measure scATAC-seq and scRNA-seq simultaneously, the data are usually highly noisy due to the limitations of the experimental environment.",4,We have entered the multi-omics era and can measure cells from different aspects.
Genomic and proteomic biomarker landscape in clinical trials.,36968019,https://pubmed.ncbi.nlm.nih.gov/36968019/,https://doi.org/10.1016/j.csbj.2023.03.014,"['Actionable biomarker', 'Biomarker', 'Clinical trial', 'Genomic biomarker', 'Proteomic biomarker', 'Text mining']","The use of molecular biomarkers to support disease diagnosis, monitor its progression, and guide drug treatment has gained traction in the last decades. While only a dozen biomarkers have been approved for their exploitation in the clinic by the FDA, many more are evaluated in the context of translational research and clinical trials. Furthermore, the information on which biomarkers are measured, for which purpose, and in relation to which conditions are not readily accessible: biomarkers used in clinical studies available through resources such as ClinicalTrials.gov are described as free text, posing significant challenges in finding, analyzing, and processing them by both humans and machines. We present a text mining strategy to identify proteomic and genomic biomarkers used in clinical trials and classify them according to the methodologies by which they are measured. We find more than 3000 biomarkers used in the context of 2600 diseases. By analyzing this dataset, we uncover patterns of use of biomarkers across therapeutic areas over time, including the biomarker type and their specificity. These data are made available at the Clinical Biomarker App at https://www.disgenet.org/biomarkers/, a new portal that enables the exploration of biomarkers extracted from the clinical studies available at ClinicalTrials.gov and enriched with information from the scientific literature. The App features several metrics that assess the specificity of the biomarkers, facilitating their selection and prioritization. Overall, the Clinical Biomarker App is a valuable and timely resource about clinical biomarkers, to accelerate biomarker discovery, development, and application.",1,"The use of molecular biomarkers to support disease diagnosis, monitor its progression, and guide drug treatment has gained traction in the last decades."
Advanced image-free analysis of the nano-organization of chromatin and other biomolecules by Single Molecule Localization Microscopy (SMLM).,36968017,https://pubmed.ncbi.nlm.nih.gov/36968017/,https://doi.org/10.1016/j.csbj.2023.03.009,"['Application of mathematical analysis tools to chromatin organization and DNA repair processes', 'DSB, DNA double-strand break', 'HR, homologous recombination', 'IRIF, ionizing radiation induced foci', 'LET, linear energy transfer', 'NHEJ, non-homologous end joining', 'NN, nearest neighbor', 'PCA, principal component analysis', 'Persistent homology', 'Persistent image', 'Principal component analysis', 'Ripley distance frequency histograms', 'SMLM, single molecule localization microscopy', 'Single molecule localization microscopy (SMLM)']","The cell as a system of many components, governed by the laws of physics and chemistry drives molecular functions having an impact on the spatial organization of these systems and vice versa. Since the relationship between structure and function is an almost universal rule not only in biology, appropriate methods are required to parameterize the relationship between the structure and function of biomolecules and their networks, the mechanisms of the processes in which they are involved, and the mechanisms of regulation of these processes. Single molecule localization microscopy (SMLM), which we focus on here, offers a significant advantage for the quantitative parametrization of molecular organization: it provides matrices of coordinates of fluorescently labeled biomolecules that can be directly subjected to advanced mathematical analytical procedures without the need for laborious and sometimes misleading image processing. Here, we propose mathematical tools for comprehensive quantitative computer data analysis of SMLM point patterns that include Ripley distance frequency analysis, persistent homology analysis, persistent 'imaging', principal component analysis and co-localization analysis. The application of these methods is explained using artificial datasets simulating different, potentially possible and interpretatively important situations. Illustrative analyses of real complex biological SMLM data are presented to emphasize the applicability of the proposed algorithms. This manuscript demonstrated the extraction of features and parameters quantifying the influence of chromatin (re)organization on genome function, offering a novel approach to study chromatin architecture at the nanoscale. However, the ability to adapt the proposed algorithms to analyze essentially any molecular organizations, e.g., membrane receptors or protein trafficking in the cytosol, offers broad flexibility of use.",2,Single molecule localization microscopy (SMLM) offers a significant advantage for the quantitative parametrization of molecular organization.
ESCCdb: A comprehensive database and key regulator exploring platform based on cross dataset comparisons for esophageal squamous cell carcinoma.,36968016,https://pubmed.ncbi.nlm.nih.gov/36968016/,https://doi.org/10.1016/j.csbj.2023.03.026,"['Consistently differential expressed genes', 'Esophageal squamous cell carcinoma', 'Multi-omics', 'Transcription factor', 'Webserver']","Esophageal cancer is the seventh most prevalent and the sixth most lethal cancer. Esophageal squamous cell carcinoma (ESCC) is one of the major esophageal cancer subtypes that accounts for 87 % of the total cases. However, its molecular mechanism remains unclear. Here, we present an integrated database for ESCC called ESCCdb, which includes a total of 56 datasets and published studies from the GEO, Xena or SRA databases and related publications. It helps users to explore a particular gene with multiple graphical and interactive views with one click. The results comprise expression changes across 20 datasets, copy number alterations in 11 datasets, somatic mutations from 12 papers, related drugs derived from DGIdb, related pathways, and gene correlations. ESCCdb enables directly cross-dataset comparison of a gene's mutations, expressions and copy number changes in multiple datasets. This allows users to easily assess the alterations in ESCC. Furthermore, survival analysis, drug-gene relationships, and results from whole-genome CRISPR/Cas9 screening can help users determine the clinical relevance, derive functional inferences, and identify potential drugs. Notably, ESCCdb also enables the exploration of the correlation structure and identification of potential key regulators for a process. Finally, we identified 789 consistently differential expressed genes; we summarized recurrently mutated genes and genes affected by significant copy number alterations. These genes may be stable biomarkers or important players during ESCC development. ESCCdb fills the gap between massive omics data and users' needs for integrated analysis and can promote basic and clinical ESCC research. The database is freely accessible at http://cailab.labshare.cn/ESCCdb.",1,"Esophageal cancer is the seventh most prevalent and the sixth most lethal cancer. Here, we present an integrated database for ESCC called ESCCdb."
"AiZynthTrain: Robust, Reproducible, and Extensible Pipelines for Training Synthesis Prediction Models.",36959737,https://pubmed.ncbi.nlm.nih.gov/36959737/,https://doi.org/10.1021/acs.jcim.2c01486,[],"We introduce the AiZynthTrain Python package for training synthesis models in a robust, reproducible, and extensible way. It contains two pipelines that create a template-based one-step retrosynthesis model and a RingBreaker model that can be straightforwardly integrated in retrosynthesis software. We train such models on the publicly available reaction data set from the U.S. Patent and Trademark Office (USPTO), and these are the first retrosynthesis models created in a completely reproducible end-to-end fashion, starting with the original reaction data source and ending with trained machine-learning models. In particular, we show that employing new heuristics implemented in the pipeline greatly improves the ability of the RingBreaker model for disconnecting ring systems. Furthermore, we demonstrate the robustness of the pipeline by training on a more diverse but proprietary data set. We envisage that this framework will be extended with other synthesis models in the future.",2,AiZynthTrain is a Python package for training synthesis models.
GlyLES: Grammar-based Parsing of Glycans from IUPAC-condensed to SMILES.,36959676,https://pubmed.ncbi.nlm.nih.gov/36959676/,https://doi.org/10.1186/s13321-023-00704-0,"['Glycan', 'Glycobiology', 'Grammar', 'IUPAC-condensed', 'SMILES']","Glycans are important polysaccharides on cellular surfaces that are bound to glycoproteins and glycolipids. These are one of the most common post-translational modifications of proteins in eukaryotic cells. They play important roles in protein folding, cell-cell interactions, and other extracellular processes. Changes in glycan structures may influence the course of different diseases, such as infections or cancer. Glycans are commonly represented using the IUPAC-condensed notation. IUPAC-condensed is a textual representation of glycans operating on the same topological level as the Symbol Nomenclature for Glycans (SNFG) that assigns colored, geometrical shapes to the main monomers. These symbols are then connected in tree-like structures, visualizing the glycan structure on a topological level. Yet for a representation on the atomic level, notations such as SMILES should be used. To our knowledge, there is no easy-to-use, general, open-source, and offline tool to convert the IUPAC-condensed notation to SMILES. Here, we present the open-access Python package GlyLES for the generalizable generation of SMILES representations out of IUPAC-condensed representations. GlyLES uses a grammar to read in the monomer tree from the IUPAC-condensed notation. From this tree, the tool can compute the atomic structures of each monomer based on their IUPAC-condensed descriptions. In the last step, it merges all monomers into the atomic structure of a glycan in the SMILES notation. GlyLES is the first package that allows conversion from the IUPAC-condensed notation of glycans to SMILES strings. This may have multiple applications, including straightforward visualization, substructure search, molecular modeling and docking, and a new featurization strategy for machine-learning algorithms. GlyLES is available at https://github.com/kalininalab/GlyLES .",2,Glycans are important polysaccharides on cellular surfaces that are bound to glycoproteins and glycolipids.
Predicting miRNA-disease associations based on PPMI and attention network.,36959547,https://pubmed.ncbi.nlm.nih.gov/36959547/,https://doi.org/10.1186/s12859-023-05152-z,"['Attention network', 'Deep learning', 'MiRNA-disease association prediction', 'PPMI']","With the development of biotechnology and the accumulation of theories, many studies have found that microRNAs (miRNAs) play an important role in various diseases. Uncovering the potential associations between miRNAs and diseases is helpful to better understand the pathogenesis of complex diseases. However, traditional biological experiments are expensive and time-consuming. Therefore, it is necessary to develop more efficient computational methods for exploring underlying disease-related miRNAs.",3,"With the development of biotechnology and the accumulation of theories, many studies have found that microRNAs (miRNAs) play an important role in various diseases."
Epigenetic modifications: Allusive clues of lncRNA functions in plants.,36950220,https://pubmed.ncbi.nlm.nih.gov/36950220/,https://doi.org/10.1016/j.csbj.2023.03.008,"['Epigenetic regulation', 'Epigenomes', 'LncRNA', 'Plant']","Long non-coding RNAs (lncRNAs) have been verified as flexible and important factors in various biological processes of multicellular eukaryotes, including plants. The respective intricate crosstalk among multiple epigenetic modifications has been examined to some extent. However, only a small proportion of lncRNAs has been functionally well characterized. Moreover, the relationship between lncRNAs and other epigenetic modifications has not been systematically studied. In this mini-review, we briefly summarize the representative biological functions of lncRNAs in developmental programs and environmental responses in plants. In addition, we particularly discuss the intimate relationship between lncRNAs and other epigenetic modifications, and we outline the underlying avenues and challenges for future research on plant lncRNAs.",2,"Long non-coding RNAs (lncRNAs) have been verified as flexible and important factors in various biological processes of multicellular eukaryotes, including plants."
Bayesian kinetic modeling for tracer-based metabolomic data.,36949395,https://pubmed.ncbi.nlm.nih.gov/36949395/,https://doi.org/10.1186/s12859-023-05211-5,"['Bayesian method', 'Kinetic modeling', 'SIRM']","Stable Isotope Resolved Metabolomics (SIRM) is a new biological approach that uses stable isotope tracers such as uniformly [Formula: see text]-enriched glucose ([Formula: see text]-Glc) to trace metabolic pathways or networks at the atomic level in complex biological systems. Non-steady-state kinetic modeling based on SIRM data uses sets of simultaneous ordinary differential equations (ODEs) to quantitatively characterize the dynamic behavior of metabolic networks. It has been increasingly used to understand the regulation of normal metabolism and dysregulation in the development of diseases. However, fitting a kinetic model is challenging because there are usually multiple sets of parameter values that fit the data equally well, especially for large-scale kinetic models. In addition, there is a lack of statistically rigorous methods to compare kinetic model parameters between different experimental groups.",2,Stable Isotope Resolved Metabolomics (SIRM) is a new biological approach that uses stable isotope tracers.
The hidden factor: accounting for covariate effects in power and sample size computation for a binary trait.,36943372,https://pubmed.ncbi.nlm.nih.gov/36943372/,https://doi.org/10.1093/bioinformatics/btad139,[],"Accurate power and sample size estimation is crucial to the design and analysis of genetic association studies. When analyzing a binary trait via logistic regression, important covariates such as age and sex are typically included in the model. However, their effects are rarely properly considered in power or sample size computation during study planning. Unlike when analyzing a continuous trait, the power of association testing between a binary trait and a genetic variant depends, explicitly, on covariate effects, even under the assumption of gene-environment independence. Earlier work recognizes this hidden factor but the implemented methods are not flexible. We thus propose and implement a generalized method for estimating power and sample size for (discovery or replication) association studies of binary traits that (i) accommodates different types of nongenetic covariates E, (ii) deals with different types of G-E relationships, and (iii) is computationally efficient.",1,Accurate power and sample size estimation is crucial to the design and analysis of genetic association studies.
OpticalBERT and OpticalTable-SQA: Text- and Table-Based Language Models for the Optical-Materials Domain.,36940385,https://pubmed.ncbi.nlm.nih.gov/36940385/,https://doi.org/10.1021/acs.jcim.2c01259,[],"Text mining in the optical-materials domain is becoming increasingly important as the number of scientific publications in this area grows rapidly. Language models such as Bidirectional Encoder Representations from Transformers (BERT) have opened up a new era and brought a significant boost to state-of-the-art natural-language-processing (NLP) tasks. In this paper, we present two ""materials-aware"" text-based language models for optical research, OpticalBERT and OpticalPureBERT, which are trained on a large corpus of scientific literature in the optical-materials domain. These two models outperform BERT and previous state-of-the-art models in a variety of text-mining tasks about optical materials. We also release the first ""materials-aware"" table-based language model, OpticalTable-SQA. This is a querying facility that solicits answers to questions about optical materials using tabular information that pertains to this scientific domain. The OpticalTable-SQA model was realized by fine-tuning the Tapas-SQA model using a manually annotated OpticalTableQA data set which was curated specifically for this work. While preserving its sequential question-answering performance on general tables, the OpticalTable-SQA model significantly outperforms Tapas-SQA on optical-materials-related tables. All models and data sets are available to the optical-materials-science community.",1,Text mining in the optical-materials domain is becoming increasingly important as the number of scientific publications in this area grows rapidly.
Metheor: Ultrafast DNA methylation heterogeneity calculation from bisulfite read alignments.,36940213,https://pubmed.ncbi.nlm.nih.gov/36940213/,https://doi.org/10.1371/journal.pcbi.1010946,[],"Phased DNA methylation states within bisulfite sequencing reads are valuable source of information that can be used to estimate epigenetic diversity across cells as well as epigenomic instability in individual cells. Various measures capturing the heterogeneity of DNA methylation states have been proposed for a decade. However, in routine analyses on DNA methylation, this heterogeneity is often ignored by computing average methylation levels at CpG sites, even though such information exists in bisulfite sequencing data in the form of phased methylation states, or methylation patterns. In this study, to facilitate the application of the DNA methylation heterogeneity measures in downstream epigenomic analyses, we present a Rust-based, extremely fast and lightweight bioinformatics toolkit called Metheor. As the analysis of DNA methylation heterogeneity requires the examination of pairs or groups of CpGs throughout the genome, existing softwares suffer from high computational burden, which almost make a large-scale DNA methylation heterogeneity studies intractable for researchers with limited resources. In this study, we benchmark the performance of Metheor against existing code implementations for DNA methylation heterogeneity measures in three different scenarios of simulated bisulfite sequencing datasets. Metheor was shown to dramatically reduce the execution time up to 300-fold and memory footprint up to 60-fold, while producing identical results with the original implementation, thereby facilitating a large-scale study of DNA methylation heterogeneity profiles. To demonstrate the utility of the low computational burden of Metheor, we show that the methylation heterogeneity profiles of 928 cancer cell lines can be computed with standard computing resources. With those profiles, we reveal the association between DNA methylation heterogeneity and various omics features. Source code for Metheor is at https://github.com/dohlee/metheor and is freely available under the GPL-3.0 license.",2,"Metheor is a Rust-based, extremely fast and lightweight bioinformatics toolkit."
IK-DDI: a novel framework based on instance position embedding and key external text for DDI extraction.,36932655,https://pubmed.ncbi.nlm.nih.gov/36932655/,https://doi.org/10.1093/bib/bbad099,"['DDI extraction', 'drug matching', 'instance position embedding', 'key external text']","Determining drug-drug interactions (DDIs) is an important part of pharmacovigilance and has a vital impact on public health. Compared with drug trials, obtaining DDI information from scientific articles is a faster and lower cost but still a highly credible approach. However, current DDI text extraction methods consider the instances generated from articles to be independent and ignore the potential connections between different instances in the same article or sentence. Effective use of external text data could improve prediction accuracy, but existing methods cannot extract key information from external data accurately and reasonably, resulting in low utilization of external data. In this study, we propose a DDI extraction framework, instance position embedding and key external text for DDI (IK-DDI), which adopts instance position embedding and key external text to extract DDI information. The proposed framework integrates the article-level and sentence-level position information of the instances into the model to strengthen the connections between instances generated from the same article or sentence. Moreover, we introduce a comprehensive similarity-matching method that uses string and word sense similarity to improve the matching accuracy between the target drug and external text. Furthermore, the key sentence search method is used to obtain key information from external data. Therefore, IK-DDI can make full use of the connection between instances and the information contained in external text data to improve the efficiency of DDI extraction. Experimental results show that IK-DDI outperforms existing methods on both macro-averaged and micro-averaged metrics, which suggests our method provides complete framework that can be used to extract relationships between biomedical entities and process external text data.",1,Determining drug-drug interactions (DDIs) is an important part of pharmacovigilance and has a vital impact on public health.
Genetics and precision health: the ecological fallacy and artificial intelligence solutions.,36927508,https://pubmed.ncbi.nlm.nih.gov/36927508/,https://doi.org/10.1186/s13040-023-00327-z,[],,1,
Avoiding background knowledge: literature based discovery from important information.,36918777,https://pubmed.ncbi.nlm.nih.gov/36918777/,https://doi.org/10.1186/s12859-022-04892-8,"['Literature based discovery', 'Machine learning', 'Subject–predicate–object triples', 'Timeslicing gold standard']","Automatic literature based discovery attempts to uncover new knowledge by connecting existing facts: information extracted from existing publications in the form of [Formula: see text] and [Formula: see text] relations can be simply connected to deduce [Formula: see text]. However, using this approach, the quantity of proposed connections is often too vast to be useful. It can be reduced by using subject[Formula: see text](predicate)[Formula: see text]object triples as the [Formula: see text] relations, but too many proposed connections remain for manual verification.",1,Automatic literature based discovery attempts to uncover new knowledge by connecting existing facts. The quantity of proposed connections is often too vast to be useful.
Structure-activity correlations for peptaibols obtained from clade Longibrachiatum of ,36915379,https://pubmed.ncbi.nlm.nih.gov/36915379/,https://doi.org/10.1016/j.csbj.2023.02.046,"['Molecular dynamics simulations', 'Peptaibols', 'Peptide folding', 'Structure-activity relationship (SAR)', 'Trichoderma']",Integrated disease management and plant protection have been discussed with much fervor in the past decade due to the rising environmental concerns of using industrially produced pesticides. Members of the genus ,1, Integrated disease management and plant protection have been discussed with much fervor in the past decade due to the rising environmental concerns of using industrially produced pesticides.
AisNet: A Universal Interatomic Potential Neural Network with Encoded Local Environment Features.,36897781,https://pubmed.ncbi.nlm.nih.gov/36897781/,https://doi.org/10.1021/acs.jcim.3c00077,[],"This paper proposes a new interatomic potential energy neural network, AisNet, which can efficiently predict atomic energies and forces covering different molecular and crystalline materials by encoding universal local environment features, such as elements and atomic positions. Inspired by the framework of SchNet, AisNet consists of an encoding module combining autoencoder with embedding, the triplet loss function and an atomic central symmetry function (ACSF), an interaction module with a periodic boundary condition (PBC), and a prediction module. In molecules, the prediction accuracy of AisNet is comparabel with SchNet on the MD17 dataset, mainly attributed to the effective capture of chemical functional groups through the interaction module. In selected metal and ceramic material datasets, the introduction of ACSF improves the overall accuracy of AisNet by an average of 16.8% for energy and 28.6% for force. Furthermore, a close relationship is found between the feature ratio (i.e., ACSF and embedding) and the force prediction errors, exhibiting similar spoon-shaped curves in the datasets of Cu and HfO",1,"AisNet consists of an encoding module combining autoencoder with embedding, the triplet loss function and an atomic central symmetry function."
"Identification of a PD1/PD-L1 inhibitor by structure-based pharmacophore modelling, virtual screening, molecular docking and biological evaluation.",36897739,https://pubmed.ncbi.nlm.nih.gov/36897739/,https://doi.org/10.1002/minf.202200254,"['PD-L1', 'chemoinformatics', 'drug repurposing', 'immunotherapy', 'sepsis']","PD-1/PD-L1 is a critical druggable target for immunotherapy against sepsis. Chemoinformatics techniques involved the structure-based 3D pharmacophore model development followed by virtual screening of small molecule databases to identify the small molecules against PD-L1 pathway inhibition. Raltitrexed and Safinamide act as potent repurposed drugs, and three other Specs database compounds using in silico methods. These compounds were screened based on the pharmacophore fit score and binding affinity towards the active site of the PD-L1 protein. In silico pharmacokinetic profiling of these screened compounds was done to test their biological activity. Next, experimental validation of the best four virtually screened hits was done in vitro for its hemocompatibility and cytotoxicity. Among these, Raltitrexed, Safinamide and Specs compound (AK-968/40642641) effectively increased the proliferation of immune cells and IFN-γ production. These compounds can act as potent PDL-1 inhibitors for adjuvant therapy against sepsis.",3,PD-1/PD-L1 is a critical druggable target for immunotherapy against sepsis.
ExamPle: explainable deep learning framework for the prediction of plant small secreted peptides.,36897030,https://pubmed.ncbi.nlm.nih.gov/36897030/,https://doi.org/10.1093/bioinformatics/btad108,[],"Plant Small Secreted Peptides (SSPs) play an important role in plant growth, development, and plant-microbe interactions. Therefore, the identification of SSPs is essential for revealing the functional mechanisms. Over the last few decades, machine learning-based methods have been developed, accelerating the discovery of SSPs to some extent. However, existing methods highly depend on handcrafted feature engineering, which easily ignores the latent feature representations and impacts the predictive performance.",1,"Plant Small Secreted Peptides (SSPs) play an important role in plant growth, development, and plant-microbe interactions."
Are Deep Learning Structural Models Sufficiently Accurate for Virtual Screening? Application of Docking Algorithms to AlphaFold2 Predicted Structures.,36892986,https://pubmed.ncbi.nlm.nih.gov/36892986/,https://doi.org/10.1021/acs.jcim.2c01270,[],"Machine learning-based protein structure prediction algorithms, such as RosettaFold and AlphaFold2, have greatly impacted the structural biology field, arousing a fair amount of discussion around their potential role in drug discovery. While there are few preliminary studies addressing the usage of these models in virtual screening, none of them focus on the prospect of hit-finding in a real-world virtual screen with a model based on low prior structural information. In order to address this, we have developed an AlphaFold2 version where we exclude all structural templates with more than 30% sequence identity from the model-building process. In a previous study, we used those models in conjunction with state-of-the-art free energy perturbation methods and demonstrated that it is possible to obtain quantitatively accurate results. In this work, we focus on using these structures in rigid receptor-ligand docking studies. Our results indicate that using out-of-the-box Alphafold2 models is not an ideal scenario for virtual screening campaigns; in fact, we strongly recommend to include some post-processing modeling to drive the binding site into a more realistic holo model.",10,"Machine learning-based protein structure prediction algorithms, such as RosettaFold and AlphaFold2, have greatly impacted the structural biology field."
Identification of significant gene expression changes in multiple perturbation experiments using knockoffs.,36892174,https://pubmed.ncbi.nlm.nih.gov/36892174/,https://doi.org/10.1093/bib/bbad084,"['chemoinformatics', 'deep learning', 'gene expression', 'genomics', 'knockoffs']","Large-scale multiple perturbation experiments have the potential to reveal a more detailed understanding of the molecular pathways that respond to genetic and environmental changes. A key question in these studies is which gene expression changes are important for the response to the perturbation. This problem is challenging because (i) the functional form of the nonlinear relationship between gene expression and the perturbation is unknown and (ii) identification of the most important genes is a high-dimensional variable selection problem. To deal with these challenges, we present here a method based on the model-X knockoffs framework and Deep Neural Networks to identify significant gene expression changes in multiple perturbation experiments. This approach makes no assumptions on the functional form of the dependence between the responses and the perturbations and it enjoys finite sample false discovery rate control for the selected set of important gene expression responses. We apply this approach to the Library of Integrated Network-Based Cellular Signature data sets which is a National Institutes of Health Common Fund program that catalogs how human cells globally respond to chemical, genetic and disease perturbations. We identified important genes whose expression is directly modulated in response to perturbation with anthracycline, vorinostat, trichostatin-a, geldanamycin and sirolimus. We compare the set of important genes that respond to these small molecules to identify co-responsive pathways. Identification of which genes respond to specific perturbation stressors can provide better understanding of the underlying mechanisms of disease and advance the identification of new drug targets.",2,Large-scale multiple perturbation experiments have the potential to reveal a more detailed understanding of the molecular pathways that respond to genetic and environmental changes.
EG-TransUNet: a transformer-based U-Net with enhanced and guided models for biomedical image segmentation.,36882688,https://pubmed.ncbi.nlm.nih.gov/36882688/,https://doi.org/10.1186/s12859-023-05196-1,"['Channel spatial attention', 'Medical image segmentation', 'Progressive enhancement module', 'Self-attention', 'Semantic guidance attention', 'Transformer']","Although various methods based on convolutional neural networks have improved the performance of biomedical image segmentation to meet the precision requirements of medical imaging segmentation task, medical image segmentation methods based on deep learning still need to solve the following problems: (1) Difficulty in extracting the discriminative feature of the lesion region in medical images during the encoding process due to variable sizes and shapes; (2) difficulty in fusing spatial and semantic information of the lesion region effectively during the decoding process due to redundant information and the semantic gap. In this paper, we used the attention-based Transformer during the encoder and decoder stages to improve feature discrimination at the level of spatial detail and semantic location by its multihead-based self-attention. In conclusion, we propose an architecture called EG-TransUNet, including three modules improved by a transformer: progressive enhancement module, channel spatial attention, and semantic guidance attention. The proposed EG-TransUNet architecture allowed us to capture object variabilities with improved results on different biomedical datasets. EG-TransUNet outperformed other methods on two popular colonoscopy datasets (Kvasir-SEG and CVC-ClinicDB) by achieving 93.44% and 95.26% on mDice. Extensive experiments and visualization results demonstrate that our method advances the performance on five medical segmentation datasets with better generalization ability.",4, EG-TransUNet outperformed other methods on two popular colonoscopy datasets.
PhaGAA: an integrated web server platform for phage genome annotation and analysis.,36882183,https://pubmed.ncbi.nlm.nih.gov/36882183/,https://doi.org/10.1093/bioinformatics/btad120,[],"Phage genome annotation plays a key role in the design of phage therapy. To date, there have been various genome annotation tools for phages, but most of these tools focus on mono-functional annotation and have complex operational processes. Accordingly, comprehensive and user-friendly platforms for phage genome annotation are needed.",3,"To date, there have been various genome annotation tools for phages."
NDEx IQuery: a multi-method network gene set analysis leveraging the Network Data Exchange.,36882166,https://pubmed.ncbi.nlm.nih.gov/36882166/,https://doi.org/10.1093/bioinformatics/btad118,[],The investigation of sets of genes using biological pathways is a common task for researchers and is supported by a wide variety of software tools. This type of analysis generates hypotheses about the biological processes that are active or modulated in a specific experimental context.,6,The investigation of sets of genes using biological pathways is a common task for researchers.
Machine learning reveals STAT motifs as predictors for GR-mediated gene repression.,36879886,https://pubmed.ncbi.nlm.nih.gov/36879886/,https://doi.org/10.1016/j.csbj.2023.02.015,"['ChIPseq', 'ChIPseq, chromatin immunoprecipitation sequencing', 'Epigenomics', 'Glucocorticoid receptor', 'Machine-learning', 'RNAseq', 'Repression', 'STAT', 'STAT, signal transducer and activator of transcription']","Glucocorticoids are potent immunosuppressive drugs, but long-term treatment leads to severe side-effects. While there is a commonly accepted model for GR-mediated gene activation, the mechanism behind repression remains elusive. Understanding the molecular action of the glucocorticoid receptor (GR) mediated gene repression is the first step towards developing novel therapies. We devised an approach that combines multiple epigenetic assays with 3D chromatin data to find sequence patterns predicting gene expression change. We systematically tested> 100 models to evaluate the best way to integrate the data types and found that GR-bound regions hold most of the information needed to predict the polarity of Dex-induced transcriptional changes. We confirmed NF-κB motif family members as predictors for gene repression and identified STAT motifs as additional negative predictors.",1,"Glucocorticoids are potent immunosuppressive drugs, but long-term treatment leads to severe side-effects."
ModInterv COVID-19: An online platform to monitor the evolution of epidemic curves.,36874079,https://pubmed.ncbi.nlm.nih.gov/36874079/,https://doi.org/10.1016/j.asoc.2023.110159,"['COVID-19', 'Epidemic curves', 'Growth models', 'Intervention strategies', 'LOWESS regression']","We present the software ModInterv as an informatics tool to monitor, in an automated and user-friendly manner, the evolution and trend of COVID-19 epidemic curves, both for cases and deaths. The ModInterv software uses parametric generalized growth models, together with LOWESS regression analysis, to fit epidemic curves with multiple waves of infections for countries around the world as well as for states and cities in Brazil and the USA. The software automatically accesses publicly available COVID-19 databases maintained by the Johns Hopkins University (for countries as well as states and cities in the USA) and the Federal University of Viçosa (for states and cities in Brazil). The richness of the implemented models lies in the possibility of quantitatively and reliably detecting the distinct acceleration regimes of the disease. We describe the backend structure of software as well as its practical use. The software helps the user not only to understand the current stage of the epidemic in a chosen location but also to make short term predictions as to how the curves may evolve. The app is freely available on the internet (http://fisica.ufpr.br/modinterv), thus making a sophisticated mathematical analysis of epidemic data readily accessible to any interested user.",1,"The ModInterv software uses parametric generalized growth models, together with LOWESS regression analysis."
MAW: the reproducible Metabolome Annotation Workflow for untargeted tandem mass spectrometry.,36871033,https://pubmed.ncbi.nlm.nih.gov/36871033/,https://doi.org/10.1186/s13321-023-00695-y,"['FAIR', 'Metabolite annotation', 'Tandem mass spectrometry', 'Untargeted metabolomics', 'Workflow']","Mapping the chemical space of compounds to chemical structures remains a challenge in metabolomics. Despite the advancements in untargeted liquid chromatography-mass spectrometry (LC-MS) to achieve a high-throughput profile of metabolites from complex biological resources, only a small fraction of these metabolites can be annotated with confidence. Many novel computational methods and tools have been developed to enable chemical structure annotation to known and unknown compounds such as in silico generated spectra and molecular networking. Here, we present an automated and reproducible Metabolome Annotation Workflow (MAW) for untargeted metabolomics data to further facilitate and automate the complex annotation by combining tandem mass spectrometry (MS",6,Mapping the chemical space of compounds to chemical structures remains a challenge in metabolomics.
Interpretable meta-learning of multi-omics data for survival analysis and pathway enrichment.,36864611,https://pubmed.ncbi.nlm.nih.gov/36864611/,https://doi.org/10.1093/bioinformatics/btad113,[],"Despite the success of recent machine learning algorithms' applications to survival analysis, their black-box nature hinders interpretability, which is arguably the most important aspect. Similarly, multi-omics data integration for survival analysis is often constrained by the underlying relationships and correlations that are rarely well understood. The goal of this work is to alleviate the interpretability problem in machine learning approaches for survival analysis and also demonstrate how multi-omics data integration improves survival analysis and pathway enrichment. We use meta-learning, a machine-learning algorithm that is trained on a variety of related datasets and allows quick adaptations to new tasks, to perform survival analysis and pathway enrichment on pan-cancer datasets. In recent machine learning research, meta-learning has been effectively used for knowledge transfer among multiple related datasets.",2,Machine learning algorithms' black-box nature hinders interpretability.
iATMEcell: identification of abnormal tumor microenvironment cells to predict the clinical outcomes in cancer based on cell-cell crosstalk network.,36864591,https://pubmed.ncbi.nlm.nih.gov/36864591/,https://doi.org/10.1093/bib/bbad074,"['cell–cell crosstalk network', 'network propagation algorithm', 'prognostic biomarker', 'tumor microenvironment']","Interactions between Tumor microenvironment (TME) cells shape the unique growth environment, sustaining tumor growth and causing the immune escape of tumor cells. Nonetheless, no studies have reported a systematic analysis of cellular interactions in the identification of cancer-related TME cells. Here, we proposed a novel network-based computational method, named as iATMEcell, to identify the abnormal TME cells associated with the biological outcome of interest based on a cell-cell crosstalk network. In the method, iATMEcell first manually collected TME cell types from multiple published studies and obtained their corresponding gene signatures. Then, a weighted cell-cell crosstalk network was constructed in the context of a specific cancer bulk tissue transcriptome data, where the weight between cells reflects both their biological function similarity and the transcriptional dysregulated activities of gene signatures shared by them. Finally, it used a network propagation algorithm to identify significantly dysregulated TME cells. Using the cancer genome atlas (TCGA) Bladder Urothelial Carcinoma training set and two independent validation sets, we illustrated that iATMEcell could identify significant abnormal cells associated with patient survival and immunotherapy response. iATMEcell was further applied to a pan-cancer analysis, which revealed that four common abnormal immune cells play important roles in the patient prognosis across multiple cancer types. Collectively, we demonstrated that iATMEcell could identify potentially abnormal TME cells based on a cell-cell crosstalk network, which provided a new insight into understanding the effect of TME cells in cancer. iATMEcell is developed as an R package, which is freely available on GitHub (https://github.com/hanjunwei-lab/iATMEcell).",1,No studies have reported a systematic analysis of cellular interactions in the identification of cancer-related TME cells.
PSnpBind-ML: predicting the effect of binding site mutations on protein-ligand binding affinity.,36864534,https://pubmed.ncbi.nlm.nih.gov/36864534/,https://doi.org/10.1186/s13321-023-00701-3,"['Binding affinity', 'Binding site', 'Feature engineering', 'Machine learning', 'Mutation effect', 'Predictive model', 'Random forest', 'SNP']","Protein mutations, especially those which occur in the binding site, play an important role in inter-individual drug response and may alter binding affinity and thus impact the drug's efficacy and side effects. Unfortunately, large-scale experimental screening of ligand-binding against protein variants is still time-consuming and expensive. Alternatively, in silico approaches can play a role in guiding those experiments. Methods ranging from computationally cheaper machine learning (ML) to the more expensive molecular dynamics have been applied to accurately predict the mutation effects. However, these effects have been mostly studied on limited and small datasets, while ideally a large dataset of binding affinity changes due to binding site mutations is needed. In this work, we used the PSnpBind database with six hundred thousand docking experiments to train a machine learning model predicting protein-ligand binding affinity for both wild-type proteins and their variants with a single-point mutation in the binding site. A numerical representation of the protein, binding site, mutation, and ligand information was encoded using 256 features, half of them were manually selected based on domain knowledge. A machine learning approach composed of two regression models is proposed, the first predicting wild-type protein-ligand binding affinity while the second predicting the mutated protein-ligand binding affinity. The best performing models reported an RMSE value within 0.5 [Formula: see text] 0.6 kcal/mol",2,"Protein mutations, especially those which occur in the binding site, play an important role in inter-individual drug response."
STEEL enables high-resolution delineation of spatiotemporal transcriptomic data.,36857617,https://pubmed.ncbi.nlm.nih.gov/36857617/,https://doi.org/10.1093/bib/bbad068,[],"Advances in spatial transcriptomics enlarge the use of single cell technologies to unveil the expression landscape of the tissues with valuable spatial context. Here, we propose an unsupervised and manifold learning-based algorithm, Spatial Transcriptome based cEll typE cLustering (STEEL), which identifies domains from spatial transcriptome by clustering beads exhibiting both highly similar gene expression profiles and close spatial distance in the manner of graphs. Comprehensive evaluation of STEEL on spatial transcriptomic datasets from 10X Visium platform demonstrates that it not only achieves a high resolution to characterize fine structures of mouse brain but also enables the integration of multiple tissue slides individually analyzed into a larger one. STEEL outperforms previous methods to effectively distinguish different cell types/domains of various tissues on Slide-seq datasets, featuring in higher bead density but lower transcript detection efficiency. Application of STEEL on spatial transcriptomes of early-stage mouse embryos (E9.5-E12.5) successfully delineates a progressive development landscape of tissues from ectoderm, mesoderm and endoderm layers, and further profiles dynamic changes on cell differentiation in heart and other organs. With the advancement of spatial transcriptome technologies, our method will have great applicability on domain identification and gene expression atlas reconstruction.",2,Spatial Transcriptome based cEll typE
Computational prediction of disordered binding regions.,36851914,https://pubmed.ncbi.nlm.nih.gov/36851914/,https://doi.org/10.1016/j.csbj.2023.02.018,"['CAID, Critical Assessment of Intrinsic Disorder', 'CASP, Critical Assessment of techniques for protein Structure Prediction', 'DL, deep learning', 'Disordered binding regions', 'IDP, intrinsically disordered protein', 'IDR, intrinsically disordered region', 'Intrinsic disorder', 'ML, machine learning', 'MoRF, molecular recognition fragment', 'Molecular recognition features', 'NN, neural network', 'Protein-lipid interactions', 'Protein-nucleic acids interactions', 'Protein-protein interactions', 'SLiM, short linear sequence motif', 'Short linear motifs']","One of the key features of intrinsically disordered regions (IDRs) is their ability to interact with a broad range of partner molecules. Multiple types of interacting IDRs were identified including molecular recognition fragments (MoRFs), short linear sequence motifs (SLiMs), and protein-, nucleic acids- and lipid-binding regions. Prediction of binding IDRs in protein sequences is gaining momentum in recent years. We survey 38 predictors of binding IDRs that target interactions with a diverse set of partners, such as peptides, proteins, RNA, DNA and lipids. We offer a historical perspective and highlight key events that fueled efforts to develop these methods. These tools rely on a diverse range of predictive architectures that include scoring functions, regular expressions, traditional and deep machine learning and meta-models. Recent efforts focus on the development of deep neural network-based architectures and extending coverage to RNA, DNA and lipid-binding IDRs. We analyze availability of these methods and show that providing implementations and webservers results in much higher rates of citations/use. We also make several recommendations to take advantage of modern deep network architectures, develop tools that bundle predictions of multiple and different types of binding IDRs, and work on algorithms that model structures of the resulting complexes.",8,"Multiple types of interacting IDRs were identified including molecular recognition fragments (MoRFs), short linear sequence motifs (SLiMs) and protein-, nucleic acids- and lipid-"
Predicting RP-LC retention indices of structurally unknown chemicals from mass spectrometry data.,36829215,https://pubmed.ncbi.nlm.nih.gov/36829215/,https://doi.org/10.1186/s13321-023-00699-8,"['HRMS', 'Machine learning', 'Non-target analysis', 'Retention indices']","Non-target analysis combined with liquid chromatography high resolution mass spectrometry is considered one of the most comprehensive strategies for the detection and identification of known and unknown chemicals in complex samples. However, many compounds remain unidentified due to data complexity and limited number structures in chemical databases. In this work, we have developed and validated a novel machine learning algorithm to predict the retention index (r[Formula: see text]) values for structurally (un)known chemicals based on their measured fragmentation pattern. The developed model, for the first time, enabled the predication of r[Formula: see text] values without the need for the exact structure of the chemicals, with an [Formula: see text] of 0.91 and 0.77 and root mean squared error (RMSE) of 47 and 67 r[Formula: see text] units for the NORMAN ([Formula: see text]) and amide ([Formula: see text]) test sets, respectively. This fragment based model showed comparable accuracy in r[Formula: see text] prediction compared to conventional descriptor-based models that rely on known chemical structure, which obtained an [Formula: see text] of 0.85 with an RMSE of 67.",2,"For the first time, a machine learning algorithm enabled the predication of r[Formula: see text] values without the need for the exact structure of the chemicals."
Designing multi-epitope vaccine against important colorectal cancer (CRC) associated pathogens based on immunoinformatics approach.,36829112,https://pubmed.ncbi.nlm.nih.gov/36829112/,https://doi.org/10.1186/s12859-023-05197-0,"['Colorectal cancer', 'Gut microbiota', 'Immunoinformatics', 'In silico', 'Multi-epitope vaccine', 'Vaccine design']","It seems that several members of intestinal gut microbiota like Streptococcus bovis, Bacteroides fragilis, Helicobacter pylori, Fusobacterium nucleatum, Enterococcus faecalis, Escherichia coli, Peptostreptococcus anaerobius may be considered as the causative agents of Colorectal Cancer (CRC). The present study used bioinformatics and immunoinformatics approaches to design a potential epitope-based multi-epitope vaccine to prevent CRC with optimal population coverage.",2,"Streptococcus bovis, Bacteroides fragilis, Helicobacter pylori, Fusobacterium nucleatum, Enterococcus faecalis"
"PriPath: identifying dysregulated pathways from differential gene expression via grouping, scoring, and modeling with an embedded feature selection approach.",36823571,https://pubmed.ncbi.nlm.nih.gov/36823571/,https://doi.org/10.1186/s12859-023-05187-2,"['Bioinformatics', 'Biological knowledge integration', 'Classification', 'Data mining', 'Data science', 'Enrichment analysis', 'Feature grouping', 'Feature scoring', 'Feature selection', 'Gene expression', 'Genomics', 'KEGG pathway', 'Machine learning']","Cell homeostasis relies on the concerted actions of genes, and dysregulated genes can lead to diseases. In living organisms, genes or their products do not act alone but within networks. Subsets of these networks can be viewed as modules that provide specific functionality to an organism. The Kyoto encyclopedia of genes and genomes (KEGG) systematically analyzes gene functions, proteins, and molecules and combines them into pathways. Measurements of gene expression (e.g., RNA-seq data) can be mapped to KEGG pathways to determine which modules are affected or dysregulated in the disease. However, genes acting in multiple pathways and other inherent issues complicate such analyses. Many current approaches may only employ gene expression data and need to pay more attention to some of the existing knowledge stored in KEGG pathways for detecting dysregulated pathways. New methods that consider more precompiled information are required for a more holistic association between gene expression and diseases.",5,"Cell homeostasis relies on the concerted actions of genes, and dysregulated genes can lead to diseases."
Double-head transformer neural network for molecular property prediction.,36823530,https://pubmed.ncbi.nlm.nih.gov/36823530/,https://doi.org/10.1186/s13321-023-00700-4,"['Deep learning', 'Molecular property prediction', 'Residual network', 'Transformer']","Existing molecular property prediction methods based on deep learning ignore the generalization ability of the nonlinear representation of molecular features and the reasonable assignment of weights of molecular features, making it difficult to further improve the accuracy of molecular property prediction. To solve the above problems, an end-to-end double-head transformer neural network (DHTNN) is proposed in this paper for high-precision molecular property prediction. For the data distribution characteristics of the molecular dataset, DHTNN specially designs a new activation function, beaf, which can greatly improve the generalization ability of the nonlinear representation of molecular features. A residual network is introduced in the molecular encoding part to solve the gradient explosion problem and ensure that the model can converge quickly. The transformer based on double-head attention is used to extract molecular intrinsic detail features, and the weights are reasonably assigned for predicting molecular properties with high accuracy. Our model, which was tested on the MoleculeNet [1] benchmark dataset, showed significant performance improvements over other state-of-the-art methods.",2,Existing molecular property prediction methods based on deep learning ignore the generalization ability of the nonlinear representation of molecular features.
HIT-2: Implementing machine learning algorithms to treat bound ions in biomolecules.,36817955,https://pubmed.ncbi.nlm.nih.gov/36817955/,https://doi.org/10.1016/j.csbj.2023.02.013,"['Bound ions', 'Delphi', 'Electrostatic calculation', 'Explicit solvent model', 'Implicit solvent model']","Electrostatic features are fundamental to protein functions and protein-protein interactions. Studying highly charged biomolecules is challenging given the heterogeneous distribution of the ionic cloud around such biomolecules. Here we report a new computational method, Hybridizing Ions Treatment-2 (HIT-2), which is used to model biomolecule-bound ions using the implicit solvation model. By modeling ions, HIT-2 allows the user to calculate important electrostatic features of the biomolecules. HIT-2 applies an efficient algorithm to calculate the position of bound ions from molecular dynamics simulations. Modeling parameters were optimized by machine learning methods from thousands of datasets. The optimized parameters produced results with errors lower than 0.2 Å. The testing results on bound Ca",1,Electrostatic features are fundamental to protein functions and protein-protein interactions.
Deep learning facilitates multi-data type analysis and predictive biomarker discovery in cancer precision medicine.,36817954,https://pubmed.ncbi.nlm.nih.gov/36817954/,https://doi.org/10.1016/j.csbj.2023.01.043,"['Cancer', 'Deep learning', 'Oncogene', 'Precision medicine', 'Reinforcement learning', 'Systems medicine']","Cancer progression is linked to gene-environment interactions that alter cellular homeostasis. The use of biomarkers as early indicators of disease manifestation and progression can substantially improve diagnosis and treatment. Large omics datasets generated by high-throughput profiling technologies, such as microarrays, RNA sequencing, whole-genome shotgun sequencing, nuclear magnetic resonance, and mass spectrometry, have enabled data-driven biomarker discoveries. The identification of differentially expressed traits as molecular markers has traditionally relied on statistical techniques that are often limited to linear parametric modeling. The heterogeneity, epigenetic changes, and high degree of polymorphism observed in oncogenes demand biomarker-assisted personalized medication schemes. Deep learning (DL), a major subunit of machine learning (ML), has been increasingly utilized in recent years to investigate various diseases. The combination of ML/DL approaches for performance optimization across multi-omics datasets produces robust ensemble-learning prediction models, which are becoming useful in precision medicine. This review focuses on the recent development of ML/DL methods to provide integrative solutions in discovering cancer-related biomarkers, and their utilization in precision medicine.",3,Cancer progression is linked to gene-environment interactions that alter cellular homeostasis.
Kinome inhibition states and multiomics data enable prediction of cell viability in diverse cancer types.,36809237,https://pubmed.ncbi.nlm.nih.gov/36809237/,https://doi.org/10.1371/journal.pcbi.1010888,[],"Protein kinases play a vital role in a wide range of cellular processes, and compounds that inhibit kinase activity emerging as a primary focus for targeted therapy development, especially in cancer. Consequently, efforts to characterize the behavior of kinases in response to inhibitor treatment, as well as downstream cellular responses, have been performed at increasingly large scales. Previous work with smaller datasets have used baseline profiling of cell lines and limited kinome profiling data to attempt to predict small molecule effects on cell viability, but these efforts did not use multi-dose kinase profiles and achieved low accuracy with very limited external validation. This work focuses on two large-scale primary data types, kinase inhibitor profiles and gene expression, to predict the results of cell viability screening. We describe the process by which we combined these data sets, examined their properties in relation to cell viability and finally developed a set of computational models that achieve a reasonably high prediction accuracy (R2 of 0.78 and RMSE of 0.154). Using these models, we identified a set of kinases, several of which are understudied, that are strongly influential in the cell viability prediction models. In addition, we also tested to see if a wider range of multiomics data sets could improve the model results and found that proteomic kinase inhibitor profiles were the single most informative data type. Finally, we validated a small subset of the model predictions in several triple-negative and HER2 positive breast cancer cell lines demonstrating that the model performs well with compounds and cell lines that were not included in the training data set. Overall, this result demonstrates that generic knowledge of the kinome is predictive of very specific cell phenotypes, and has the potential to be integrated into targeted therapy development pipelines.",2,Protein kinases play a vital role in a wide range of cellular processes.
Pathogen detection in RNA-seq data with Pathonoia.,36803415,https://pubmed.ncbi.nlm.nih.gov/36803415/,https://doi.org/10.1186/s12859-023-05144-z,"['Metagenomics', 'Pathogen detection', 'RNA sequencing']","Bacterial and viral infections may cause or exacerbate various human diseases and to detect microbes in tissue, one method of choice is RNA sequencing. The detection of specific microbes using RNA sequencing offers good sensitivity and specificity, but untargeted approaches suffer from high false positive rates and a lack of sensitivity for lowly abundant organisms.",1," RNA sequencing offers good sensitivity and specificity, but untargeted approaches suffer from high false positive rates and lack of sensitivity for lowly abundant organisms."
Deafness gene screening based on a multilevel cascaded BPNN model.,36803022,https://pubmed.ncbi.nlm.nih.gov/36803022/,https://doi.org/10.1186/s12859-023-05182-7,"['Backpropagation neural network', 'Cascaded BPNN model', 'Highly suspected deafness-related genes', 'Sudden sensorineural hearing loss']","Sudden sensorineural hearing loss is a common and frequently occurring condition in otolaryngology. Existing studies have shown that sudden sensorineural hearing loss is closely associated with mutations in genes for inherited deafness. To identify these genes associated with deafness, researchers have mostly used biological experiments, which are accurate but time-consuming and laborious. In this paper, we proposed a computational method based on machine learning to predict deafness-associated genes. The model is based on several basic backpropagation neural networks (BPNNs), which were cascaded as multiple-level BPNN models. The cascaded BPNN model showed a stronger ability for screening deafness-associated genes than the conventional BPNN. A total of 211 of 214 deafness-associated genes from the deafness variant database (DVD v9.0) were used as positive data, and 2110 genes extracted from chromosomes were used as negative data to train our model. The test achieved a mean AUC higher than 0.98. Furthermore, to illustrate the predictive performance of the model for suspected deafness-associated genes, we analyzed the remaining 17,711 genes in the human genome and screened the 20 genes with the highest scores as highly suspected deafness-associated genes. Among these 20 predicted genes, three genes were mentioned as deafness-associated genes in the literature. The analysis showed that our approach has the potential to screen out highly suspected deafness-associated genes from a large number of genes, and our predictions could be valuable for future research and discovery of deafness-associated genes.",1,Sudden sensorineural hearing loss is closely associated with mutations in genes for inherited deafness.
Systematic Description of the Content Variation of Natural Products (NPs): To Prompt the Yield of High-Value NPs and the Discovery of New Therapeutics.,36795011,https://pubmed.ncbi.nlm.nih.gov/36795011/,https://doi.org/10.1021/acs.jcim.2c01459,[],"Natural products (NPs) have long been associated with human production and play a key role in the survival of species. Significant variations in NP content may severely affect the ""return on investment"" of NP-based industries and render ecological systems vulnerable. Thus, it is crucial to construct a platform that relates variations in NP content to their corresponding mechanisms. In this study, a publicly accessible online platform, NPcVar (http://npcvar.idrblab.net/), was developed, which systematically described the variations of NP contents and their corresponding mechanisms. The platform comprises 2201 NPs and 694 biological resources, including plants, bacteria, and fungi, curated using 126 diverse factors with 26,425 records. Each record contains information about the species, NP, and factors involved, as well as NP content data, parts of the plant that produce NPs, the location of the experiment, and reference information. All factors were manually curated and categorized into 42 classes which belong to four mechanisms (molecular regulation, species factor, environmental condition, and combined factor). Additionally, the cross-links of species and NP to well-established databases and the visualization of NP content under various experimental conditions were provided. In conclusion, NPcVar is a valuable resource for understanding the relationship between species, factors, and NP contents and is anticipated to serve as a promising tool for improving the yield of high-value NPs and facilitating the development of new therapeutics.",1,Natural products (NPs) have long been associated with human production and play a key role in the survival of species.
VirBot: an RNA viral contig detector for metagenomic data.,36794927,https://pubmed.ncbi.nlm.nih.gov/36794927/,https://doi.org/10.1093/bioinformatics/btad093,[],"Without relying on cultivation, metagenomic sequencing greatly accelerated the novel RNA virus detection. However, it is not trivial to accurately identify RNA viral contigs from a mixture of species. The low content of RNA viruses in metagenomic data requires a highly specific detector, while new RNA viruses can exhibit high genetic diversity, posing a challenge for alignment-based tools. In this work, we developed VirBot, a simple yet effective RNA virus identification tool based on the protein families and the corresponding adaptive score cutoffs. We benchmarked it with seven popular tools for virus identification on both simulated and real sequencing data. VirBot shows its high specificity in metagenomic datasets and superior sensitivity in detecting novel RNA viruses.",1,VirBot is a simple yet effective RNA virus identification tool based on the protein families and the corresponding adaptive score cutoffs.
LDmat: efficiently queryable compression of linkage disequilibrium matrices.,36794924,https://pubmed.ncbi.nlm.nih.gov/36794924/,https://doi.org/10.1093/bioinformatics/btad092,[],"Linkage disequilibrium (LD) matrices derived from large populations are widely used in population genetics in fine-mapping, LD score regression, and linear mixed models for Genome-wide Association Studies (GWAS). However, these matrices can reach large sizes when they are derived from millions of individuals; hence, moving, sharing and extracting granular information from this large amount of data can be cumbersome.",1,Linkage disequilibrium (LD) matrices derived from large populations are widely used in population genetics.
Persistent Tor-algebra for protein-protein interaction analysis.,36790858,https://pubmed.ncbi.nlm.nih.gov/36790858/,https://doi.org/10.1093/bib/bbad046,[],"Protein-protein interactions (PPIs) play crucial roles in almost all biological processes from cell-signaling and membrane transport to metabolism and immune systems. Efficient characterization of PPIs at the molecular level is key to the fundamental understanding of PPI mechanisms. Even with the gigantic amount of PPI models from graphs, networks, geometry and topology, it remains as a great challenge to design functional models that efficiently characterize the complicated multiphysical information within PPIs. Here we propose persistent Tor-algebra (PTA) model for a unified algebraic representation of the multiphysical interactions. Mathematically, our PTA is inherently algebraic data analysis. In our PTA model, protein structures and interactions are described as a series of face rings and Tor modules, from which PTA model is developed. The multiphysical information within/between biomolecules are implicitly characterized by PTA and further represented as PTA barcodes. To test our PTA models, we consider PTA-based ensemble learning for PPI binding affinity prediction. The two most commonly used datasets, i.e. SKEMPI and AB-Bind, are employed. It has been found that our model outperforms all the existing models as far as we know. Mathematically, our PTA model provides a highly efficient way for the characterization of molecular structures and interactions.",1,Protein-protein interactions (PPIs) play crucial roles in almost all biological processes.
MDBuilder: a PyMOL plugin for the preparation of molecular dynamics simulations.,36790845,https://pubmed.ncbi.nlm.nih.gov/36790845/,https://doi.org/10.1093/bib/bbad057,"['AMBER', 'CHARMM', 'NAMD', 'PyMOL', 'biomolecular simulations', 'molecular dynamics']","The preprocessed initial files that feed the molecular dynamics (MD) simulation packages dramatically influence the outcome of the simulations. However, the popular MD simulation packages depend, to a great extent, on the user's experience in the preparation of MD simulation systems. In this work, we present an easy-to-use tool called MDBuilder, a PyMOL plugin that assists researchers in building the starting structures for multiple popular MD simulation packages. MDBuilder is not only designed to assist MD beginners to overcome the steep learning curve by providing a menu-oriented, point-and-click user graphic interface (GUI), but also to provide an alternative way to prepare the input files for some highly scalable CHARMM force field-based MD simulation packages. The platform-independent GUI is implemented as a PyMOL plugin using the Python language, and it has been tested on Windows and Linux platforms. The source code and documentation of MDBuilder can be downloaded freely from https://github.com/HuiLiuCode/MDBuilder under the GNU General Public License.",2,MDBuilder is a PyMOL plugin that assists researchers in building the starting structures for multiple popular MD simulation packages.
Using High-Throughput Molecular Dynamics Simulation to Enhance the Computational Design of Kemp Elimination Enzymes.,36782360,https://pubmed.ncbi.nlm.nih.gov/36782360/,https://doi.org/10.1021/acs.jcim.3c00002,[],"Computational enzyme design has been successfully applied to identify new alternatives to natural enzymes for the biosynthesis of important compounds. However, the moderate catalytic activities of de novo designed enzymes indicate that the modeling accuracy of current computational enzyme design methods should be improved. Here, high-throughput molecular dynamics simulations were used to enhance computational enzyme design, thus allowing the identification of variants with higher activities in silico. Different time schemes of high-throughput molecular dynamics simulations were tested to identify the catalytic features of evolved Kemp eliminases. The 20 × 1 ns molecular dynamics simulation scheme was sufficiently accurate and computationally viable to screen the computationally designed massive variants of Kemp elimination enzymes. The developed hybrid computational strategy was used to redesign the most active Kemp eliminase, HG3.17, and five variants were generated and experimentally confirmed to afford higher catalytic efficiencies than that of HG3.17, with one double variant (D52Q/A53S) exhibiting a 55% increase. The hybrid computational enzyme design strategy is general and computationally economical, with which we anticipate the efficient creation of practical enzymes for industrial biocatalysis.",1, Computational enzyme design has been successfully applied to identify new alternatives to natural enzymes for the biosynthesis of important compounds.
Global reactivity models are impactful in industrial synthesis applications.,36774523,https://pubmed.ncbi.nlm.nih.gov/36774523/,https://doi.org/10.1186/s13321-023-00685-0,[],"Artificial Intelligence is revolutionizing many aspects of the pharmaceutical industry. Deep learning models are now routinely applied to guide drug discovery projects leading to faster and improved findings, but there are still many tasks with enormous unrealized potential. One such task is the reaction yield prediction. Every year more than one fifth of all synthesis attempts result in product yields which are either zero or too low. This equates to chemical and human resources being spent on activities which ultimately do not progress the programs, leading to a triple loss when accounting for the cost of opportunity in time wasted. In this work we pre-train a BERT model on more than 16 million reactions from 4 different data sources, and fine tune it to achieve an uncertainty calibrated global yield prediction model. This model is an improvement upon state of the art not just from the increase in pre-train data but also by introducing a new embedding layer which solves a few limitations of SMILES and enables integration of additional information such as equivalents and molecule role into the reaction encoding, the model is called BERT Enriched Embedding (BEE). The model is benchmarked on an open-source dataset against a state-of-the-art synthesis focused BERT showing a near 20-point improvement in r2 score. The model is fine-tuned and tested on an internal company data benchmark, and a prospective study shows that the application of the model can reduce the total number of negative reactions (yield under 5%) ran in Janssen by at least 34%. Lastly, we corroborate the previous results through experimental validation, by directly deploying the model in an on-going drug discovery project and showing that it can also be used successfully as a reagent recommender due to its fast inference speed and reliable confidence estimation, a critical feature for industry application.",3,Every year more than one fifth of all synthesis attempts result in product yields which are either zero or too low.
A computational framework of routine test data for the cost-effective chronic disease prediction.,36772998,https://pubmed.ncbi.nlm.nih.gov/36772998/,https://doi.org/10.1093/bib/bbad054,"['biochemical test', 'chronic diseases', 'machine learning', 'prediction', 'routine blood test']","Chronic diseases, because of insidious onset and long latent period, have become the major global disease burden. However, the current chronic disease diagnosis methods based on genetic markers or imaging analysis are challenging to promote completely due to high costs and cannot reach universality and popularization. This study analyzed massive data from routine blood and biochemical test of 32 448 patients and developed a novel framework for cost-effective chronic disease prediction with high accuracy (AUC 87.32%). Based on the best-performing XGBoost algorithm, 20 classification models were further constructed for 17 types of chronic diseases, including 9 types of cancers, 5 types of cardiovascular diseases and 3 types of mental illness. The highest accuracy of the model was 90.13% for cardia cancer, and the lowest was 76.38% for rectal cancer. The model interpretation with the SHAP algorithm showed that CREA, R-CV, GLU and NEUT% might be important indices to identify the most chronic diseases. PDW and R-CV are also discovered to be crucial indices in classifying the three types of chronic diseases (cardiovascular disease, cancer and mental illness). In addition, R-CV has a higher specificity for cancer, ALP for cardiovascular disease and GLU for mental illness. The association between chronic diseases was further revealed. At last, we build a user-friendly explainable machine-learning-based clinical decision support system (DisPioneer: http://bioinfor.imu.edu.cn/dispioneer) to assist in predicting, classifying and treating chronic diseases. This cost-effective work with simple blood tests will benefit more people and motivate clinical implementation and further investigation of chronic diseases prevention and surveillance program.",1,The study analyzed massive data from routine blood and biochemical test of 32 448 patients.
Mechanism of Calcium Permeation in a Glutamate Receptor Ion Channel.,36758214,https://pubmed.ncbi.nlm.nih.gov/36758214/,https://doi.org/10.1021/acs.jcim.2c01494,[],"The α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid receptors (AMPARs) are neurotransmitter-activated cation channels ubiquitously expressed in vertebrate brains. The regulation of calcium flux through the channel pore by RNA-editing is linked to synaptic plasticity while excessive calcium influx poses a risk for neurodegeneration. Unfortunately, the molecular mechanisms underlying this key process are mostly unknown. Here, we investigated calcium conduction in calcium-permeable AMPAR using Molecular Dynamics (MD) simulations with recently introduced multisite force-field parameters for Ca",6,AMPARs are neurotransmitter-activated cation channels ubiquitously expressed in vertebrate brains.
"An electrophysiological and kinematic model of Paramecium, the ""swimming neuron"".",36758112,https://pubmed.ncbi.nlm.nih.gov/36758112/,https://doi.org/10.1371/journal.pcbi.1010899,[],"Paramecium is a large unicellular organism that swims in fresh water using cilia. When stimulated by various means (mechanically, chemically, optically, thermally), it often swims backward then turns and swims forward again in a new direction: this is called the avoiding reaction. This reaction is triggered by a calcium-based action potential. For this reason, several authors have called Paramecium the ""swimming neuron"". Here we present an empirically constrained model of its action potential based on electrophysiology experiments on live immobilized paramecia, together with simultaneous measurement of ciliary beating using particle image velocimetry. Using these measurements and additional behavioral measurements of free swimming, we extend the electrophysiological model by coupling calcium concentration to kinematic parameters, turning it into a swimming model. In this way, we obtain a model of autonomously behaving Paramecium. Finally, we demonstrate how the modeled organism interacts with an environment, can follow gradients and display collective behavior. This work provides a modeling basis for investigating the physiological basis of autonomous behavior of Paramecium in ecological environments.",4,Paramecium is a large unicellular organism that swims in fresh water using cilia.
iPRESTO: Automated discovery of biosynthetic sub-clusters linked to specific natural product substructures.,36758069,https://pubmed.ncbi.nlm.nih.gov/36758069/,https://doi.org/10.1371/journal.pcbi.1010462,[],"Microbial specialised metabolism is full of valuable natural products that are applied clinically, agriculturally, and industrially. The genes that encode their biosynthesis are often physically clustered on the genome in biosynthetic gene clusters (BGCs). Many BGCs consist of multiple groups of co-evolving genes called sub-clusters that are responsible for the biosynthesis of a specific chemical moiety in a natural product. Sub-clusters therefore provide an important link between the structures of a natural product and its BGC, which can be leveraged for predicting natural product structures from sequence, as well as for linking chemical structures and metabolomics-derived mass features to BGCs. While some initial computational methodologies have been devised for sub-cluster detection, current approaches are not scalable, have only been run on small and outdated datasets, or produce an impractically large number of possible sub-clusters to mine through. Here, we constructed a scalable method for unsupervised sub-cluster detection, called iPRESTO, based on topic modelling and statistical analysis of co-occurrence patterns of enzyme-coding protein families. iPRESTO was used to mine sub-clusters across 150,000 prokaryotic BGCs from antiSMASH-DB. After annotating a fraction of the resulting sub-cluster families, we could predict a substructure for 16% of the antiSMASH-DB BGCs. Additionally, our method was able to confirm 83% of the experimentally characterised sub-clusters in MIBiG reference BGCs. Based on iPRESTO-detected sub-clusters, we could correctly identify the BGCs for xenorhabdin and salbostatin biosynthesis (which had not yet been annotated in BGC databases), as well as propose a candidate BGC for akashin biosynthesis. Additionally, we show for a collection of 145 actinobacteria how substructures can aid in linking BGCs to molecules by correlating iPRESTO-detected sub-clusters to MS/MS-derived Mass2Motifs substructure patterns. This work paves the way for deeper functional and structural annotation of microbial BGCs by improved linking of orphan molecules to their cognate gene clusters, thus facilitating accelerated natural product discovery.",1,The genes that encode their biosynthesis are often physically clustered on the genome in biosynthetic gene clusters (BGCs) Many BGCs consist of multiple groups of co-ev
UV-Resonance Raman Spectra of Systems in Complex Environments: A Multiscale Modeling Applied to Doxorubicin Intercalated into DNA.,36745496,https://pubmed.ncbi.nlm.nih.gov/36745496/,https://doi.org/10.1021/acs.jcim.2c01495,[],"UV-Resonance Raman (RR) spectroscopy is a valuable tool to study the binding of drugs to biomolecular receptors. The extraction of information at the molecular level from experimental RR spectra is made much easier and more complete thanks to the use of computational approaches, specifically tuned to deal with the complexity of the supramolecular system. In this paper, we propose a protocol to simulate RR spectra of complex systems at different levels of sophistication, by exploiting a quantum mechanics/molecular mechanics (QM/MM) approach. The approach is challenged to investigate RR spectra of a widely used chemotherapy drug, doxorubicin (DOX) intercalated into a DNA double strand. The computed results show good agreement with experimental data, thus confirming the reliability of the computational protocol.",3, UV-Resonance Raman (RR) spectroscopy is a valuable tool to study the binding of drugs to biomolecular receptors.
PALM: a powerful and adaptive latent model for prioritizing risk variants with functional annotations.,36744920,https://pubmed.ncbi.nlm.nih.gov/36744920/,https://doi.org/10.1093/bioinformatics/btad068,[],"The findings from genome-wide association studies (GWASs) have greatly helped us to understand the genetic basis of human complex traits and diseases. Despite the tremendous progress, much effects are still needed to address several major challenges arising in GWAS. First, most GWAS hits are located in the non-coding region of human genome, and thus their biological functions largely remain unknown. Second, due to the polygenicity of human complex traits and diseases, many genetic risk variants with weak or moderate effects have not been identified yet.",1,The findings from genome-wide association studies (GWASs) have greatly helped us to understand the genetic basis of human complex traits and diseases.
Cuproptosis-related lncRNA signature for prognostic prediction in patients with acute myeloid leukemia.,36737692,https://pubmed.ncbi.nlm.nih.gov/36737692/,https://doi.org/10.1186/s12859-023-05148-9,"['Acute myeloid leukemia', 'Cuproptosis', 'Prognostic prediction', 'Tumor immunity', 'lncRNA signature']","Long non-coding RNAs (lncRNAs) have been reported to have a crucial impact on the pathogenesis of acute myeloid leukemia (AML). Cuproptosis, a copper-triggered modality of mitochondrial cell death, might serve as a promising therapeutic target for cancer treatment and clinical outcome prediction. Nevertheless, the role of cuproptosis-related lncRNAs in AML is not fully understood.",3,Long non-coding RNAs (lncRNAs) have been reported to have a crucial impact on the pathogenesis of acute myeloid leukemia (AML) Cupro
Benefit-aware early prediction of health outcomes on multivariate EEG time series.,36736937,https://pubmed.ncbi.nlm.nih.gov/36736937/,https://doi.org/10.1016/j.jbi.2023.104296,"['EEG', 'Early classification', 'Multivariate time series']","Given a cardiac-arrest patient being monitored in the ICU (intensive care unit) for brain activity, how can we predict their health outcomes as early as possible? Early decision-making is critical in many applications, e.g. monitoring patients may assist in early intervention and improved care. On the other hand, early prediction on EEG data poses several challenges: (i) earliness-accuracy trade-off; observing more data often increases accuracy but sacrifices earliness, (ii) large-scale (for training) and streaming (online decision-making) data processing, and (iii) multi-variate (due to multiple electrodes) and multi-length (due to varying length of stay of patients) time series. Motivated by this real-world application, we present BeneFitter that infuses the incurred savings from an early prediction as well as the cost from misclassification into a unified domain-specific target called benefit. Unifying these two quantities allows us to directly estimate a single target (i.e. benefit), and importantly, (a) is efficient and fast, with training time linear in the number of input sequences, and can operate in real-time for decision-making, (b) can handle multi-variate and variable-length time-series, suitable for patient data, and (c) is effective, providing up to 2× time-savings with equal or better accuracy as compared to competitors.",1,"Early decision-making is critical in many applications, e.g. monitoring patients may assist in early intervention and improved care."
GACNNMDA: a computational model for predicting potential human microbe-drug associations based on graph attention network and CNN-based classifier.,36732704,https://pubmed.ncbi.nlm.nih.gov/36732704/,https://doi.org/10.1186/s12859-023-05158-7,"['Computational model', 'Convolutional neural network', 'Graph attention network', 'Microbe-drug associations', 'Prediction model']","As new drug targets, human microbes are proven to be closely related to human health. Effective computational methods for inferring potential microbe-drug associations can provide a useful complement to conventional experimental methods and will facilitate drug research and development. However, it is still a challenging work to predict potential interactions for new microbes or new drugs, since the number of known microbe-drug associations is very limited at present. In this manuscript, we first constructed two heterogeneous microbe-drug networks based on multiple measures of similarity of microbes and drugs, and known microbe-drug associations or known microbe-disease-drug associations, respectively. And then, we established two feature matrices for microbes and drugs through concatenating various attributes of microbes and drugs. Thereafter, after taking these two feature matrices and two heterogeneous microbe-drug networks as inputs of a two-layer graph attention network, we obtained low dimensional feature representations for microbes and drugs separately. Finally, through integrating low dimensional feature representations with two feature matrices to form the inputs of a convolutional neural network respectively, a novel computational model named GACNNMDA was designed to predict possible scores of microbe-drug pairs. Experimental results show that the predictive performance of GACNNMDA is superior to existing advanced methods. Furthermore, case studies on well-known microbes and drugs demonstrate the effectiveness of GACNNMDA as well. Source codes and supplementary materials are available at: https://github.com/tyqGitHub/TYQ/tree/master/GACNNMDA.",1,The number of known microbe-drug associations is very limited at present. A novel computational model named GACNNMDA was designed to predict possible scores.
Causal knowledge graph construction and evaluation for clinical decision support of diabetic nephropathy.,36731730,https://pubmed.ncbi.nlm.nih.gov/36731730/,https://doi.org/10.1016/j.jbi.2023.104298,"['Causal knowledge', 'Diabetic nephropathy', 'Electronic health record', 'Knowledge graph']","Many important clinical decisions require causal knowledge (CK) to take action. Although many causal knowledge bases for medicine have been constructed, a comprehensive evaluation based on real-world data and methods for handling potential knowledge noise are still lacking.",2,Many important clinical decisions require causal knowledge (CK) to take action.
Systematic and benchmarking studies of pipelines for mammal WGBS data in the novel NGS platform.,36721080,https://pubmed.ncbi.nlm.nih.gov/36721080/,https://doi.org/10.1186/s12859-023-05163-w,"['5-mC', 'BS-Seeker2', 'BSBolt', 'BSMAP', 'BatMeth2', 'Bismark', 'Epigenetics', 'GenoLab M', 'NovaSeq 6000']","Whole genome bisulfite sequencing (WGBS), possesses the aptitude to dissect methylation status at the nucleotide-level resolution of 5-methylcytosine (5-mC) on a genome-wide scale. It is a powerful technique for epigenome in various cell types, and tissues. As a recently established next-generation sequencing (NGS) platform, GenoLab M is a promising alternative platform. However, its comprehensive evaluation for WGBS has not been reported. We sequenced two bisulfite-converted mammal DNA in this research using our GenoLab M and NovaSeq 6000, respectively. Then, we systematically compared those data via four widely used WGBS tools (BSMAP, Bismark, BatMeth2, BS-Seeker2) and a new bisulfite-seq tool (BSBolt). We interrogated their computational time, genome depth and coverage, and evaluated their percentage of methylated Cs.",1,Whole genome bisulfite sequencing (WGBS) possesses the aptitude to dissect methylation status at the nucleotide-level resolution of 5-methylcytosine (
What Has Genomics Taught An Evolutionary Biologist?,36720382,https://pubmed.ncbi.nlm.nih.gov/36720382/,https://doi.org/10.1016/j.gpb.2023.01.005,"['Evolution', 'Genetics', 'Interaction', 'Mutation', 'Selection', 'Variation']","Genomics, an interdisciplinary field of biology on the structure, function, and evolution of genomes, has revolutionized many subdisciplines of life sciences, including my field of evolutionary biology, by supplying huge data, bringing high-throughput technologies, and offering a new approach to biology. In this review, I describe what I have learned from genomics and highlight the fundamental knowledge and mechanistic insights gained. I focus on three broad topics that are central to evolutionary biology and beyond-variation, interaction, and selection-and use primarily my own research and study subjects as examples. In the next decade or two, I expect that the most important contributions of genomics to evolutionary biology will be to provide genome sequences of nearly all known species on Earth, facilitate high-throughput phenotyping of natural variants and systematically constructed mutants for mapping genotype-phenotype-fitness landscapes, and assist the determination of causality in evolutionary processes using experimental evolution.",1,"Genomics has revolutionized many subdisciplines of life sciences, including my field of evolutionary biology."
An interpretable machine learning approach to multimodal stress detection in a simulated office environment.,36720332,https://pubmed.ncbi.nlm.nih.gov/36720332/,https://doi.org/10.1016/j.jbi.2023.104299,"['Heart rate variability', 'Interpretability', 'Keystroke dynamics', 'Machine learning', 'Mouse movements', 'Stress detection']","Work-related stress affects a large part of today's workforce and is known to have detrimental effects on physical and mental health. Continuous and unobtrusive stress detection may help prevent and reduce stress by providing personalised feedback and allowing for the development of just-in-time adaptive health interventions for stress management. Previous studies on stress detection in work environments have often struggled to adequately reflect real-world conditions in controlled laboratory experiments. To close this gap, in this paper, we present a machine learning methodology for stress detection based on multimodal data collected from unobtrusive sources in an experiment simulating a realistic group office environment (N=90).",1,Work-related stress affects a large part of today's workforce. It is known to have detrimental effects on physical and mental health.
TIVAN-indel: a computational framework for annotating and predicting non-coding regulatory small insertions and deletions.,36707993,https://pubmed.ncbi.nlm.nih.gov/36707993/,https://doi.org/10.1093/bioinformatics/btad060,[],"Small insertion and deletion (sindel) of human genome has an important implication for human disease. One important mechanism for non-coding sindel (nc-sindel) to have an impact on human diseases and phenotypes is through the regulation of gene expression. Nevertheless, current sequencing experiments may lack statistical power and resolution to pinpoint the functional sindel due to lower minor allele frequency or small effect size. As an alternative strategy, a supervised machine learning method can identify the otherwise masked functional sindels by predicting their regulatory potential directly. However, computational methods for annotating and predicting the regulatory sindels, especially in the non-coding regions, are underdeveloped.",2,Small insertion and deletion (sindel) of human genome has an important implication for human disease.
Potent antibiotic design via guided search from antibacterial activity evaluations.,36707990,https://pubmed.ncbi.nlm.nih.gov/36707990/,https://doi.org/10.1093/bioinformatics/btad059,[],"The emergence of drug-resistant bacteria makes the discovery of new antibiotics an urgent issue, but finding new molecules with the desired antibacterial activity is an extremely difficult task. To address this challenge, we established a framework, MDAGS (Molecular Design via Attribute-Guided Search), to optimize and generate potent antibiotic molecules.",12,The emergence of drug-resistant bacteria makes the discovery of new antibiotics an urgent issue.
Preventing AI From Creating Biochemical Threats.,36696568,https://pubmed.ncbi.nlm.nih.gov/36696568/,https://doi.org/10.1021/acs.jcim.2c01616,[],"We have previously applied our machine learning models for bioactivity and toxicity along with a generative algorithm to develop VX and tens of thousands of analogues. The publication brought attention to the ease of designing chemical warfare agents. In this Viewpoint, we discuss 10 recommendations to prevent future biochemical threats.",1,We have previously applied our machine learning models for bioactivity and toxicity along with a generative algorithm to develop VX and tens of thousands of analogues.
Chemical Descriptors for a Large-Scale Study on Drop-Weight Impact Sensitivity of High Explosives.,36695777,https://pubmed.ncbi.nlm.nih.gov/36695777/,https://doi.org/10.1021/acs.jcim.2c01154,[],"The drop-weight impact test is an experiment that has been used for nearly 80 years to evaluate handling sensitivity of high explosives. Although the results of this test are known to have large statistical uncertainties, it is one of the most common tests due to its accessibility and modest material requirements. In this paper, we compile a large data set of drop-weight impact sensitivity test results (mainly performed at Los Alamos National Laboratory), along with a compendium of molecular and chemical descriptors for the explosives under test. These data consist of over 500 unique explosives, over 1000 repeat tests, and over 100 descriptors, for a total of about 1500 observations. We use random forest methods to estimate a model of explosive handling sensitivity as a function of chemical and molecular properties of the explosives under test. Our model predicts well across a wide range of explosive types, spanning a broad range of explosive performance and sensitivity. We find that properties related to explosive performance, such as heat of explosion, oxygen balance, and functional group, are highly predictive of explosive handling sensitivity. Yet, models that omit many of these properties still perform well. Our results suggest that there is not one or even several factors that explain explosive handling sensitivity, but that there are many complex, interrelated effects at play.",1,The drop-weight impact test is an experiment that has been used for nearly 80 years to evaluate handling sensitivity of high explosives.
Fast and automated protein-DNA/RNA macromolecular complex modeling from cryo-EM maps.,36682003,https://pubmed.ncbi.nlm.nih.gov/36682003/,https://doi.org/10.1093/bib/bbac632,"['artificial intelligence', 'cryo-EM', 'machine learning', 'macromolecular modeling', 'protein-DNA/RNA']","Cryo-electron microscopy (cryo-EM) allows a macromolecular structure such as protein-DNA/RNA complexes to be reconstructed in a three-dimensional coulomb potential map. The structural information of these macromolecular complexes forms the foundation for understanding the molecular mechanism including many human diseases. However, the model building of large macromolecular complexes is often difficult and time-consuming. We recently developed DeepTracer-2.0, an artificial-intelligence-based pipeline that can build amino acid and nucleic acid backbones from a single cryo-EM map, and even predict the best-fitting residues according to the density of side chains. The experiments showed improved accuracy and efficiency when benchmarking the performance on independent experimental maps of protein-DNA/RNA complexes and demonstrated the promising future of macromolecular modeling from cryo-EM maps. Our method and pipeline could benefit researchers worldwide who work in molecular biomedicine and drug discovery, and substantially increase the throughput of the cryo-EM model building. The pipeline has been integrated into the web portal https://deeptracer.uw.edu/.",6,Cryo-electron microscopy allows a macromolecular structure such as protein-DNA/RNA complexes to be reconstructed in a three-dimensional coulomb potential map.
Hierarchical cell-type identifier accurately distinguishes immune-cell subtypes enabling precise profiling of tissue microenvironment with single-cell RNA-sequencing.,36681937,https://pubmed.ncbi.nlm.nih.gov/36681937/,https://doi.org/10.1093/bib/bbad006,"['cell-type identifier', 'cell-type markers', 'hierarchical identification', 'single-cell RNA-seq']","Single-cell RNA-seq enabled in-depth study on tissue micro-environment and immune-profiling, where a crucial step is to annotate cell identity. Immune cells play key roles in many diseases, whereas their activities are hard to track due to their diverse and highly variable nature. Existing cell-type identifiers had limited performance for this purpose. We present HiCAT, a hierarchical, marker-based cell-type identifier utilising gene set analysis for statistical scoring for given markers. It features successive identification of major-type, minor-type and subsets utilising subset markers structured in a three-level taxonomy tree. Comparison with manual annotation and pairwise match test showed HiCAT outperforms others in major- and minor-type identification. For subsets, we qualitatively evaluated the marker expression profile demonstrating that HiCAT provide the clearest immune-cell landscape. HiCAT was also used for immune-cell profiling in ulcerative colitis and discovered distinct features of the disease in macrophage and T-cell subsets that could not be identified previously.",2,"Immune cells play key roles in many diseases, whereas their activities are hard to track due to their diverse and highly variable nature."
m,36496129,https://pubmed.ncbi.nlm.nih.gov/36496129/,https://doi.org/10.1016/j.gpb.2022.12.002,"['Embryo', 'Evo-devo', 'Metamorphosis', 'RNA methylation', 'Transcription']",The N,1,"""The N"" is the number of neurons in the human brain."
CNEReg Interprets Ruminant-specific Conserved Non-coding Elements by Developmental Gene Regulatory Network.,36494035,https://pubmed.ncbi.nlm.nih.gov/36494035/,https://doi.org/10.1016/j.gpb.2022.11.007,"['Conserved non-coding element', 'Gene regulatory network', 'Ruminant', 'Toolkit transcription factor', 'Trait innovation']","The genetic information coded in DNA leads to trait innovation via a gene regulatory network (GRN) in development. Here, we developed a conserved non-coding element interpretation method to integrate multi-omics data into gene regulatory network (CNEReg) to investigate the ruminant multi-chambered stomach innovation. We generated paired expression and chromatin accessibility data during rumen and esophagus development in sheep, and revealed 1601 active ruminant-specific conserved non-coding elements (active-RSCNEs). To interpret the function of these active-RSCNEs, we defined toolkit transcription factors (TTFs) and modeled their regulation on rumen-specific genes via batteries of active-RSCNEs during development. Our developmental GRN revealed 18 TTFs and 313 active-RSCNEs regulating 7 rumen functional modules. Notably, 6 TTFs (OTX1, SOX21, HOXC8, SOX2, TP63, and PPARG), as well as 16 active-RSCNEs, functionally distinguished the rumen from the esophagus. Our study provides a systematic approach to understanding how gene regulation evolves and shapes complex traits by putting evo-devo concepts into practice with developmental multi-omics data.",1,The genetic information coded in DNA leads to trait innovation via a gene regulatory network (GRN) in development.
Draft Genome of White-blotched River Stingray Provides Novel Clues for Niche Adaptation and Skeleton Formation.,36470576,https://pubmed.ncbi.nlm.nih.gov/36470576/,https://doi.org/10.1016/j.gpb.2022.11.005,"['De novo genome assembly', 'Niche adaptation', 'Potamotrygon leopoldi', 'Vitamin D-binding protein', 'White-blotched river stingray']","The white-blotched river stingray (Potamotrygon leopoldi) is a cartilaginous fish native to the Xingu River, a tributary of the Amazon River system. As a rare freshwater-dwelling cartilaginous fish in the Potamotrygonidae family in which no member has the genome sequencing information available, P. leopoldi provides the evolutionary details in fish phylogeny, niche adaptation, and skeleton formation. In this study, we present its draft genome of 4.11 Gb comprising 16,227 contigs and 13,238 scaffolds, with contig N50 of 3937 kb and scaffold N50 of 5675 kb in size. Our analysis shows that P. leopoldi is a slow-evolving fish that diverged from elephant sharks about 96 million years ago. Moreover, two gene families related to the immune system (immunoglobulin heavy constant delta genes and T-cell receptor alpha/delta variable genes) exhibit expansion in P. leopoldi only. We also identified the Hox gene clusters in P. leopoldi and discovered that seven Hox genes shared by five representative fish species are missing in P. leopoldi. The RNA sequencing data from P. leopoldi and other three fish species demonstrate that fishes have a more diversified tissue expression spectrum when compared to mammals. Our functional studies suggest that lack of the gc gene encoding vitamin D-binding protein in cartilaginous fishes (both P. leopoldi and Callorhinchus milii) could partly explain the absence of hard bone in their endoskeleton. Overall, this genome resource provides new insights into the niche adaptation, body plan, and skeleton formation of P. leopoldi, as well as the genome evolution in cartilaginous fishes.",1,"The white-blotched river stingray (Potamotrygon leopoldi) is a cartilaginous fish native to the Xingu River, a tribut"
An Attention-Guided CNN Framework for Segmentation and Grading of Glioma Using 3D MRI Scans.,36350865,https://pubmed.ncbi.nlm.nih.gov/36350865/,https://doi.org/10.1109/TCBB.2022.3220902,[],"Glioma has emerged as the deadliest form of brain tumor for human beings. Timely diagnosis of these tumors is a major step towards effective oncological treatment. Magnetic Resonance Imaging (MRI) typically offers a non-invasive inspection of brain lesions. However, manual inspection of tumors from MRI scans requires a large amount of time and it is also an error-prone process. Therefore, automated diagnosis of tumors plays a crucial role in clinical management and surgical interventions of gliomas. In this study, we propose a Convolutional Neural Network (CNN)-based framework for non-invasive grading of tumors from 3D MRI scans. The proposed framework incorporates two novel CNN architectures. The first CNN architecture performs the segmentation of tumors from multimodel MRI volumes. The proposed segmentation network leverages the spatial and channel attention modules to recalibrate the feature maps across the layers. The second network utilizes the multi-task learning strategy to perform the classification based on the three glioma grading tasks which include characterization of tumor into low-grade or high-grade, identification of 1p19q, and Isocitrate Dehydrogenase (IDH) status. We have carried out several experiments to evaluate the performance of our method. Extensive experimental observations indicate that the proposed framework achieves better performance than several state-of-the-art methods. We have also executed Welch's- t test to show the statistical significance of grading results. The source code of this study is available at https://github.com/prasunc/Gliomanet.",2,Glioma has emerged as the deadliest form of brain tumor for human beings. Timely diagnosis of these tumors is a major step towards effective oncological treatment.
BRMCF: Binary Relevance and MLSMOTE Based Computational Framework to Predict Drug Functions From Chemical and Biological Properties of Drugs.,36260591,https://pubmed.ncbi.nlm.nih.gov/36260591/,https://doi.org/10.1109/TCBB.2022.3215645,[],"In silico machine learning based prediction of drug functions considering the drug properties would substantially enhance the speed and reduce the cost of identifying promising drug leads. The drug function prediction capability of different drug properties happens to be different. So assessing these is advantageous in drug discovery. The task of drug function prediction is multi-label in nature reason being, in case of several drugs, multiple functions are associated with a drug. A number of existing works have ignored this inherent multi-label nature of the problem in context of addressing the issue of class imbalance. In the present work, a computational framework named as BRMCF has been proposed for analysing the prediction capability of chemical and biological properties of drugs toward drug functions in view of multi-label nature of problem. It employs Binary Relevance (BR) approach along with five base classifiers for handling the multi-label prediction task and MLSMOTE for addressing the issue of class imbalance. The proposed framework has been validated and compared with BR, Classifier Chains (CC) and Deep Neural Network (DNN) method on four drug properties datasets: SMILES Strings (SS) dataset, 17 Molecular Descriptors (17MD) dataset, Protein Sequences (PS) dataset and drug perturbed Gene EXpression Profiles (GEX) dataset. The analysis of results shows that the proposed framework BRMCF has outperformed BR, CC and DNN method in terms of exact match ratio, precision, recall, F1-score, ROC-AUC which signifies the effectiveness of MLSMOTE. Further, assessment of prediction capability of different drug properties is done and they are ranked as SS GEX PS 17MD. Additionally, the visualization and analysis of drug function co-occurrences signify the appropriateness of the proposed framework for drug function co-occurrence detection and in signaling the new possible drug leads where the detection rate varies from 94.34% to 99.61%.",1,In silico machine learning based prediction of drug functions considering the drug properties would substantially enhance the speed and reduce the cost of identifying promising drug leads.
Quantum-based Modeling of Protein-ligand Interaction: The Complex of RutA with Uracil and Molecular Oxygen.,36259359,https://pubmed.ncbi.nlm.nih.gov/36259359/,https://doi.org/10.1002/minf.202200175,"['flavin-dependent enzyme RutA', 'molecular dynamics', 'oxygenation', 'protein-ligand interaction', 'quantum chemistry']","Modern quantum-based methods are employed to model interaction of the flavin-dependent enzyme RutA with the uracil and oxygen molecules. This complex presents the structure of reactants for the chain of chemical reactions of monooxygenation in the enzyme active site, which is important in drug metabolism. In this case, application of quantum-based approaches is an essential issue, unlike conventional modeling of protein-ligand interaction with force fields using molecular mechanics and classical molecular dynamics methods. We focus on two difficult problems to characterize the structure of reactants in the RutA-FMN-O",1,Modern quantum-based methods are employed to model interaction of the flavin-dependent enzyme RutA with the uracil and oxygen molecules.
Semantic Meta-Path Enhanced Global and Local Topology Learning for lncRNA-Disease Association Prediction.,36173783,https://pubmed.ncbi.nlm.nih.gov/36173783/,https://doi.org/10.1109/TCBB.2022.3209571,[],"Since abnormal expression of long non-coding RNAs (lncRNAs) is associated with various human diseases, identifying disease-related lncRNAs helps reveal the pathogenesis of diseases. Existing methods for lncRNA-disease association prediction mainly focus on multi-sourced data related to lncRNAs and diseases. The rich semantic information of meta-paths, composed of multiple kinds of connections between lncRNA and disease nodes, is neglected. We propose a new prediction method, MGLDA, to encode and integrate the semantics of multiple meta-paths, the global topology of heterogeneous graph, and pairwise attributes of lncRNA and disease nodes. First, a tri-layer heterogeneous graph is constructed to associate multi-sourced data across the lncRNA, disease, and miRNA nodes. Afterwards, we establish multiple meta-paths connecting the lncRNA and disease nodes to derive and denote various semantics. Each meta-path contains its specific semantics formulated by an embedding strategy, and each embedding covers local topology formed by the diverse semantic connections among the lncRNA, disease, and miRNA nodes. We construct multiple graph convolutional autoencoders (GCA) with topology-level attention to learn global and multiple local topologies from the tri-layer graph and each meta-path, respectively. The topology-level attention mechanism can learn the importance of various global and local topologies for adaptive pairwise topology fusion. Finally, a convolutional autoencoder learns the attribute representations of lncRNA-disease pairs, which integrates the learnt detailed and representative pairwise features. Experimental results show that MGLDA outperforms other state-of-the-art prediction methods in comparison and retrieves more real lncRNA-disease associations in the top-ranked candidates. The ablation study also demonstrates the important contributions of the local and global topology learning, and pairwise attribute learning. Case studies on three diseases further demonstrate MGLDA's ability to identify potential disease-related lncRNAs.",2,Identifying disease-related lncRNAs helps reveal the pathogenesis of diseases.
"A Survey on Methods for Predicting Polyadenylation Sites from DNA Sequences, Bulk RNA-seq, and Single-cell RNA-seq.",36167284,https://pubmed.ncbi.nlm.nih.gov/36167284/,https://doi.org/10.1016/j.gpb.2022.09.005,"['Machine learning', 'Polyadenylation', 'Predictive modeling', 'RNA-seq', 'scRNA-seq']","Alternative polyadenylation (APA) plays important roles in modulating mRNA stability, translation, and subcellular localization, and contributes extensively to shaping eukaryotic transcriptome complexity and proteome diversity. Identification of poly(A) sites (pAs) on a genome-wide scale is a critical step toward understanding the underlying mechanism of APA-mediated gene regulation. A number of established computational tools have been proposed to predict pAs from diverse genomic data. Here we provided an exhaustive overview of computational approaches for predicting pAs from DNA sequences, bulk RNA sequencing (RNA-seq) data, and single-cell RNA sequencing (scRNA-seq) data. Particularly, we examined several representative tools using bulk RNA-seq and scRNA-seq data from peripheral blood mononuclear cells and put forward operable suggestions on how to assess the reliability of pAs predicted by different tools. We also proposed practical guidelines on choosing appropriate methods applicable to diverse scenarios. Moreover, we discussed in depth the challenges in improving the performance of pA prediction and benchmarking different methods. Additionally, we highlighted outstanding challenges and opportunities using new machine learning and integrative multi-omics techniques, and provided our perspective on how computational methodologies might evolve in the future for non-3' untranslated region, tissue-specific, cross-species, and single-cell pA prediction.",7,"Alternative polyadenylation (APA) plays important roles in modulating mRNA stability, translation, and subcellular localization."
Application of Microbiome in Forensics.,36031058,https://pubmed.ncbi.nlm.nih.gov/36031058/,https://doi.org/10.1016/j.gpb.2022.07.007,"['Application', 'Bioinformatics', 'Forensics', 'Microbiome', 'Next-generation sequencing']","Recent advances in next-generation sequencing technologies and improvements in bioinformatics have expanded the scope of microbiome analysis as a forensic tool. Microbiome research is concerned with the study of the compositional profile and diversity of microbial flora as well as the interactions between microbes, hosts, and the environment. It has opened up many new possibilities for forensic analysis. In this review, we discuss various applications of microbiome in forensics, including identification of individuals, geolocation inference, and post-mortem interval (PMI) estimation.",4,Microbiome research is concerned with the study of the compositional profile and diversity of microbial flora.
TransCrispr: Transformer Based Hybrid Model for Predicting CRISPR/Cas9 Single Guide RNA Cleavage Efficiency.,36006888,https://pubmed.ncbi.nlm.nih.gov/36006888/,https://doi.org/10.1109/TCBB.2022.3201631,[],"CRISPR/Cas9 is a widely used genome editing tool for site-directed modification of deoxyribonucleic acid (DNA) nucleotide sequences. However, how to accurately predict and evaluate the on- and off-target effects of single guide RNA (sgRNA) is one of the key problems for CRISPR/Cas9 system. Using computational methods to obtain high cell-specific sensitivity and specificity is a prerequisite for the optimal design of sgRNAs. Inspired by the work of predecessors, we found that sgRNA on-target knockout efficacy was not only related to the original sequence but also affected by important biological features. Hence, we introduce a novel approach called TransCrispr, which integrates Transformer and convolutional neural network (CNN) architecture to predict sgRNA knockout efficacy. Firstly, we encode the sequence data and send the transformed sgRNA sequence, positional information, and biological features into the network as input. Then, the convolutional neural network will automatically learn an appropriate feature representation for the sgRNA sequence and combine it with the positional information for self-attention learning of the Transformer. Finally, a regression score is generated by predicting biological features. Experiments on seven public datasets illustrate that TransCrispr outperforms state-of-the-art methods in terms of prediction accuracy and generalization ability.",2,How to accurately predict and evaluate the on- and off-target effects of single guide RNA (sgRNA) is one of the key problems for CRISPR/Cas9 system.
Proposal of SVM Utility Kernel for Breast Cancer Survival Estimation.,35994556,https://pubmed.ncbi.nlm.nih.gov/35994556/,https://doi.org/10.1109/TCBB.2022.3198879,[],"The advancement of medical research in the field of cancer prognosis and diagnosis using various modalities has put oncologists under tremendous stress. The complexity and heterogeneity involved in multiple modalities and their significantly varied clinical outcomes make it difficult to analyze the disease and provide the correct treatment. Breast cancer is the major concern among all cancers worldwide, specifically for females. To help oncologists and cancer patients, research for breast cancer survival estimation has been proposed. It ranges from complex deep neural networks to simple and interpretable architectures. We propose a utility kernel for a support vector machine (SVM) in this article. It is a simple yet powerful function, which performs better than other popular machine learning algorithms and deep neural networks in the task of breast cancer survival prediction using the TCGA-BRCA dataset. This study validates the proposed utility kernel using four different modalities (gene expression, copy number variation, clinical, and histopathological tissue images) and their multi-modal combinations. The SVM based on our utility kernel empirically proves its efficacy by achieving the highest value on various performance measures, whereas advanced deep neural networks fail to train on small and highly imbalanced breast cancer data.",2,The study validates the proposed utility kernel using four different modalities.
Gut Microbiome in Colorectal Cancer: Clinical Diagnosis and Treatment.,35914737,https://pubmed.ncbi.nlm.nih.gov/35914737/,https://doi.org/10.1016/j.gpb.2022.07.002,"['Chemotherapy', 'Colorectal cancer', 'Diagnostic biomarker', 'Gut microbiome', 'Immunotherapy']","Colorectal cancer (CRC) is one of the most frequently diagnosed cancers and the leading cause of cancer-associated deaths. Epidemiological studies have shown that both genetic and environmental risk factors contribute to the development of CRC. Several metagenomic studies of CRC have identified gut dysbiosis as a fundamental risk factor in the evolution of colorectal malignancy. Although enormous efforts and substantial progresses have been made in understanding the relationship between human gut microbiome and CRC, the precise mechanisms involved remain elusive. Recent data have shown a direct causative role of the gut microbiome in DNA damage, inflammation, and drug resistance in CRC, suggesting that modulation of gut microbiome could act as a powerful tool in CRC prevention and therapy. Here, we provide an overview of the relationship between gut microbiome and CRC, and explore relevant mechanisms of colorectal tumorigenesis. We next highlight the potential of bacterial species as clinical biomarkers, as well as their roles in therapeutic response. Factors limiting the clinical translation of gut microbiome and strategies for resolving current challenges are further discussed.",6,Colorectal cancer (CRC) is one of the most frequently diagnosed cancers and the leading cause of cancer-associated deaths.
PiTLiD: Identification of Plant Disease From Leaf Images Based on Convolutional Neural Network.,35914052,https://pubmed.ncbi.nlm.nih.gov/35914052/,https://doi.org/10.1109/TCBB.2022.3195291,[],"With the development of plant phenomics, the identification of plant diseases from leaf images has become an effective and economic approach in plant disease science. Among the methods of plant diseases identification, the convolutional neural network (CNN) is the most popular one for its superior performance. However, CNN's representation power is still a challenge in dealing with small datasets, which greatly affects its popularization. In this work, we propose a new method, namely PiTLiD, based on pretrained Inception-V3 convolutional neural network and transfer learning to identify plant leaf diseases from phenotype data of plant leaf with small sample size. To evaluate the robustness of the proposed method, the experiments on several datasets with small-scale samples were implemented. The results show that PiTLiD performs better than compared methods. This study provides a plant disease identification tool based on a deep learning algorithm for plant phenomics. All the source data and code are accessible at https://github.com/zhanglab-wbgcas/PiTLiD.",4,PiTLiD is based on pretrained Inception-V3 convolutional neural network and transfer learning to identify plant leaf diseases.
Improving miRNA Disease Association Prediction Accuracy Using Integrated Similarity Information and Deep Autoencoders.,35914051,https://pubmed.ncbi.nlm.nih.gov/35914051/,https://doi.org/10.1109/TCBB.2022.3195514,[],"MicroRNAs (miRNAs) are short endogenous non-encoding RNA molecules (22nt) that have a vital role in many biological and molecular processes inside the human body. Abnormal and dysregulated expressions of miRNAs are correlated with many complex disorders. Time-consuming wet-lab biological experiments are costly and labour-intensive. So, the situation demands feasible and efficient computational approaches for predicting promising miRNAs associated with diseases. Here a two-stage feature pruning approach based on miRNA feature similarity fusion that uses deep attention autoencoder and recursive feature elimination with cross-validation (RFECV) is proposed for predicting unknown miRNA-disease associations. In the first stage, an attention autoencoder captures highly influential features from the fused feature vector. For further pruning of features, RFECV is applied. The resultant features were given to a Random Forest classifier for association prediction. The Highest AUC of 94.41% is attained when all miRNA similarity measures are merged with disease similarities. Case studies were done on two diseases-lymphoma and leukaemia, to examine the reliability of the approach. Comparative analysis shows that the proposed approach outperforms recent methodologies for predicting miRNA-disease associations.",2,MicroRNAs (miRNAs) are short endogenous non-encoding RNA molecules (22nt) Abnormal and dysregulated expressions of miRNAs are correlated with many complex disorders
Explaining Black Box Drug Target Prediction Through Model Agnostic Counterfactual Samples.,35820003,https://pubmed.ncbi.nlm.nih.gov/35820003/,https://doi.org/10.1109/TCBB.2022.3190266,[],"Many high-performance DTA deep learning models have been proposed, but they are mostly black-box and thus lack human interpretability. Explainable AI (XAI) can make DTA models more trustworthy, and allows to distill biological knowledge from the models. Counterfactual explanation is one popular approach to explaining the behaviour of a deep neural network, which works by systematically answering the question ""How would the model output change if the inputs were changed in this way?"". We propose a multi-agent reinforcement learning framework, Multi-Agent Counterfactual Drug-target binding Affinity (MACDA), to generate counterfactual explanations for the drug-protein complex. Our proposed framework provides human-interpretable counterfactual instances while optimizing both the input drug and target for counterfactual generation at the same time. We benchmark the proposed MACDA framework using the Davis and PDBBind dataset and find that our framework produces more parsimonious explanations with no loss in explanation validity, as measured by encoding similarity. We then present a case study involving ABL1 and Nilotinib to demonstrate how MACDA can explain the behaviour of a DTA model in the underlying substructure interaction between inputs in its prediction, revealing mechanisms that align with prior domain knowledge.",1,"Many high-performance DTA deep learning models have been proposed, but they are mostly black-box and thus lack human interpretability."
KinasePhos 3.0: Redesign and Expansion of the Prediction on Kinase-specific Phosphorylation Sites.,35781048,https://pubmed.ncbi.nlm.nih.gov/35781048/,https://doi.org/10.1016/j.gpb.2022.06.004,"['Kinase', 'Kinase-specific phosphorylation', 'Phosphorylation', 'Phosphorylation site prediction', 'SHAP feature importance']","The purpose of this work is to enhance KinasePhos, a machine learning-based kinase-specific phosphorylation site prediction tool. Experimentally verified kinase-specific phosphorylation data were collected from PhosphoSitePlus, UniProtKB, the GPS 5.0, and Phospho.ELM. In total, 41,421 experimentally verified kinase-specific phosphorylation sites were identified. A total of 1380 unique kinases were identified, including 753 with existing classification information from KinBase and the remaining 627 annotated by building a phylogenetic tree. Based on this kinase classification, a total of 771 predictive models were built at the individual, family, and group levels, using at least 15 experimentally verified substrate sites in positive training datasets. The improved models demonstrated their effectiveness compared with other prediction tools. For example, the prediction of sites phosphorylated by the protein kinase B, casein kinase 2, and protein kinase A families had accuracies of 94.5%, 92.5%, and 90.0%, respectively. The average prediction accuracy for all 771 models was 87.2%. For enhancing interpretability, the SHapley Additive exPlanations (SHAP) method was employed to assess feature importance. The web interface of KinasePhos 3.0 has been redesigned to provide comprehensive annotations of kinase-specific phosphorylation sites on multiple proteins. Additionally, considering the large scale of phosphoproteomic data, a downloadable prediction tool is available at https://awi.cuhk.edu.cn/KinasePhos/download.html or https://github.com/tom-209/KinasePhos-3.0-executable-file.",11,"The purpose of this work is to enhance KinasePhos, a machine learning-based kinase-specific phosphorylation site prediction tool."
ADmeth: A Manually Curated Database for the Differential Methylation in Alzheimer's Disease.,35617175,https://pubmed.ncbi.nlm.nih.gov/35617175/,https://doi.org/10.1109/TCBB.2022.3178087,[],"Alzheimer's disease (AD) is the most common neurodegenerative disease. More and more evidence show that DNA methylation is closely related to the pathological mechanism of AD. Many AD-associated differentially methylated genes, regions and CpG sites have been identified in recent researches, which may have great potential in clinical research. However, there is no dedicated database to collect AD-related differential methylation up to now. To provide a reference to researchers, we design a database named ADmeth by manually curating relevant articles, which contains a total of 16,709 AD-related differentially methylated items identified from different brain regions and different cell types in the blood, involving 209 genes, 2,229 regions and 14,271 CpG sites. The ADmeth database provides user-friendly pages to search, submit and download data. We hope that the ADmeth database can facilitate researchers to select candidate AD-associated methylation markers in revealing the pathological mechanism of AD and promote the cell-free DNA based non-invasive diagnosis of AD. The ADmeth database is available at http://www.biobdlab.cn/ADmeth.",1,More and more evidence show that DNA methylation is closely related to the pathological mechanism of AD.
Improved DNA-Versus-Protein Homology Search for Protein Fossils.,35617174,https://pubmed.ncbi.nlm.nih.gov/35617174/,https://doi.org/10.1109/TCBB.2022.3177855,[],"Protein fossils, i.e., noncoding DNA descended from coding DNA, arise frequently from transposable elements (TEs), decayed genes, and viral integrations. They can reveal, and mislead about, evolutionary history and relationships. They have been detected by comparing DNA to protein sequences, but current methods are not optimized for this task. We describe a powerful DNA-protein homology search method. We use a 64×21 substitution matrix, which is fitted to sequence data, automatically learning the genetic code. We detect subtly homologous regions by considering alternative possible alignments between them, and calculate significance (probability of occurring by chance between random sequences). Our method detects TE protein fossils much more sensitively than blastx, and faster. Of the  ∼ 7 major categories of eukaryotic TE, three were long thought absent in mammals: we find two of them in the human genome, polinton and DIRS/Ngaro. This method increases our power to find ancient fossils, and perhaps to detect non-standard genetic codes. The alternative-alignments and significance paradigm is not specific to DNA-protein comparison, and could benefit homology search generally. This is an extended version of a conference paper (Yao & Frith, 2021).",2,"Protein fossils arise frequently from transposable elements (TEs), decayed genes, and viral integrations."
Semi-Supervised Deep Learning for Cell Type Identification From Single-Cell Transcriptomic Data.,35536811,https://pubmed.ncbi.nlm.nih.gov/35536811/,https://doi.org/10.1109/TCBB.2022.3173587,[],"Cell type identification from single-cell transcriptomic data is a common goal of single-cell RNA sequencing (scRNAseq) data analysis. Deep neural networks have been employed to identify cell types from scRNAseq data with high performance. However, it requires a large mount of individual cells with accurate and unbiased annotated types to train the identification models. Unfortunately, labeling the scRNAseq data is cumbersome and time-consuming as it involves manual inspection of marker genes. To overcome this challenge, we propose a semi-supervised learning model ""SemiRNet"" to use unlabeled scRNAseq cells and a limited amount of labeled scRNAseq cells to implement cell identification. The proposed model is based on recurrent convolutional neural networks (RCNN), which includes a shared network, a supervised network and an unsupervised network. The proposed model is evaluated on two large scale single-cell transcriptomic datasets. It is observed that the proposed model is able to achieve encouraging performance by learning on the very limited amount of labeled scRNAseq cells together with a large number of unlabeled scRNAseq cells.",3,Deep neural networks have been employed to identify cell types from scRNAseq data with high performance.
PhenoBERT: A Combined Deep Learning Method for Automated Recognition of Human Phenotype Ontology.,35471885,https://pubmed.ncbi.nlm.nih.gov/35471885/,https://doi.org/10.1109/TCBB.2022.3170301,[],"Automated recognition of Human Phenotype Ontology (HPO) terms from clinical texts is of significant interest to the field of clinical data mining. In this study, we develop a combined deep learning method named PhenoBERT for this purpose. PhenoBERT uses BERT, currently the state-of-the-art NLP model, as its core model for evaluating whether a clinically relevant text segment (CTS) could be represented by an HPO term. However, to avoid unnecessary comparison of a CTS with each of ∼14,000 HPO terms using BERT, we introduce a two-levels CNN module consisting of a series of CNN models organized at two levels in PhenoBERT. For a given CTS, the CNN module produces only a short list of candidate HPO terms for BERT to evaluate, significantly improving the computational efficiency. In addition, BERT is able to assign an ancestor HPO term to a CTS when recognition of the direct HPO term is not successful, mimicking the process of HPO term assignment by human. In two benchmarks, PhenoBERT outperforms four traditional dictionary-based methods and two recently developed deep learning-based methods in two benchmark tests, and its advantage is more obvious when the recognition task is more challenging. As such, PhenoBERT is of great use for assisting in the mining of clinical text data.",4,Automated recognition of Human Phenotype Ontology (HPO) terms from clinical texts is of significant interest to the field of clinical data mining.
Attention Deficit Hyperactivity Disorder Classification Based on Deep Learning.,35471884,https://pubmed.ncbi.nlm.nih.gov/35471884/,https://doi.org/10.1109/TCBB.2022.3170527,[],"Attention Deficit Hyperactivity Disorder (ADHD) is a type of mental health disorder that can be seen from children to adults and affects patients' normal life. Accurate diagnosis of ADHD as early as possible is very important for the treatment of patients in clinical applications. Some traditional classification methods, although having been shown powerful in many other classification tasks, are not as successful in the application of ADHD classification. In this paper, we propose two novel deep learning approaches for ADHD classification based on functional magnetic resonance imaging. The first method incorporates independent component analysis with convolutional neural network. It first extracts independent components from each subject. The independent components are then fed into a convolutional neural network as input features to classify the ADHD patient from typical controls. The second method, called the correlation autoencoder method, uses correlations between regions of interest of the brain as the input of an autoencoder to learn latent features, which are then used in the classification task by a new neural network. These two methods use different ways to extract the inter-voxel information from fMRI, but both use convolutional neural networks to further extract predictive features for the classification task. Empirical experiments show that both methods are able to outperform the classical methods such as logistic regression, support vector machines, and other methods used in previous studies.",1,ADHD is a type of mental health disorder that can be seen from children to adults and affects patients' normal life.
Cross-Modality LGE-CMR Segmentation Using Image-to-Image Translation Based Data Augmentation.,34982688,https://pubmed.ncbi.nlm.nih.gov/34982688/,https://doi.org/10.1109/TCBB.2022.3140306,[],"Accurate segmentation of ventricle and myocardium from the late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) is an important tool for myocardial infarction (MI) analysis. However, the complex enhancement pattern of LGE-CMR and the lack of labeled samples make its automatic segmentation difficult to be implemented. In this paper, we propose an unsupervised LGE-CMR segmentation algorithm by using multiple style transfer networks for data augmentation. It adopts two different style transfer networks to perform style transfer of the easily available annotated balanced-Steady State Free Precession (bSSFP)-CMR images. Then, multiple sets of synthetic LGE-CMR images are generated by the style transfer networks and used as the training data for the improved U-Net. The entire implementation of the algorithm does not require the labeled LGE-CMR. Validation experiments demonstrate the effectiveness and advantages of the proposed algorithm.",4,The complex enhancement pattern of LGE-CMR and the lack of labeled samples make its automatic segmentation difficult to be implemented.
Specific Regulation of m,34954129,https://pubmed.ncbi.nlm.nih.gov/34954129/,https://doi.org/10.1016/j.gpb.2021.11.001,"['Cell-specific regulation', 'Glioblastoma', 'PDZ-binding kinase', 'Serine/arginine-rich splicing factor 7', 'm(6)A']","Serine/arginine-rich splicing factor 7 (SRSF7), a known splicing factor, has been revealed to play oncogenic roles in multiple cancers. However, the mechanisms underlying its oncogenic roles have not been well addressed. Here, based on N",8,Serine/arginine-rich splicing factor 7 (SRSF7) has been revealed to play oncogenic roles in multiple cancers.
