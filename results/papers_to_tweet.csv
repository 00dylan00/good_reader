title,pmid,link,doi_link,keywords,abstract,citations,abstract_summary
Predicting antimicrobial resistance in ,38274998,https://pubmed.ncbi.nlm.nih.gov/38274998/,https://doi.org/10.1016/j.csbj.2023.12.041,"['Antimicrobial resistance', 'E. coli', 'Feature Augmentation', 'Machine Learning', 'Single Nucleotide Polymorphism', 'Whole-Genome Sequencing']",,1,
Using Generative Modeling to Endow with Potency Initially Inert Compounds with Good Bioavailability and Low Toxicity.,38261763,https://pubmed.ncbi.nlm.nih.gov/38261763/,https://doi.org/10.1021/acs.jcim.3c01777,[],"In the early stages of drug development, large chemical libraries are typically screened to identify compounds of promising potency against the chosen targets. Often, however, the resulting hit compounds tend to have poor drug metabolism and pharmacokinetics (DMPK), with negative developability features that may be difficult to eliminate. Therefore, starting the drug discovery process with a ""null library"", compounds that have highly desirable DMPK properties but no potency against the chosen targets, could be advantageous. Here, we explore the opportunities offered by machine learning to realize this strategy in the case of the inhibition of α-synuclein aggregation, a process associated with Parkinson's disease. We apply MolDQN, a generative machine learning method, to build an inhibitory activity against α-synuclein aggregation into an initial inactive compound with good DMPK properties. Our results illustrate how generative modeling can be used to endow initially inert compounds with desirable developability properties.",1,Machine learning can be used to build inhibitory activity against Parkinson's disease.
Accelerating therapeutic protein design with computational approaches toward the clinical stage.,38213894,https://pubmed.ncbi.nlm.nih.gov/38213894/,https://doi.org/10.1016/j.csbj.2023.04.027,"['Artificial intelligence', 'Computational approaches', 'Molecular dynamics', 'Protein design', 'Therapeutic protein']","Therapeutic protein, represented by antibodies, is of increasing interest in human medicine. However, clinical translation of therapeutic protein is still largely hindered by different aspects of developability, including affinity and selectivity, stability and aggregation prevention, solubility and viscosity reduction, and deimmunization. Conventional optimization of the developability with widely used methods, like display technologies and library screening approaches, is a time and cost-intensive endeavor, and the efficiency in finding suitable solutions is still not enough to meet clinical needs. In recent years, the accelerated advancement of computational methodologies has ushered in a transformative era in the field of therapeutic protein design. Owing to their remarkable capabilities in feature extraction and modeling, the integration of cutting-edge computational strategies with conventional techniques presents a promising avenue to accelerate the progression of therapeutic protein design and optimization toward clinical implementation. Here, we compared the differences between therapeutic protein and small molecules in developability and provided an overview of the computational approaches applicable to the design or optimization of therapeutic protein in several developability issues.",2,Clinical translation of therapeutic protein is still largely hindered by different aspects of developability.
Early warning and diagnosis of liver cancer based on dynamic network biomarker and deep learning.,38213892,https://pubmed.ncbi.nlm.nih.gov/38213892/,https://doi.org/10.1016/j.csbj.2023.07.002,"['Dynamic network biomarkers', 'Early warning of diseases', 'Graph convolutional neural networks', 'Hepatocellular carcinoma', 'Latency detection']","Early detection of complex diseases like hepatocellular carcinoma remains challenging due to their network-driven pathology. Dynamic network biomarkers (DNB) based on monitoring changes in molecular correlations may enable earlier predictions. However, DNB analysis often overlooks disease heterogeneity.",1,Early detection of complex diseases like hepatocellular carcinoma remains challenging due to their network-driven pathology.
Attention is all you need: utilizing attention in AI-enabled drug discovery.,38189543,https://pubmed.ncbi.nlm.nih.gov/38189543/,https://doi.org/10.1093/bib/bbad467,"['Artificial Intelligence', 'attention mechanism', 'drug discovery', 'molecular representation', 'molecule generation', 'transformer']","Recently, attention mechanism and derived models have gained significant traction in drug development due to their outstanding performance and interpretability in handling complex data structures. This review offers an in-depth exploration of the principles underlying attention-based models and their advantages in drug discovery. We further elaborate on their applications in various aspects of drug development, from molecular screening and target binding to property prediction and molecule generation. Finally, we discuss the current challenges faced in the application of attention mechanisms and Artificial Intelligence technologies, including data quality, model interpretability and computational resource constraints, along with future directions for research. Given the accelerating pace of technological advancement, we believe that attention-based models will have an increasingly prominent role in future drug discovery. We anticipate that these models will usher in revolutionary breakthroughs in the pharmaceutical domain, significantly accelerating the pace of drug development.",1,Attention mechanism and derived models have gained significant traction in drug development.
The role of ncRNA regulatory mechanisms in diseases-case on gestational diabetes.,38189542,https://pubmed.ncbi.nlm.nih.gov/38189542/,https://doi.org/10.1093/bib/bbad489,"['attention mechanism', 'biomarkers', 'gestational diabetes', 'non-coding RNA', 'regulatory mechanism']","Non-coding RNAs (ncRNAs) are a class of RNA molecules that do not have the potential to encode proteins. Meanwhile, they can occupy a significant portion of the human genome and participate in gene expression regulation through various mechanisms. Gestational diabetes mellitus (GDM) is a pathologic condition of carbohydrate intolerance that begins or is first detected during pregnancy, making it one of the most common pregnancy complications. Although the exact pathogenesis of GDM remains unclear, several recent studies have shown that ncRNAs play a crucial regulatory role in GDM. Herein, we present a comprehensive review on the multiple mechanisms of ncRNAs in GDM along with their potential role as biomarkers. In addition, we investigate the contribution of deep learning-based models in discovering disease-specific ncRNA biomarkers and elucidate the underlying mechanisms of ncRNA. This might assist community-wide efforts to obtain insights into the regulatory mechanisms of ncRNAs in disease and guide a novel approach for early diagnosis and treatment of disease.",1,Non-coding RNAs (ncRNAs) are a class of RNA molecules that do not have the potential to encode proteins.
Protein-DNA binding sites prediction based on pre-trained protein language model and contrastive learning.,38171929,https://pubmed.ncbi.nlm.nih.gov/38171929/,https://doi.org/10.1093/bib/bbad488,"['contrastive learning', 'pre-training', 'protein–DNA interaction']","Protein-DNA interaction is critical for life activities such as replication, transcription and splicing. Identifying protein-DNA binding residues is essential for modeling their interaction and downstream studies. However, developing accurate and efficient computational methods for this task remains challenging. Improvements in this area have the potential to drive novel applications in biotechnology and drug design. In this study, we propose a novel approach called Contrastive Learning And Pre-trained Encoder (CLAPE), which combines a pre-trained protein language model and the contrastive learning method to predict DNA binding residues. We trained the CLAPE-DB model on the protein-DNA binding sites dataset and evaluated the model performance and generalization ability through various experiments. The results showed that the area under ROC curve values of the CLAPE-DB model on the two benchmark datasets reached 0.871 and 0.881, respectively, indicating superior performance compared to other existing models. CLAPE-DB showed better generalization ability and was specific to DNA-binding sites. In addition, we trained CLAPE on different protein-ligand binding sites datasets, demonstrating that CLAPE is a general framework for binding sites prediction. To facilitate the scientific community, the benchmark datasets and codes are freely available at https://github.com/YAndrewL/clape.",1,Identifying protein-DNA binding residues is essential for modeling their interaction.
Single-cell and spatiotemporal transcriptomic analyses reveal the effects of microorganisms on immunity and metabolism in the mouse liver.,38152123,https://pubmed.ncbi.nlm.nih.gov/38152123/,https://doi.org/10.1016/j.csbj.2023.06.020,"['Germ-free mice', 'Gut-liver axis', 'Immune cell', 'Liver zonation', 'Metabolism', 'Microbiota', 'Stereo-seq & sc/snRNA-seq']","The gut-liver axis is a complex bidirectional communication pathway between the intestine and the liver in which microorganisms and their metabolites flow from the intestine through the portal vein to the liver and influence liver function. In a sterile environment, the phenotype or function of the liver is altered, but few studies have investigated the specific cellular and molecular effects of microorganisms on the liver. To this end, we constructed single-cell and spatial transcriptomic (ST) profiles of germ-free (GF) and specific-pathogen-free (SPF) mouse livers. Single-cell RNA sequencing (scRNA-seq) and single-nucleus RNA sequencing (snRNA-seq) revealed that the ratio of most immune cells was altered in the liver of GF mice; in particular, natural killer T (NKT) cells, IgA plasma cells (IgAs) and Kupffer cells (KCs) were significantly reduced in GF mice. Spatial enhanced resolution omics sequencing (Stereo-seq) confirmed that microorganisms mediated the accumulation of Kupffer cells in the periportal zone. Unexpectedly, IgA plasma cells were more numerous and concentrated in the periportal vein in liver sections from SPF mice but less numerous and scattered in GF mice. ST technology also enables the precise zonation of liver lobules into eight layers and three patterns based on the gene expression level in each layer, allowing us to further investigate the effects of microbes on gene zonation patterns and functions. Furthermore, untargeted metabolism experiments of the liver revealed that the propionic acid levels were significantly lower in GF mice, and this reduction may be related to the control of genes involved in bile acid and fatty acid metabolism. In conclusion, the combination of sc/snRNA-seq, Stereo-seq, and untargeted metabolomics revealed immune system defects as well as altered bile acid and lipid metabolic processes at the single-cell and spatial levels in the livers of GF mice. This study will be of great value for understanding host-microbiota interactions.",1,The gut-liver axis is a complex bidirectional communication pathway between the intestine and the liver.
,38146436,https://pubmed.ncbi.nlm.nih.gov/38146436/,https://doi.org/10.1016/j.csbj.2023.11.048,"['Artificial intelligence', 'Computational biotechnology', 'Digital pathology', 'Immune', 'Response']","The immune response associated with oncogenesis and potential oncological ther- apeutic interventions has dominated the field of cancer research over the last decade. T-cell lymphocytes in the tumor microenvironment are a crucial aspect of cancer's adaptive immunity, and the quantification of T-cells in specific can- cer types has been suggested as a potential diagnostic aid. However, this is cur- rently not part of routine diagnostics. To address this challenge, we present a new method called ",1,T-cell lymphocytes in the tumor microenvironment are a crucial aspect of cancer's adaptive immunity.
Novel metrics reveal new structure and unappreciated heterogeneity in Caenorhabditis elegans development.,38113280,https://pubmed.ncbi.nlm.nih.gov/38113280/,https://doi.org/10.1371/journal.pcbi.1011733,[],"High throughput experimental approaches are increasingly allowing for the quantitative description of cellular and organismal phenotypes. Distilling these large volumes of complex data into meaningful measures that can drive biological insight remains a central challenge. In the quantitative study of development, for instance, one can resolve phenotypic measures for single cells onto their lineage history, enabling joint consideration of heritable signals and cell fate decisions. Most attempts to analyze this type of data, however, discard much of the information content contained within lineage trees. In this work we introduce a generalized metric, which we term the branch edit distance, that allows us to compare any two embryos based on phenotypic measurements in individual cells. This approach aligns those phenotypic measurements to the underlying lineage tree, providing a flexible and intuitive framework for quantitative comparisons between, for instance, Wild-Type (WT) and mutant developmental programs. We apply this novel metric to data on cell-cycle timing from over 1300 WT and RNAi-treated Caenorhabditis elegans embryos. Our new metric revealed surprising heterogeneity within this data set, including subtle batch effects in WT embryos and dramatic variability in RNAi-induced developmental phenotypes, all of which had been missed in previous analyses. Further investigation of these results suggests a novel, quantitative link between pathways that govern cell fate decisions and pathways that pattern cell cycle timing in the early embryo. Our work demonstrates that the branch edit distance we propose, and similar metrics like it, have the potential to revolutionize our quantitative understanding of organismal phenotype.",1,New metric allows us to compare any two embryos based on phenotypic measurements in individual cells.
Recent Advances and Challenges in Protein Structure Prediction.,38109487,https://pubmed.ncbi.nlm.nih.gov/38109487/,https://doi.org/10.1021/acs.jcim.3c01324,"['Protein structure prediction', 'artificial intelligence', 'multidomain protein', 'multiple conformational states', 'protein complex', 'protein folding pathways']","Artificial intelligence has made significant advances in the field of protein structure prediction in recent years. In particular, DeepMind's end-to-end model, AlphaFold2, has demonstrated the capability to predict three-dimensional structures of numerous unknown proteins with accuracy levels comparable to those of experimental methods. This breakthrough has opened up new possibilities for understanding protein structure and function as well as accelerating drug discovery and other applications in the field of biology and medicine. Despite the remarkable achievements of artificial intelligence in the field, there are still some challenges and limitations. In this Review, we discuss the recent progress and some of the challenges in protein structure prediction. These challenges include predicting multidomain protein structures, protein complex structures, multiple conformational states of proteins, and protein folding pathways. Furthermore, we highlight directions in which further improvements can be conducted.",1,"DeepMind's end-to-end model, AlphaFold2, has demonstrated the capability to predict three-dimensional structures of numerous unknown proteins."
A comprehensive overview of graph neural network-based approaches to clustering for spatial transcriptomics.,38089467,https://pubmed.ncbi.nlm.nih.gov/38089467/,https://doi.org/10.1016/j.csbj.2023.11.055,"['Cell type identification', 'Graph neural networks', 'Graph-based deep learning', 'Spatial transcriptome', 'Survey']","Spatial transcriptomics technologies enable researchers to accurately quantify and localize messenger ribonucleic acid (mRNA) transcripts at a high resolution while preserving their spatial context. The identification of spatial domains, or the task of spatial clustering, plays a crucial role in investigating data on spatial transcriptomes. One promising approach for classifying spatial domains involves the use of graph neural networks (GNNs) by leveraging gene expressions, spatial locations, and histological images. This study provided a comprehensive overview of the most recent GNN-based methods of spatial clustering methods for the analysis of data on spatial transcriptomics. We extensively evaluated the performance of current methods on prevalent datasets of spatial transcriptomics by considering their accuracy of clustering, robustness, data stabilization, relevant requirements, computational efficiency, and memory use. To this end, we explored 60 clustering scenarios by extending the essential frameworks of spatial clustering for the selection of the GNNs, algorithms of downstream clustering, principal component analysis (PCA)-based reduction, and refined methods of correction. We comparatively analyzed the performance of the methods in terms of spatial clustering to identify their limitations and outline future directions of research in the field. Our survey yielded novel insights, and provided motivation for further investigating spatial transcriptomics.",1,The identification of spatial domains plays a crucial role in investigating data on spatial transcriptomes.
Major depressive disorder and bistability in an HPA-CNS toggle switch.,38055769,https://pubmed.ncbi.nlm.nih.gov/38055769/,https://doi.org/10.1371/journal.pcbi.1011645,[],"Major depressive disorder (MDD) is the most common psychiatric disorder. It has a complex and heterogeneous etiology. Most treatments take weeks to show effects and work well only for a fraction of the patients. Thus, new concepts are needed to understand MDD and its dynamics. One of the strong correlates of MDD is increased activity and dysregulation of the hypothalamic-pituitary-adrenal (HPA) axis which produces the stress hormone cortisol. Existing mathematical models of the HPA axis describe its operation on the scale of hours, and thus are unable to explore the dynamic on the scale of weeks that characterizes many aspects of MDD. Here, we propose a mathematical model of MDD on the scale of weeks, a timescale provided by the growth of the HPA hormone glands under control of HPA hormones. We add to this the mutual inhibition of the HPA axis and the hippocampus and other regions of the central nervous system (CNS) that forms a toggle switch. The model shows bistability between euthymic and depressed states, with a slow timescale of weeks in its dynamics. It explains why prolonged but not acute stress can trigger a self-sustaining depressive episode that persists even after the stress is removed. The model explains the weeks timescale for drugs to take effect, as well as the dysregulation of the HPA axis in MDD, based on gland mass changes. This understanding of MDD dynamics may help to guide strategies for treatment.",1,Major depressive disorder (MDD) is the most common psychiatric disorder.. It has a complex and heterogeneous etiology.
An automated pipeline integrating AlphaFold 2 and MODELLER for protein structure prediction.,38047234,https://pubmed.ncbi.nlm.nih.gov/38047234/,https://doi.org/10.1016/j.csbj.2023.10.056,"['AlphaFold 2', 'Deep learning', 'MODELLER', 'Protein structure prediction']","The ability to predict a protein's three-dimensional conformation represents a crucial starting point for investigating evolutionary connections with other members of the corresponding protein family, examining interactions with other proteins, and potentially utilizing this knowledge for the purpose of rational drug design. In this work, we evaluated the feasibility of improving AlphaFold2's three-dimensional protein predictions by developing a novel pipeline (AlphaMod) that incorporates AlphaFold2 with MODELLER, a template-based modeling program. Additionally, our tool can drive a comprehensive quality assessment of the tertiary protein structure by incorporating and comparing a set of different quality assessment tools. The outcomes of selected tools are combined into a composite score (BORDASCORE) that exhibits a meaningful correlation with GDT_TS and facilitates the selection of optimal models in the absence of a reference structure. To validate AlphaMod's results, we conducted evaluations using two distinct datasets summing up to 72 targets, previously used to independently assess AlphaFold2's performance. The generated models underwent evaluation through two methods: i) averaging the GDT_TS scores across all produced structures for a single target sequence, and ii) a pairwise comparison of the best structures generated by AlphaFold2 and AlphaMod. The latter, within the unsupervised setups, shows a rising accuracy of approximately 34% over AlphaFold2. While, when considering the supervised setup, AlphaMod surpasses AlphaFold2 in 18% of the instances. Finally, there is an 11% correspondence in outcomes between the diverse methodologies. Consequently, AlphaMod's best-predicted tertiary structures in several cases exhibited a significant improvement in the accuracy of the predictions with respect to the best models obtained by AlphaFold2. This pipeline paves the way for the integration of additional data and AI-based algorithms to further improve the reliability of the predictions.",1,The ability to predict a protein's three-dimensional conformation represents a crucial starting point for investigating evolutionary connections with other members of the corresponding protein family.
Natural language processing with machine learning methods to analyze unstructured patient-reported outcomes derived from electronic health records: A systematic review.,38042599,https://pubmed.ncbi.nlm.nih.gov/38042599/,https://doi.org/10.1016/j.artmed.2023.102701,"['Electronic health records', 'Machine learning', 'Natural language processing', 'Patient-reported outcomes', 'Unstructured clinical narrative']",Natural language processing (NLP) combined with machine learning (ML) techniques are increasingly used to process unstructured/free-text patient-reported outcome (PRO) data available in electronic health records (EHRs). This systematic review summarizes the literature reporting NLP/ML systems/toolkits for analyzing PROs in clinical narratives of EHRs and discusses the future directions for the application of this modality in clinical care.,1,Natural language processing (NLP) combined with machine learning (ML) techniques are increasingly used to process unstructured/free-text patient-reported outcome (PRO) data.
Modeling the diverse effects of divisive normalization on noise correlations.,38033166,https://pubmed.ncbi.nlm.nih.gov/38033166/,https://doi.org/10.1371/journal.pcbi.1011667,[],"Divisive normalization, a prominent descriptive model of neural activity, is employed by theories of neural coding across many different brain areas. Yet, the relationship between normalization and the statistics of neural responses beyond single neurons remains largely unexplored. Here we focus on noise correlations, a widely studied pairwise statistic, because its stimulus and state dependence plays a central role in neural coding. Existing models of covariability typically ignore normalization despite empirical evidence suggesting it affects correlation structure in neural populations. We therefore propose a pairwise stochastic divisive normalization model that accounts for the effects of normalization and other factors on covariability. We first show that normalization modulates noise correlations in qualitatively different ways depending on whether normalization is shared between neurons, and we discuss how to infer when normalization signals are shared. We then apply our model to calcium imaging data from mouse primary visual cortex (V1), and find that it accurately fits the data, often outperforming a popular alternative model of correlations. Our analysis indicates that normalization signals are often shared between V1 neurons in this dataset. Our model will enable quantifying the relation between normalization and covariability in a broad range of neural systems, which could provide new constraints on circuit mechanisms of normalization and their role in information transmission and representation.",1,Divisive normalization is employed by theories of neural coding across many different brain areas.. The relationship between normalization and statistics of neural responses beyond single neurons remains largely unexplored.
Ensemble Geometric Deep Learning of Aqueous Solubility.,37990484,https://pubmed.ncbi.nlm.nih.gov/37990484/,https://doi.org/10.1021/acs.jcim.3c01536,[],"Geometric deep learning is one of the main workhorses for harnessing the power of big data to predict molecular properties such as aqueous solubility, which is key to the pharmacokinetic improvement of drug candidates. Two ensembles of graph neural network architectures were built, one based on spectral convolution and the other on spatial convolution. The pretrained models, denoted respectively as SolNet-GCN and SolNet-GAT, significantly outperformed the existing neural networks benchmarked on a validation set of 207 molecules. The SolNet-GCN model demonstrated the best performance on both the training and validation sets, with RMSE values of 0.53 and 0.72 log molar unit and Pearson ",1,Geometric deep learning is one of the main workhorses for harnessing the power of big data to predict molecular properties such as aqueous solubility.
On the difficulty of validating molecular generative models realistically: a case study on public and proprietary data.,37990215,https://pubmed.ncbi.nlm.nih.gov/37990215/,https://doi.org/10.1186/s13321-023-00781-1,[],"While a multitude of deep generative models have recently emerged there exists no best practice for their practically relevant validation. On the one hand, novel de novo-generated molecules cannot be refuted by retrospective validation (so that this type of validation is biased); but on the other hand prospective validation is expensive and then often biased by the human selection process. In this case study, we frame retrospective validation as the ability to mimic human drug design, by answering the following question: Can a generative model trained on early-stage project compounds generate middle/late-stage compounds de novo? To this end, we used experimental data that contains the elapsed time of a synthetic expansion following hit identification from five public (where the time series was pre-processed to better reflect realistic synthetic expansions) and six in-house project datasets, and used REINVENT as a widely adopted RNN-based generative model. After splitting the dataset and training REINVENT on early-stage compounds, we found that rediscovery of middle/late-stage compounds was much higher in public projects (at 1.60%, 0.64%, and 0.21% of the top 100, 500, and 5000 scored generated compounds) than in in-house projects (where the values were 0.00%, 0.03%, and 0.04%, respectively). Similarly, average single nearest neighbour similarity between early- and middle/late-stage compounds in public projects was higher between active compounds than inactive compounds; however, for in-house projects the converse was true, which makes rediscovery (if so desired) more difficult. We hence show that the generative model recovers very few middle/late-stage compounds from real-world drug discovery projects, highlighting the fundamental difference between purely algorithmic design and drug discovery as a real-world process. Evaluating de novo compound design approaches appears, based on the current study, difficult or even impossible to do retrospectively.Scientific Contribution This contribution hence illustrates aspects of evaluating the performance of generative models in a real-world setting which have not been extensively described previously and which hopefully contribute to their further future development.",1,ReinVENT is a widely adopted RNN-based generative model.
PanomiR: a systems biology framework for analysis of multi-pathway targeting by miRNAs.,37985452,https://pubmed.ncbi.nlm.nih.gov/37985452/,https://doi.org/10.1093/bib/bbad418,"['bioinformatics', 'biological networks', 'computational biology', 'miRNA prioritization', 'miRNA regulation', 'microRNA', 'pathway analysis', 'pathways', 'statistical models', 'systems biology']","Charting microRNA (miRNA) regulation across pathways is key to characterizing their function. Yet, no method currently exists that can quantify how miRNAs regulate multiple interconnected pathways or prioritize them for their ability to regulate coordinate transcriptional programs. Existing methods primarily infer one-to-one relationships between miRNAs and pathways using differentially expressed genes. We introduce PanomiR, an in silico framework for studying the interplay of miRNAs and disease functions. PanomiR integrates gene expression, mRNA-miRNA interactions and known biological pathways to reveal coordinated multi-pathway targeting by miRNAs. PanomiR utilizes pathway-activity profiling approaches, a pathway co-expression network and network clustering algorithms to prioritize miRNAs that target broad-scale transcriptional disease phenotypes. It directly resolves differential regulation of pathways, irrespective of their differential gene expression, and captures co-activity to establish functional pathway groupings and the miRNAs that may regulate them. PanomiR uses a systems biology approach to provide broad but precise insights into miRNA-regulated functional programs. It is available at https://bioconductor.org/packages/PanomiR.",1,PanomiR is an in silico framework for studying the interplay of miRNAs and disease functions.
CENTRE: a gradient boosting algorithm for Cell-type-specific ENhancer-Target pREdiction.,37982748,https://pubmed.ncbi.nlm.nih.gov/37982748/,https://doi.org/10.1093/bioinformatics/btad687,[],"Identifying target promoters of active enhancers is a crucial step for realizing gene regulation and deciphering phenotypes and diseases. Up to now, several computational methods were developed to predict enhancer gene interactions, but they require either many epigenomic and transcriptomic experimental assays to generate cell-type (CT)-specific predictions or a single experiment applied to a large cohort of CTs to extract correlations between activities of regulatory elements. Thus, inferring CT-specific enhancer gene interactions in unstudied or poorly annotated CTs becomes a laborious and costly task.",1,Identifying target promoters of active enhancers is a crucial step for realizing gene regulation and deciphering phenotypes and diseases.
Structure-function and engineering of plant UDP-glycosyltransferase.,37965058,https://pubmed.ncbi.nlm.nih.gov/37965058/,https://doi.org/10.1016/j.csbj.2023.10.046,"['Glycosyltransferase', 'Mechanism', 'Protein engineering', 'Structure', 'UGT']","Natural products synthesized by plants have substantial industrial and medicinal values and are therefore attracting increasing interest in various related industries. Among the key enzyme families involved in the biosynthesis of natural products, uridine diphosphate-dependent glycosyltransferases (UGTs) play a crucial role in plants. In recent years, significant efforts have been made to elucidate the catalytic mechanisms and substrate recognition of plant UGTs and to improve them for desired functions. In this review, we presented a comprehensive overview of all currently published structures of plant UGTs, along with in-depth analyses of the corresponding catalytic and substrate recognition mechanisms. In addition, we summarized and evaluated the protein engineering strategies applied to improve the catalytic activities of plant UGTs, with a particular focus on high-throughput screening methods. The primary objective of this review is to provide readers with a comprehensive understanding of plant UGTs and to serve as a valuable reference for the latest techniques used to improve their activities.",1,Natural products synthesized by plants have substantial industrial and medicinal values.
PiDeeL: metabolic pathway-informed deep learning model for survival analysis and pathological classification of gliomas.,37952175,https://pubmed.ncbi.nlm.nih.gov/37952175/,https://doi.org/10.1093/bioinformatics/btad684,[],"Online assessment of tumor characteristics during surgery is important and has the potential to establish an intra-operative surgeon feedback mechanism. With the availability of such feedback, surgeons could decide to be more liberal or conservative regarding the resection of the tumor. While there are methods to perform metabolomics-based tumor pathology prediction, their model complexity predictive performance is limited by the small dataset sizes. Furthermore, the information conveyed by the feedback provided on the tumor tissue could be improved both in terms of content and accuracy.",1,Online assessment of tumor characteristics during surgery is important and has the potential to establish an intra-operative surgeon feedback mechanism.
ILIAD: a suite of automated Snakemake workflows for processing genomic data for downstream applications.,37940870,https://pubmed.ncbi.nlm.nih.gov/37940870/,https://doi.org/10.1186/s12859-023-05548-x,"['Genetic data', 'Genome mapping', 'Genomics', 'Iliad', 'Pipeline', 'Snakemake', 'Variant calling', 'Workflow']","Processing raw genomic data for downstream applications such as imputation, association studies, and modeling requires numerous third-party bioinformatics software tools. It is highly time-consuming and resource-intensive with computational demands and storage limitations that pose significant challenges that increase cost. The use of software tools independent of one another, in a disjointed stepwise fashion, increases the difficulty and sets forth higher error rates because of fragmented job executions in alignment, variant calling, and/or build conversion complications. As sequencing data availability grows, the ability for biologists to process it using stable, automated, and reproducible workflows is paramount as it significantly reduces the time to generate clean and reliable data.",1," Processing raw genomic data for downstream applications such as imputation, association studies, and modeling requires numerous third-party bioinformatics software tools."
Rhythmic modulation of prediction errors: A top-down gating role for the beta-range in speech processing.,37934766,https://pubmed.ncbi.nlm.nih.gov/37934766/,https://doi.org/10.1371/journal.pcbi.1011595,[],"Natural speech perception requires processing the ongoing acoustic input while keeping in mind the preceding one and predicting the next. This complex computational problem could be handled by a dynamic multi-timescale hierarchical inferential process that coordinates the information flow up and down the language network hierarchy. Using a predictive coding computational model (Precoss-β) that identifies online individual syllables from continuous speech, we address the advantage of a rhythmic modulation of up and down information flows, and whether beta oscillations could be optimal for this. In the model, and consistent with experimental data, theta and low-gamma neural frequency scales ensure syllable-tracking and phoneme-level speech encoding, respectively, while the beta rhythm is associated with inferential processes. We show that a rhythmic alternation of bottom-up and top-down processing regimes improves syllable recognition, and that optimal efficacy is reached when the alternation of bottom-up and top-down regimes, via oscillating prediction error precisions, is in the beta range (around 20-30 Hz). These results not only demonstrate the advantage of a rhythmic alternation of up- and down-going information, but also that the low-beta range is optimal given sensory analysis at theta and low-gamma scales. While specific to speech processing, the notion of alternating bottom-up and top-down processes with frequency multiplexing might generalize to other cognitive architectures.",1,Natural speech perception requires processing the ongoing acoustic input while keeping in mind the preceding one and predicting the next.
FG-BERT: a generalized and self-supervised functional group-based molecular representation learning framework for properties prediction.,37930026,https://pubmed.ncbi.nlm.nih.gov/37930026/,https://doi.org/10.1093/bib/bbad398,"['FG-BERT', 'deep learning', 'molecular property prediction', 'molecular representations', 'self-supervised learning']","Artificial intelligence-based molecular property prediction plays a key role in molecular design such as bioactive molecules and functional materials. In this study, we propose a self-supervised pretraining deep learning (DL) framework, called functional group bidirectional encoder representations from transformers (FG-BERT), pertained based on ~1.45 million unlabeled drug-like molecules, to learn meaningful representation of molecules from function groups. The pretrained FG-BERT framework can be fine-tuned to predict molecular properties. Compared to state-of-the-art (SOTA) machine learning and DL methods, we demonstrate the high performance of FG-BERT in evaluating molecular properties in tasks involving physical chemistry, biophysics and physiology across 44 benchmark datasets. In addition, FG-BERT utilizes attention mechanisms to focus on FG features that are critical to the target properties, thereby providing excellent interpretability for downstream training tasks. Collectively, FG-BERT does not require any artificially crafted features as input and has excellent interpretability, providing an out-of-the-box framework for developing SOTA models for a variety of molecule (especially for drug) discovery tasks.",1,Artificial intelligence-based molecular property prediction plays a key role in molecular design such as bioactive molecules and functional materials.
ComplexQA: a deep graph learning approach for protein complex structure assessment.,37930021,https://pubmed.ncbi.nlm.nih.gov/37930021/,https://doi.org/10.1093/bib/bbad287,"['deep graph learning', 'machine learning', 'protein complex assessment', 'protein interface']","In recent years, the end-to-end deep learning method for single-chain protein structure prediction has achieved high accuracy. For example, the state-of-the-art method AlphaFold, developed by Google, has largely increased the accuracy of protein structure predictions to near experimental accuracy in some of the cases. At the same time, there are few methods that can evaluate the quality of protein complexes at the residue level. In particular, evaluating the quality of residues at the interface of protein complexes can lead to a wide range of applications, such as protein function analysis and drug design. In this paper, we introduce a new deep graph neural network-based method ComplexQA, to evaluate the local quality of interfaces for protein complexes by utilizing the residue-level structural information in 3D space and the sequence-level constraints.",1,"In recent years, the end-to-end deep learning method for single-chain protein structure prediction has achieved high accuracy."
AIPs-SnTCN: Predicting Anti-Inflammatory Peptides Using fastText and Transformer Encoder-Based Hybrid Word Embedding with Self-Normalized Temporal Convolutional Networks.,37905969,https://pubmed.ncbi.nlm.nih.gov/37905969/,https://doi.org/10.1021/acs.jcim.3c01563,[],"Inflammation is a biologically resistant response to harmful stimuli, such as infection, damaged cells, toxic chemicals, or tissue injuries. Its purpose is to eradicate pathogenic micro-organisms or irritants and facilitate tissue repair. Prolonged inflammation can result in chronic inflammatory diseases. However, wet-laboratory-based treatments are costly and time-consuming and may have adverse side effects on normal cells. In the past decade, peptide therapeutics have gained significant attention due to their high specificity in targeting affected cells without affecting healthy cells. Motivated by the significance of peptide-based therapies, we developed a highly discriminative prediction model called AIPs-SnTCN to predict anti-inflammatory peptides accurately. The peptide samples are encoded using word embedding techniques such as skip-gram and attention-based bidirectional encoder representation using a transformer (BERT). The conjoint triad feature (CTF) also collects structure-based cluster profile features. The fused vector of word embedding and sequential features is formed to compensate for the limitations of single encoding methods. Support vector machine-based recursive feature elimination (SVM-RFE) is applied to choose the ranking-based optimal space. The optimized feature space is trained by using an improved self-normalized temporal convolutional network (SnTCN). The AIPs-SnTCN model achieved a predictive accuracy of 95.86% and an AUC of 0.97 by using training samples. In the case of the alternate training data set, our model obtained an accuracy of 92.04% and an AUC of 0.96. The proposed AIPs-SnTCN model outperformed existing models with an ∼19% higher accuracy and an ∼14% higher AUC value. The reliability and efficacy of our AIPs-SnTCN model make it a valuable tool for scientists and may play a beneficial role in pharmaceutical design and research academia.",5,"Inflammation is a biologically resistant response to harmful stimuli, such as infection, damaged cells, toxic chemicals, or tissue injuries."
Dose-response in modulating brain function with transcranial direct current stimulation: From local to network levels.,37883583,https://pubmed.ncbi.nlm.nih.gov/37883583/,https://doi.org/10.1371/journal.pcbi.1011572,[],"Understanding the dose-response relationship is crucial in studying the effects of brain stimulation techniques, such as transcranial direct current stimulation (tDCS). The dose-response relationship refers to the relationship between the received stimulation dose and the resulting response, which can be described as a function of the dose at various levels, including single/multiple neurons, clusters, regions, or networks. Here, we are focused on the received stimulation dose obtained from computational head models and brain responses which are quantified by functional magnetic resonance imaging (fMRI) data. In this randomized, triple-blind, sham-controlled clinical trial, we recruited sixty participants with methamphetamine use disorders (MUDs) as a sample clinical population who were randomly assigned to receive either sham or active tDCS. Structural and functional MRI data, including high-resolution T1 and T2-weighted MRI, resting-state functional MRI, and a methamphetamine cue-reactivity task fMRI, were acquired before and after tDCS. Individual head models were generated using the T1 and T2-weighted MRI data to simulate electric fields. In a linear approach, we investigated the associations between electric fields (received dose) and changes in brain function (response) at four different levels: voxel level, regional level (using atlas-based parcellation), cluster level (identifying active clusters), and network level (task-based functional connectivity). At the voxel level, regional level, and cluster level, no FDR-corrected significant correlation was observed between changes in functional activity and electric fields. However, at the network level, a significant positive correlation was found between frontoparietal connectivity and the electric field at the frontopolar stimulation site (r = 0.42, p corrected = 0.02; medium effect size). Our proposed pipeline offers a methodological framework for analyzing tDCS effects by exploring dose-response relationships at different levels, enabling a direct link between electric field variability and the neural response to tDCS. The results indicate that network-based analysis provides valuable insights into the dependency of tDCS neuromodulatory effects on the individual's regional current dose. Integration of dose-response relationships can inform dose optimization, customization, or the extraction of predictive/treatment-response biomarkers in future brain stimulation studies.",1," understanding the dose-response relationship is crucial in studying the effects of brain stimulation techniques, such as transcranial direct current stimulation (tDCS)"
Tissue Forge: Interactive biological and biophysics simulation environment.,37871133,https://pubmed.ncbi.nlm.nih.gov/37871133/,https://doi.org/10.1371/journal.pcbi.1010768,[],"Tissue Forge is an open-source interactive environment for particle-based physics, chemistry and biology modeling and simulation. Tissue Forge allows users to create, simulate and explore models and virtual experiments based on soft condensed matter physics at multiple scales, from the molecular to the multicellular, using a simple, consistent interface. While Tissue Forge is designed to simplify solving problems in complex subcellular, cellular and tissue biophysics, it supports applications ranging from classic molecular dynamics to agent-based multicellular systems with dynamic populations. Tissue Forge users can build and interact with models and simulations in real-time and change simulation details during execution, or execute simulations off-screen and/or remotely in high-performance computing environments. Tissue Forge provides a growing library of built-in model components along with support for user-specified models during the development and application of custom, agent-based models. Tissue Forge includes an extensive Python API for model and simulation specification via Python scripts, an IPython console and a Jupyter Notebook, as well as C and C++ APIs for integrated applications with other software tools. Tissue Forge supports installations on 64-bit Windows, Linux and MacOS systems and is available for local installation via conda.",3,"Tissue Forge is an open-source interactive environment for particle-based physics, chemistry and biology modeling and simulation."
Refphase: Multi-sample phasing reveals haplotype-specific copy number heterogeneity.,37871126,https://pubmed.ncbi.nlm.nih.gov/37871126/,https://doi.org/10.1371/journal.pcbi.1011379,[],"Most computational methods that infer somatic copy number alterations (SCNAs) from bulk sequencing of DNA analyse tumour samples individually. However, the sequencing of multiple tumour samples from a patient's disease is an increasingly common practice. We introduce Refphase, an algorithm that leverages this multi-sampling approach to infer haplotype-specific copy numbers through multi-sample phasing. We demonstrate Refphase's ability to infer haplotype-specific SCNAs and characterise their intra-tumour heterogeneity, to uncover previously undetected allelic imbalance in low purity samples, and to identify parallel evolution in the context of whole genome doubling in a pan-cancer cohort of 336 samples from 99 tumours.",1,Most computational methods that infer somatic copy number alterations (SCNAs) from bulk sequencing of DNA analyse tumour samples individually.
Semla: a versatile toolkit for spatially resolved transcriptomics analysis and visualization.,37846051,https://pubmed.ncbi.nlm.nih.gov/37846051/,https://doi.org/10.1093/bioinformatics/btad626,[],"Spatially resolved transcriptomics technologies generate gene expression data with retained positional information from a tissue section, often accompanied by a corresponding histological image. Computational tools should make it effortless to incorporate spatial information into data analyses and present analysis results in their histological context. Here, we present semla, an R package for processing, analysis, and visualization of spatially resolved transcriptomics data generated by the Visium platform, that includes interactive web applications for data exploration and tissue annotation.",1,"Sla is an R package for processing, analysis, and visualization of spatially resolved transcriptomics data."
Applying the digital data and the bioinformatics tools in SARS-CoV-2 research.,37841328,https://pubmed.ncbi.nlm.nih.gov/37841328/,https://doi.org/10.1016/j.csbj.2023.09.044,"['Bioinformatics tool', 'Database', 'SARS-CoV-2', 'Software', 'Webserver']","Bioinformatics has been playing a crucial role in the scientific progress to fight against the pandemic of the coronavirus disease 2019 (COVID-19) caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The advances in novel algorithms, mega data technology, artificial intelligence and deep learning assisted the development of novel bioinformatics tools to analyze daily increasing SARS-CoV-2 data in the past years. These tools were applied in genomic analyses, evolutionary tracking, epidemiological analyses, protein structure interpretation, studies in virus-host interaction and clinical performance. To promote the ",1,"The advances in novel algorithms, mega data technology, artificial intelligence and deep learning assisted the development of novel bioinformatics tools to analyze daily increasing SARS-CoV-2 data"
From BIG Data Center to China National Center for Bioinformation.,37832784,https://pubmed.ncbi.nlm.nih.gov/37832784/,https://doi.org/10.1016/j.gpb.2023.10.001,[],,1,
Accurately identifying nucleic-acid-binding sites through geometric graph learning on language model predicted structures.,37824738,https://pubmed.ncbi.nlm.nih.gov/37824738/,https://doi.org/10.1093/bib/bbad360,"['binding sites', 'geometric graph learning', 'nucleic acids', 'pre-trained language model']","The interactions between nucleic acids and proteins are important in diverse biological processes. The high-quality prediction of nucleic-acid-binding sites continues to pose a significant challenge. Presently, the predictive efficacy of sequence-based methods is constrained by their exclusive consideration of sequence context information, whereas structure-based methods are unsuitable for proteins lacking known tertiary structures. Though protein structures predicted by AlphaFold2 could be used, the extensive computing requirement of AlphaFold2 hinders its use for genome-wide applications. Based on the recent breakthrough of ESMFold for fast prediction of protein structures, we have developed GLMSite, which accurately identifies DNA- and RNA-binding sites using geometric graph learning on ESMFold predicted structures. Here, the predicted protein structures are employed to construct protein structural graph with residues as nodes and spatially neighboring residue pairs for edges. The node representations are further enhanced through the pre-trained language model ProtTrans. The network was trained using a geometric vector perceptron, and the geometric embeddings were subsequently fed into a common network to acquire common binding characteristics. Finally, these characteristics were input into two fully connected layers to predict binding sites with DNA and RNA, respectively. Through comprehensive tests on DNA/RNA benchmark datasets, GLMSite was shown to surpass the latest sequence-based methods and be comparable with structure-based methods. Moreover, the prediction was shown useful for inferring nucleic-acid-binding proteins, demonstrating its potential for protein function discovery. The datasets, codes, and trained models are available at https://github.com/biomed-AI/nucleic-acid-binding.",2,GLMSite accurately identifies DNA- and RNA-binding sites using geometric graph learning on ESMFold predicted structures.
A Comparative Analysis of Data Synthesis Techniques to Improve Classification Accuracy of Raman Spectroscopy Data.,37820361,https://pubmed.ncbi.nlm.nih.gov/37820361/,https://doi.org/10.1021/acs.jcim.3c00761,[],"Raman spectra are examples of high dimensional data that can often be limited in the number of samples. This is a primary concern when Deep Learning frameworks are developed for tasks such as chemical species identification, quantification, and diagnostics. Open-source data are difficult to obtain and often sparse; furthermore, the collecting and curating of new spectra require expertise and resources. Deep generative modeling utilizes Deep Learning architectures to approximate high dimensional distributions and aims to generate realistic synthetic data. The evaluation of the data and the performance of the deep models is usually conducted on a per-task basis and provides no indication of an increase to robustness, or generalization, on a wider scale. In this study, we compare the benefits and limitations of a standard statistical approach to data synthesis (",1,Raman spectra are examples of high dimensional data that can often be limited in the number of samples.. Open-source data are difficult to obtain and often sparse.
Phertilizer: Growing a clonal tree from ultra-low coverage single-cell DNA sequencing of tumors.,37819942,https://pubmed.ncbi.nlm.nih.gov/37819942/,https://doi.org/10.1371/journal.pcbi.1011544,[],"Emerging ultra-low coverage single-cell DNA sequencing (scDNA-seq) technologies have enabled high resolution evolutionary studies of copy number aberrations (CNAs) within tumors. While these sequencing technologies are well suited for identifying CNAs due to the uniformity of sequencing coverage, the sparsity of coverage poses challenges for the study of single-nucleotide variants (SNVs). In order to maximize the utility of increasingly available ultra-low coverage scDNA-seq data and obtain a comprehensive understanding of tumor evolution, it is important to also analyze the evolution of SNVs from the same set of tumor cells. We present Phertilizer, a method to infer a clonal tree from ultra-low coverage scDNA-seq data of a tumor. Based on a probabilistic model, our method recursively partitions the data by identifying key evolutionary events in the history of the tumor. We demonstrate the performance of Phertilizer on simulated data as well as on two real datasets, finding that Phertilizer effectively utilizes the copy-number signal inherent in the data to more accurately uncover clonal structure and genotypes compared to previous methods.",2,Phertilizer is a method to infer a clonal tree from ultra-low coverage scDNA-seq data of a tumor.
"simpleaf: a simple, flexible, and scalable framework for single-cell data processing using alevin-fry.",37802884,https://pubmed.ncbi.nlm.nih.gov/37802884/,https://doi.org/10.1093/bioinformatics/btad614,[],"The alevin-fry ecosystem provides a robust and growing suite of programs for single-cell data processing. However, as new single-cell technologies are introduced, as the community continues to adjust best practices for data processing, and as the alevin-fry ecosystem itself expands and grows, it is becoming increasingly important to manage the complexity of alevin-fry's single-cell preprocessing workflows while retaining the performance and flexibility that make these tools enticing. We introduce simpleaf, a program that simplifies the processing of single-cell data using tools from the alevin-fry ecosystem, and adds new functionality and capabilities, while retaining the flexibility and performance of the underlying tools.",3,Simpleaf is a program that simplifies the processing of single-cell data using tools from the alevin-fry ecosystem.
E2EDA: Protein Domain Assembly Based on End-to-End Deep Learning.,37788318,https://pubmed.ncbi.nlm.nih.gov/37788318/,https://doi.org/10.1021/acs.jcim.3c01387,[],"With the development of deep learning, almost all single-domain proteins can be predicted at experimental resolution. However, the structure prediction of multi-domain proteins remains a challenge. Achieving end-to-end protein domain assembly and further improving the accuracy of the full-chain modeling by accurately predicting inter-domain orientation while improving the assembly efficiency will provide significant insights into structure-based drug discovery. In this work, we propose an End-to-End Domain Assembly method based on deep learning, named E2EDA. We first develop RMNet, an EfficientNetV2-based deep learning model that fuses multiple features using an attention mechanism to predict inter-domain rigid motion. Then, the predicted rigid motions are transformed into inter-domain spatial transformations to directly assemble the full-chain model. Finally, the scoring strategy RMscore is designed to select the best model from multiple assembled models. The experimental results show that the average TM-score of the model assembled by E2EDA on the benchmark set (282) is 0.827, which is better than those of other domain assembly methods SADA (0.792) and DEMO (0.730). Meanwhile, on our constructed multi-domain data set from AlphaFold DB, the model reassembled by E2EDA is 7.0% higher in TM-score compared to the full-chain model predicted by AlphaFold2, indicating that E2EDA can capture more accurate inter-domain orientations to improve the quality of the model predicted by AlphaFold2. Furthermore, compared to SADA and AlphaFold2, E2EDA reduced the average runtime on the benchmark by 64.7% and 19.2%, respectively, indicating that E2EDA can significantly improve assembly efficiency through an end-to-end approach. The online server is available at http://zhanglab-bioinf.com/E2EDA.",1,E2EDA is an End-to-End Domain Assembly method based on deep learning.
An interpretable deep learning model for time-series electronic health records: Case study of delirium prediction in critical care.,37783541,https://pubmed.ncbi.nlm.nih.gov/37783541/,https://doi.org/10.1016/j.artmed.2023.102659,"['Clinical explainable AI', 'Critical care', 'Delirium prediction', 'Double Self-Attention (DSA)', 'Time dimension', 'Variable importance']","Deep Learning (DL) models have received increasing attention in the clinical setting, particularly in intensive care units (ICU). In this context, the interpretability of the outcomes estimated by the DL models is an essential step towards increasing adoption of DL models in clinical practice. To address this challenge, we propose an ante-hoc, interpretable neural network model. Our proposed model, named double self-attention architecture (DSA), uses two attention-based mechanisms, including self-attention and effective attention. It can capture the importance of input variables in general, as well as changes in importance along the time dimension for the outcome of interest. We evaluated our model using two real-world clinical datasets covering 22840 patients in predicting onset of delirium 12 h and 48 h in advance. Additionally, we compare the descriptive performance of our model with three post-hoc interpretable algorithms as well as with the opinion of clinicians based on the published literature and clinical experience. We find that our model covers the majority of the top-10 variables ranked by the other three post-hoc interpretable algorithms as well as the clinical opinion, with the advantage of taking into account both, the dependencies among variables as well as dependencies between varying time-steps. Finally, our results show that our model can improve descriptive performance without sacrificing predictive performance.",1,"Deep Learning (DL) models have received increasing attention in the clinical setting, particularly in intensive care units."
Fuse feeds as one: cross-modal framework for general identification of AMPs.,37779248,https://pubmed.ncbi.nlm.nih.gov/37779248/,https://doi.org/10.1093/bib/bbad336,"['antimicrobial peptides identification', 'cross-modal framework', 'deep learning', 'fusion model']","Antimicrobial peptides (AMPs) are promising candidates for the development of new antibiotics due to their broad-spectrum activity against a range of pathogens. However, identifying AMPs through a huge bunch of candidates is challenging due to their complex structures and diverse sequences. In this study, we propose SenseXAMP, a cross-modal framework that leverages semantic embeddings of and protein descriptors (PDs) of input sequences to improve the identification performance of AMPs. SenseXAMP includes a multi-input alignment module and cross-representation fusion module to explore the hidden information between the two input features and better leverage the fusion feature. To better address the AMPs identification task, we accumulate the latest annotated AMPs data to form more generous benchmark datasets. Additionally, we expand the existing AMPs identification task settings by adding an AMPs regression task to meet more specific requirements like antimicrobial activity prediction. The experimental results indicated that SenseXAMP outperformed existing state-of-the-art models on multiple AMP-related datasets including commonly used AMPs classification datasets and our proposed benchmark datasets. Furthermore, we conducted a series of experiments to demonstrate the complementary nature of traditional PDs and protein pre-training models in AMPs tasks. Our experiments reveal that SenseXAMP can effectively combine the advantages of PDs to improve the performance of protein pre-training models in AMPs tasks.",1,Antimicrobial peptides (AMPs) are promising candidates for the development of new antibiotics.
Integrating a tailored recurrent neural network with Bayesian experimental design to optimize microbial community functions.,37773951,https://pubmed.ncbi.nlm.nih.gov/37773951/,https://doi.org/10.1371/journal.pcbi.1011436,[],"Microbiomes interact dynamically with their environment to perform exploitable functions such as production of valuable metabolites and degradation of toxic metabolites for a wide range of applications in human health, agriculture, and environmental cleanup. Developing computational models to predict the key bacterial species and environmental factors to build and optimize such functions are crucial to accelerate microbial community engineering. However, there is an unknown web of interactions that determine the highly complex and dynamic behavior of these systems, which precludes the development of models based on known mechanisms. By contrast, entirely data-driven machine learning models can produce physically unrealistic predictions and often require significant amounts of experimental data to learn system behavior. We develop a physically-constrained recurrent neural network that preserves model flexibility but is constrained to produce physically consistent predictions and show that it can outperform existing machine learning methods in the prediction of certain experimentally measured species abundance and metabolite concentrations. Further, we present a closed-loop, Bayesian experimental design algorithm to guide data collection by selecting experimental conditions that simultaneously maximize information gain and target microbial community functions. Using a bioreactor case study, we demonstrate how the proposed framework can be used to efficiently navigate a large design space to identify optimal operating conditions. The proposed methodology offers a flexible machine learning approach specifically tailored to optimize microbiome target functions through the sequential design of informative experiments that seek to explore and exploit community functions.",2,Microbiomes interact dynamically with their environment to perform exploitable functions such as production of valuable metabolites and degradation of toxic metabolites.
"Profile-Wise Analysis: A profile likelihood-based workflow for identifiability analysis, estimation, and prediction with mechanistic mathematical models.",37773942,https://pubmed.ncbi.nlm.nih.gov/37773942/,https://doi.org/10.1371/journal.pcbi.1011515,[],"Interpreting data using mechanistic mathematical models provides a foundation for discovery and decision-making in all areas of science and engineering. Developing mechanistic insight by combining mathematical models and experimental data is especially critical in mathematical biology as new data and new types of data are collected and reported. Key steps in using mechanistic mathematical models to interpret data include: (i) identifiability analysis; (ii) parameter estimation; and (iii) model prediction. Here we present a systematic, computationally-efficient workflow we call Profile-Wise Analysis (PWA) that addresses all three steps in a unified way. Recently-developed methods for constructing 'profile-wise' prediction intervals enable this workflow and provide the central linkage between different workflow components. These methods propagate profile-likelihood-based confidence sets for model parameters to predictions in a way that isolates how different parameter combinations affect model predictions. We show how to extend these profile-wise prediction intervals to two-dimensional interest parameters. We then demonstrate how to combine profile-wise prediction confidence sets to give an overall prediction confidence set that approximates the full likelihood-based prediction confidence set well. Our three case studies illustrate practical aspects of the workflow, focusing on ordinary differential equation (ODE) mechanistic models with both Gaussian and non-Gaussian noise models. While the case studies focus on ODE-based models, the workflow applies to other classes of mathematical models, including partial differential equations and simulation-based stochastic models. Open-source software on GitHub can be used to replicate the case studies.",1,Interpreting data using mechanistic mathematical models provides a foundation for discovery and decision-making in all areas of science and engineering.
Multimodal analysis and the oncology patient: Creating a hospital system for integrated diagnostics and discovery.,37767106,https://pubmed.ncbi.nlm.nih.gov/37767106/,https://doi.org/10.1016/j.csbj.2023.09.014,"['Artificial Intelligence', 'Computational Oncology', 'Digital Pathology', 'Health data', 'Integrated Diagnostics and Discovery', 'Multimodal Analysis', 'Radiomics']","We propose that an information technology and computational framework that would unify access to hospital digital information silos, and enable integration of this information using machine learning methods, would bring a new paradigm to patient management and research. This is the core principle of Integrated Diagnostics (ID): ",1,"An information technology and computational framework that would unify access to hospital digital information silos, and enable integration of this information using machine learning methods, would bring a new paradigm to patient management"
A heterogeneous graph convolutional attention network method for classification of autism spectrum disorder.,37759189,https://pubmed.ncbi.nlm.nih.gov/37759189/,https://doi.org/10.1186/s12859-023-05495-7,"['ASD', 'Attention mechanism', 'FMRI', 'Heterogeneous graph convolution network']","Autism spectrum disorder (ASD) is a serious developmental disorder of the brain. Recently, various deep learning methods based on functional magnetic resonance imaging (fMRI) data have been developed for the classification of ASD. Among them, graph neural networks, which generalize deep neural network models to graph structured data, have shown great advantages. However, in graph neural methods, because the graphs constructed are homogeneous, the phenotype information of the subjects cannot be fully utilized. This affects the improvement of the classification performance.",1,Autism spectrum disorder (ASD) is a serious developmental disorder of the brain.
A molecule perturbation software library and its application to study the effects of molecular design constraints.,37752561,https://pubmed.ncbi.nlm.nih.gov/37752561/,https://doi.org/10.1186/s13321-023-00761-5,"['Chemical space', 'Constraints', 'De novo molecule generation', 'Molecular design', 'Molecular fingerprints', 'RDKit', 'Software library', 'Topological perturbations']","Computational molecular design can yield chemically unreasonable compounds when performed carelessly. A popular strategy to mitigate this risk is mimicking reference chemistry. This is commonly achieved by restricting the way in which molecules are constructed or modified. While it is well established that such an approach helps in designing chemically appealing molecules, concerns about these restrictions impacting chemical space exploration negatively linger. In this work we present a software library for constrained graph-based molecule manipulation and showcase its functionality by developing a molecule generator. Said generator designs molecules mimicking reference chemical features of differing granularity. We find that restricting molecular construction lightly, beyond the usual positive effects on drug-likeness and synthesizability of designed molecules, provides guidance to optimization algorithms navigating chemical space. Nonetheless, restricting molecular construction excessively can indeed hinder effective chemical space exploration.",1, Computational molecular design can yield chemically unreasonable compounds when performed carelessly.. A popular strategy to mitigate this risk is mimicking reference chemistry.
Comprehensive evaluation of methods for differential expression analysis of metatranscriptomics data.,37738402,https://pubmed.ncbi.nlm.nih.gov/37738402/,https://doi.org/10.1093/bib/bbad279,"['benchmark', 'differential expression', 'early childhood caries', 'logistic-beta', 'metagenomics', 'metatranscriptomics']","Understanding the function of the human microbiome is important but the development of statistical methods specifically for the microbial gene expression (i.e. metatranscriptomics) is in its infancy. Many currently employed differential expression analysis methods have been designed for different data types and have not been evaluated in metatranscriptomics settings. To address this gap, we undertook a comprehensive evaluation and benchmarking of 10 differential analysis methods for metatranscriptomics data. We used a combination of real and simulated data to evaluate performance (i.e. type I error, false discovery rate and sensitivity) of the following methods: log-normal (LN), logistic-beta (LB), MAST, DESeq2, metagenomeSeq, ANCOM-BC, LEfSe, ALDEx2, Kruskal-Wallis and two-part Kruskal-Wallis. The simulation was informed by supragingival biofilm microbiome data from 300 preschool-age children enrolled in a study of childhood dental disease (early childhood caries, ECC), whereas validations were sought in two additional datasets from the ECC study and an inflammatory bowel disease study. The LB test showed the highest sensitivity in both small and large samples and reasonably controlled type I error. Contrarily, MAST was hampered by inflated type I error. Upon application of the LN and LB tests in the ECC study, we found that genes C8PHV7 and C8PEV7, harbored by the lactate-producing Campylobacter gracilis, had the strongest association with childhood dental disease. This comprehensive model evaluation offers practical guidance for selection of appropriate methods for rigorous analyses of differential expression in metatranscriptomics. Selection of an optimal method increases the possibility of detecting true signals while minimizing the chance of claiming false ones.",1,"Log-normal (LN), logistic-beta (LB), MAST, DESeq2, metagenomeSeq, ANCOM-BC, LEfSe, AL"
A platform-independent framework for phenotyping of multiplex tissue imaging data.,37733781,https://pubmed.ncbi.nlm.nih.gov/37733781/,https://doi.org/10.1371/journal.pcbi.1011432,[],"Multiplex imaging is a powerful tool to analyze the structural and functional states of cells in their morphological and pathological contexts. However, hypothesis testing with multiplex imaging data is a challenging task due to the extent and complexity of the information obtained. Various computational pipelines have been developed and validated to extract knowledge from specific imaging platforms. A common problem with customized pipelines is their reduced applicability across different imaging platforms: Every multiplex imaging technique exhibits platform-specific characteristics in terms of signal-to-noise ratio and acquisition artifacts that need to be accounted for to yield reliable and reproducible results. We propose a pixel classifier-based image preprocessing step that aims to minimize platform-dependency for all multiplex image analysis pipelines. Signal detection and noise reduction as well as artifact removal can be posed as a pixel classification problem in which all pixels in multiplex images can be assigned to two general classes of either I) signal of interest or II) artifacts and noise. The resulting feature representation maps contain pixel-scale representations of the input data, but exhibit significantly increased signal-to-noise ratios with normalized pixel values as output data. We demonstrate the validity of our proposed image preprocessing approach by comparing the results of two well-accepted and widely-used image analysis pipelines.",1,Multiplex imaging is a powerful tool to analyze the structural and functional states of cells.
MoleculeExperiment enables consistent infrastructure for molecule-resolved spatial omics data in bioconductor.,37698995,https://pubmed.ncbi.nlm.nih.gov/37698995/,https://doi.org/10.1093/bioinformatics/btad550,[],"Imaging-based spatial transcriptomics (ST) technologies have achieved subcellular resolution, enabling detection of individual molecules in their native tissue context. Data associated with these technologies promise unprecedented opportunity toward understanding cellular and subcellular biology. However, in R/Bioconductor, there is a scarcity of existing computational infrastructure to represent such data, and particularly to summarize and transform it for existing widely adopted computational tools in single-cell transcriptomics analysis, including SingleCellExperiment and SpatialExperiment (SPE) classes. With the emergence of several commercial offerings of imaging-based ST, there is a pressing need to develop consistent data structure standards for these technologies at the individual molecule-level.",3,"In R/Bioconductor, there is a scarcity of existing computational infrastructure to represent such data."
Multimodal data fusion for cancer biomarker discovery with deep learning.,37693852,https://pubmed.ncbi.nlm.nih.gov/37693852/,https://doi.org/10.1038/s42256-023-00633-5,[],"Technological advances now make it possible to study a patient from multiple angles with high-dimensional, high-throughput multi-scale biomedical data. In oncology, massive amounts of data are being generated ranging from molecular, histopathology, radiology to clinical records. The introduction of deep learning has significantly advanced the analysis of biomedical data. However, most approaches focus on single data modalities leading to slow progress in methods to integrate complementary data types. Development of effective multimodal fusion approaches is becoming increasingly important as a single modality might not be consistent and sufficient to capture the heterogeneity of complex diseases to tailor medical care and improve personalised medicine. Many initiatives now focus on integrating these disparate modalities to unravel the biological processes involved in multifactorial diseases such as cancer. However, many obstacles remain, including lack of usable data as well as methods for clinical validation and interpretation. Here, we cover these current challenges and reflect on opportunities through deep learning to tackle data sparsity and scarcity, multimodal interpretability, and standardisation of datasets.",7,"In oncology, massive amounts of data are being generated ranging from molecular, histopathology, radiology to clinical records."
An extensive benchmark study on biomedical text generation and mining with ChatGPT.,37682111,https://pubmed.ncbi.nlm.nih.gov/37682111/,https://doi.org/10.1093/bioinformatics/btad557,[],"In recent years, the development of natural language process (NLP) technologies and deep learning hardware has led to significant improvement in large language models (LLMs). The ChatGPT, the state-of-the-art LLM built on GPT-3.5 and GPT-4, shows excellent capabilities in general language understanding and reasoning. Researchers also tested the GPTs on a variety of NLP-related tasks and benchmarks and got excellent results. With exciting performance on daily chat, researchers began to explore the capacity of ChatGPT on expertise that requires professional education for human and we are interested in the biomedical domain.",6,ChatGPT shows excellent capabilities in general language understanding and reasoning.
Malignant Mesothelioma subtyping via sampling driven multiple instance prediction on tissue image and cell morphology data.,37673586,https://pubmed.ncbi.nlm.nih.gov/37673586/,https://doi.org/10.1016/j.artmed.2023.102628,"['Cancer subtyping', 'Computational pathology', 'Deep learning', 'Malignant Mesothelioma', 'Multiple instance learning']","Malignant Mesothelioma is a difficult to diagnose and highly lethal cancer usually associated with asbestos exposure. It can be broadly classified into three subtypes: Epithelioid, Sarcomatoid, and a hybrid Biphasic subtype in which significant components of both of the previous subtypes are present. Early diagnosis and identification of the subtype informs treatment and can help improve patient outcome. However, the subtyping of malignant mesothelioma, and specifically the recognition of transitional features from routine histology slides has a high level of inter-observer variability. In this work, we propose an end-to-end multiple instance learning (MIL) approach for malignant mesothelioma subtyping. This uses an adaptive instance-based sampling scheme for training deep convolutional neural networks on bags of image patches that allows learning on a wider range of relevant instances compared to max or top-N based MIL approaches. We also investigate augmenting the instance representation to include aggregate cellular morphology features from cell segmentation. The proposed MIL approach enables identification of malignant mesothelial subtypes of specific tissue regions. From this a continuous characterisation of a sample according to predominance of sarcomatoid vs epithelioid regions is possible, thus avoiding the arbitrary and highly subjective categorisation by currently used subtypes. Instance scoring also enables studying tumor heterogeneity and identifying patterns associated with different subtypes. We have evaluated the proposed method on a dataset of 234 tissue micro-array cores with an AUROC of 0.89±0.05 for this task. The dataset and developed methodology is available for the community at: https://github.com/measty/PINS.",1,Malignant Mesothelioma is a difficult to diagnose and highly lethal cancer usually associated with asbestos exposure.
PyDESeq2: a python package for bulk RNA-seq differential expression analysis.,37669147,https://pubmed.ncbi.nlm.nih.gov/37669147/,https://doi.org/10.1093/bioinformatics/btad547,[],"We present PyDESeq2, a python implementation of the DESeq2 workflow for differential expression analysis on bulk RNA-seq data. This re-implementation yields similar, but not identical, results: it achieves higher model likelihood, allows speed improvements on large datasets, as shown in experiments on TCGA data, and can be more easily interfaced with modern python-based data science tools.",10,PyDESeq2 is a python implementation of the DESeq2 workflow for differential expression analysis on bulk RNA-seq data.
Phylogenetic inference using generative adversarial networks.,37669126,https://pubmed.ncbi.nlm.nih.gov/37669126/,https://doi.org/10.1093/bioinformatics/btad543,[],"The application of machine learning approaches in phylogenetics has been impeded by the vast model space associated with inference. Supervised machine learning approaches require data from across this space to train models. Because of this, previous approaches have typically been limited to inferring relationships among unrooted quartets of taxa, where there are only three possible topologies. Here, we explore the potential of generative adversarial networks (GANs) to address this limitation. GANs consist of a generator and a discriminator: at each step, the generator aims to create data that is similar to real data, while the discriminator attempts to distinguish generated and real data. By using an evolutionary model as the generator, we use GANs to make evolutionary inferences. Since a new model can be considered at each iteration, heuristic searches of complex model spaces are possible. Thus, GANs offer a potential solution to the challenges of applying machine learning in phylogenetics.",1,The application of machine learning approaches in phylogenetics has been impeded by the vast model space associated with inference.
Machine Learning-Boosted Docking Enables the Efficient Structure-Based Virtual Screening of Giga-Scale Enumerated Chemical Libraries.,37655823,https://pubmed.ncbi.nlm.nih.gov/37655823/,https://doi.org/10.1021/acs.jcim.3c01239,[],"The emergence of ultra-large screening libraries, filled to the brim with billions of readily available compounds, poses a growing challenge for docking-based virtual screening. Machine learning (ML)-boosted strategies like the tool HASTEN combine rapid ML prediction with the brute-force docking of small fractions of such libraries to increase screening throughput and take on giga-scale libraries. In our case study of an anti-bacterial chaperone and an anti-viral kinase, we first generated a brute-force docking baseline for 1.56 billion compounds in the Enamine REAL lead-like library with the fast Glide high-throughput virtual screening protocol. With HASTEN, we observed robust recall of 90% of the true 1000 top-scoring virtual hits in both targets when docking only 1% of the entire library. This reduction of the required docking experiments by 99% significantly shortens the screening time. In the kinase target, the employment of a hydrogen bonding constraint resulted in a major proportion of unsuccessful docking attempts and hampered ML predictions. We demonstrate the optimization potential in the treatment of failed compounds when performing ML-boosted screening and benchmark and showcase HASTEN as a fast and robust tool in a growing arsenal of approaches to unlock the chemical space covered by giga-scale screening libraries for everyday drug discovery campaigns.",1,Machine learning (ML)-boosted strategies like the tool HASTEN combine rapid ML prediction with the brute-force docking of small fractions of such libraries to increase screening throughput and take on
Neural network models for influenza forecasting with associated uncertainty using Web search activity trends.,37639427,https://pubmed.ncbi.nlm.nih.gov/37639427/,https://doi.org/10.1371/journal.pcbi.1011392,[],"Influenza affects millions of people every year. It causes a considerable amount of medical visits and hospitalisations as well as hundreds of thousands of deaths. Forecasting influenza prevalence with good accuracy can significantly help public health agencies to timely react to seasonal or novel strain epidemics. Although significant progress has been made, influenza forecasting remains a challenging modelling task. In this paper, we propose a methodological framework that improves over the state-of-the-art forecasting accuracy of influenza-like illness (ILI) rates in the United States. We achieve this by using Web search activity time series in conjunction with historical ILI rates as observations for training neural network (NN) architectures. The proposed models incorporate Bayesian layers to produce associated uncertainty intervals to their forecast estimates, positioning themselves as legitimate complementary solutions to more conventional approaches. The best performing NN, referred to as the iterative recurrent neural network (IRNN) architecture, reduces mean absolute error by 10.3% and improves skill by 17.1% on average in nowcasting and forecasting tasks across 4 consecutive flu seasons.",1,Influenza affects millions of people every year.
Somatic mutation effects diffused over microRNA dysregulation.,37624931,https://pubmed.ncbi.nlm.nih.gov/37624931/,https://doi.org/10.1093/bioinformatics/btad520,[],"As an important player in transcriptome regulation, microRNAs may effectively diffuse somatic mutation impacts to broad cellular processes and ultimately manifest disease and dictate prognosis. Previous studies that tried to correlate mutation with gene expression dysregulation neglected to adjust for the disparate multitudes of false positives associated with unequal sample sizes and uneven class balancing scenarios.",1,MicroRNAs may effectively diffuse somatic mutation impacts to broad cellular processes and ultimately manifest disease and dictate prognosis.
EnzyHTP Computational Directed Evolution with Adaptive Resource Allocation.,37611241,https://pubmed.ncbi.nlm.nih.gov/37611241/,https://doi.org/10.1021/acs.jcim.3c00618,[],"Directed evolution facilitates enzyme engineering via iterative rounds of mutagenesis. Despite the wide applications of high-throughput screening, building ""smart libraries"" to effectively identify beneficial variants remains a major challenge in the community. Here, we developed a new computational directed evolution protocol based on EnzyHTP, a software that we have previously reported to automate enzyme modeling. To enhance the throughput efficiency, we implemented an adaptive resource allocation strategy that dynamically allocates different types of computing resources (e.g., GPU/CPU) based on the specific need of an enzyme modeling subtask in the workflow. We implemented the strategy as a Python library and tested the library using fluoroacetate dehalogenase as a model enzyme. The results show that compared to fixed resource allocation where both CPU and GPU are on-call for use during the entire workflow, applying adaptive resource allocation can save 87% CPU hours and 14% GPU hours. Furthermore, we constructed a computational directed evolution protocol under the framework of adaptive resource allocation. The workflow was tested against two rounds of mutational screening in the directed evolution experiments of Kemp eliminase (KE07) with a total of 184 mutants. Using folding stability and electrostatic stabilization energy as computational readout, we identified all four experimentally observed target variants. Enabled by the workflow, the entire computation task (i.e., 18.4 μs MD and 18,400 QM single-point calculations) completes in 3 days of wall-clock time using ∼30 GPUs and ∼1000 CPUs.",2,Directed evolution facilitates enzyme engineering via iterative rounds of mutagenesis.
"Targeted Protein Degradation: Advances, Challenges, and Prospects for Computational Methods.",37602861,https://pubmed.ncbi.nlm.nih.gov/37602861/,https://doi.org/10.1021/acs.jcim.3c00603,[],"The therapeutic approach of targeted protein degradation (TPD) is gaining momentum due to its potentially superior effects compared with protein inhibition. Recent advancements in the biotech and pharmaceutical sectors have led to the development of compounds that are currently in human trials, with some showing promising clinical results. However, the use of computational tools in TPD is still limited, as it has distinct characteristics compared with traditional computational drug design methods. TPD involves creating a ternary structure (protein-degrader-ligase) responsible for the biological function, such as ubiquitination and subsequent proteasomal degradation, which depends on the spatial orientation of the protein of interest (POI) relative to E2-loaded ubiquitin. Modeling this structure necessitates a unique blend of tools initially developed for small molecules (e.g., docking) and biologics (e.g., protein-protein interaction modeling). Additionally, degrader molecules, particularly heterobifunctional degraders, are generally larger than conventional small molecule drugs, leading to challenges in determining drug-like properties like solubility and permeability. Furthermore, the catalytic nature of TPD makes occupancy-based modeling insufficient. TPD consists of multiple interconnected yet distinct steps, such as POI binding, E3 ligase binding, ternary structure interactions, ubiquitination, and degradation, along with traditional small molecule properties. A comprehensive set of tools is needed to address the dynamic nature of the induced proximity ternary complex and its implications for ubiquitination. In this Perspective, we discuss the current state of computational tools for TPD. We start by describing the series of steps involved in the degradation process and the experimental methods used to characterize them. Then, we delve into a detailed analysis of the computational tools employed in TPD. We also present an integrative approach that has proven successful for degrader design and its impact on project decisions. Finally, we examine the future prospects of computational methods in TPD and the areas with the greatest potential for impact.",1,The therapeutic approach of targeted protein degradation (TPD) is gaining momentum due to its potentially superior effects compared with protein inhibition.
The specious art of single-cell genomics.,37590228,https://pubmed.ncbi.nlm.nih.gov/37590228/,https://doi.org/10.1371/journal.pcbi.1011288,[],"Dimensionality reduction is standard practice for filtering noise and identifying relevant features in large-scale data analyses. In biology, single-cell genomics studies typically begin with reduction to 2 or 3 dimensions to produce ""all-in-one"" visuals of the data that are amenable to the human eye, and these are subsequently used for qualitative and quantitative exploratory analysis. However, there is little theoretical support for this practice, and we show that extreme dimension reduction, from hundreds or thousands of dimensions to 2, inevitably induces significant distortion of high-dimensional datasets. We therefore examine the practical implications of low-dimensional embedding of single-cell data and find that extensive distortions and inconsistent practices make such embeddings counter-productive for exploratory, biological analyses. In lieu of this, we discuss alternative approaches for conducting targeted embedding and feature exploration to enable hypothesis-driven biological discovery.",31, Dimensionality reduction is standard practice for filtering noise and identifying relevant features in large-scale data analyses.
MolSHAP: Interpreting Quantitative Structure-Activity Relationships Using Shapley Values of R-Groups.,37584270,https://pubmed.ncbi.nlm.nih.gov/37584270/,https://doi.org/10.1021/acs.jcim.3c00465,[],"Optimizing the activities and properties of lead compounds is an essential step in the drug discovery process. Despite recent advances in machine learning-aided drug discovery, most of the existing methods focus on making predictions for the desired objectives directly while ignoring the explanations for predictions. Although several techniques can provide interpretations for machine learning-based methods such as feature attribution, there are still gaps between these interpretations and the principles commonly adopted by medicinal chemists when designing and optimizing molecules. Here, we propose an interpretation framework, named MolSHAP, for quantitative structure-activity relationship analysis by estimating the contributions of R-groups. Instead of attributing the activities to individual input features, MolSHAP regards the R-group fragments as the basic units of interpretation, which is in accordance with the fragment-based modifications in molecule optimization. MolSHAP is a model-agnostic method that can interpret activity regression models with arbitrary input formats and model architectures. Based on the evaluations of numerous representative activity regression models on a specially designed R-group ranking task, MolSHAP achieved significantly better interpretation power compared with other methods. In addition, we developed a compound optimization algorithm based on MolSHAP and illustrated the reliability of the optimized compounds using an independent case study. These results demonstrated that MolSHAP can provide a useful tool for accurately interpreting the quantitative structure-activity relationships and rationally optimizing the compound activities in drug discovery.",2,MolSHAP is a model-agnostic method that can interpret activity regression models with arbitrary input formats and model architectures.
"A stochastic analysis of the interplay between antibiotic dose, mode of action, and bacterial competition in the evolution of antibiotic resistance.",37578976,https://pubmed.ncbi.nlm.nih.gov/37578976/,https://doi.org/10.1371/journal.pcbi.1011364,[],"The use of an antibiotic may lead to the emergence and spread of bacterial strains resistant to this antibiotic. Experimental and theoretical studies have investigated the drug dose that minimizes the risk of resistance evolution over the course of treatment of an individual, showing that the optimal dose will either be the highest or the lowest drug concentration possible to administer; however, no analytical results exist that help decide between these two extremes. To address this gap, we develop a stochastic mathematical model of bacterial dynamics under antibiotic treatment. We explore various scenarios of density regulation (bacterial density affects cell birth or death rates), and antibiotic modes of action (biostatic or biocidal). We derive analytical results for the survival probability of the resistant subpopulation until the end of treatment, the size of the resistant subpopulation at the end of treatment, the carriage time of the resistant subpopulation until it is replaced by a sensitive one after treatment, and we verify these results with stochastic simulations. We find that the scenario of density regulation and the drug mode of action are important determinants of the survival of a resistant subpopulation. Resistant cells survive best when bacterial competition reduces cell birth and under biocidal antibiotics. Compared to an analogous deterministic model, the population size reached by the resistant type is larger and carriage time is slightly reduced by stochastic loss of resistant cells. Moreover, we obtain an analytical prediction of the antibiotic concentration that maximizes the survival of resistant cells, which may help to decide which drug dosage (not) to administer. Our results are amenable to experimental tests and help link the within and between host scales in epidemiological models.",1,The use of an antibiotic may lead to the emergence and spread of bacterial strains resistant to this antibiotic.
A structured evaluation of genome-scale constraint-based modeling tools for microbial consortia.,37578975,https://pubmed.ncbi.nlm.nih.gov/37578975/,https://doi.org/10.1371/journal.pcbi.1011363,[],"Harnessing the power of microbial consortia is integral to a diverse range of sectors, from healthcare to biotechnology to environmental remediation. To fully realize this potential, it is critical to understand the mechanisms behind the interactions that structure microbial consortia and determine their functions. Constraint-based reconstruction and analysis (COBRA) approaches, employing genome-scale metabolic models (GEMs), have emerged as the state-of-the-art tool to simulate the behavior of microbial communities from their constituent genomes. In the last decade, many tools have been developed that use COBRA approaches to simulate multi-species consortia, under either steady-state, dynamic, or spatiotemporally varying scenarios. Yet, these tools have not been systematically evaluated regarding their software quality, most suitable application, and predictive power. Hence, it is uncertain which tools users should apply to their system and what are the most urgent directions that developers should take in the future to improve existing capacities. This study conducted a systematic evaluation of COBRA-based tools for microbial communities using datasets from two-member communities as test cases. First, we performed a qualitative assessment in which we evaluated 24 published tools based on a list of FAIR (Findability, Accessibility, Interoperability, and Reusability) features essential for software quality. Next, we quantitatively tested the predictions in a subset of 14 of these tools against experimental data from three different case studies: a) syngas fermentation by C. autoethanogenum and C. kluyveri for the static tools, b) glucose/xylose fermentation with engineered E. coli and S. cerevisiae for the dynamic tools, and c) a Petri dish of E. coli and S. enterica for tools incorporating spatiotemporal variation. Our results show varying performance levels of the best qualitatively assessed tools when examining the different categories of tools. The differences in the mathematical formulation of the approaches and their relation to the results were also discussed. Ultimately, we provide recommendations for refining future GEM microbial modeling tools.",4,"Constraint-based reconstruction and analysis (COBRA) approaches, employing genome-scale metabolic models (GEMs), have emerged as the state-of-the-art"
Intrinsic motivation for choice varies with individual risk attitudes and the controllability of the environment.,37566636,https://pubmed.ncbi.nlm.nih.gov/37566636/,https://doi.org/10.1371/journal.pcbi.1010551,[],"When deciding between options that do or do not lead to future choices, humans often choose to choose. We studied choice seeking by asking subjects to first decide between a choice opportunity or performing a computer-selected action, after which they either chose freely or performed the forced action. Subjects preferred choice when these options were equally rewarded, even deterministically, and traded extrinsic rewards for opportunities to choose. We explained individual variability in choice seeking using reinforcement learning models incorporating risk sensitivity and overvaluation of rewards obtained through choice. Model fits revealed that 28% of subjects were sensitive to the worst possible outcome associated with free choice, and this pessimism reduced their choice preference with increasing risk. Moreover, outcome overvaluation was necessary to explain patterns of individual choice preference across levels of risk. We also manipulated the degree to which subjects controlled stimulus outcomes. We found that degrading coherence between their actions and stimulus outcomes diminished choice preference following forced actions, although willingness to repeat selection of choice opportunities remained high. When subjects chose freely during these repeats, they were sensitive to rewards when actions were controllable but ignored outcomes-even positive ones-associated with reduced controllability. Our results show that preference for choice can be modulated by extrinsic reward properties including reward probability and risk as well as by controllability of the environment.",1,Researchers studied choice seeking by asking subjects to first decide between a choice opportunity or performing a computer-selected action.
De Novo Design of κ-Opioid Receptor Antagonists Using a Generative Deep-Learning Framework.,37555591,https://pubmed.ncbi.nlm.nih.gov/37555591/,https://doi.org/10.1021/acs.jcim.3c00651,[],"Likely effective pharmacological interventions for the treatment of opioid addiction include attempts to attenuate brain reward deficits during periods of abstinence. Pharmacological blockade of the κ-opioid receptor (KOR) has been shown to abolish brain reward deficits in rodents during withdrawal, as well as to reduce the escalation of opioid use in rats with extended access to opioids. Although KOR antagonists represent promising candidates for the treatment of opioid addiction, very few potent selective KOR antagonists are known to date and most of them exhibit significant safety concerns. Here, we used a generative deep-learning framework for the ",1,Pharmacological blockade of the κ-opioid receptor (KOR) has been shown to abolish brain reward deficits in rodents during withdrawal.
Spatial organisation of the mesoscale connectome: A feature influencing synchrony and metastability of network dynamics.,37552650,https://pubmed.ncbi.nlm.nih.gov/37552650/,https://doi.org/10.1371/journal.pcbi.1011349,[],"Significant research has investigated synchronisation in brain networks, but the bulk of this work has explored the contribution of brain networks at the macroscale. Here we explore the effects of changing network topology on functional dynamics in spatially constrained random networks representing mesoscale neocortex. We use the Kuramoto model to simulate network dynamics and explore synchronisation and critical dynamics of the system as a function of topology in randomly generated networks with a distance-related wiring probability and no preferential attachment term. We show networks which predominantly make short-distance connections smooth out the critical coupling point and show much greater metastability, resulting in a wider range of coupling strengths demonstrating critical dynamics and metastability. We show the emergence of cluster synchronisation in these geometrically-constrained networks with functional organisation occurring along structural connections that minimise the participation coefficient of the cluster. We show that these cohorts of internally synchronised nodes also behave en masse as weakly coupled nodes and show intra-cluster desynchronisation and resynchronisation events related to inter-cluster interaction. While cluster synchronisation appears crucial to healthy brain function, it may also be pathological if it leads to unbreakable local synchronisation which may happen at extreme topologies, with implications for epilepsy research, wider brain function and other domains such as social networks.",1,The study looked at the effects of changing network topology on functional dynamics in spatially constrained random networks representing mesoscale neocortex.
Simulating the effect of ankle plantarflexion and inversion-eversion exoskeleton torques on center of mass kinematics during walking.,37549183,https://pubmed.ncbi.nlm.nih.gov/37549183/,https://doi.org/10.1371/journal.pcbi.1010712,[],"Walking balance is central to independent mobility, and falls due to loss of balance are a leading cause of death for people 65 years of age and older. Bipedal gait is typically unstable, but healthy humans use corrective torques to counteract perturbations and stabilize gait. Exoskeleton assistance could benefit people with neuromuscular deficits by providing stabilizing torques at lower-limb joints to replace lost muscle strength and sensorimotor control. However, it is unclear how applied exoskeleton torques translate to changes in walking kinematics. This study used musculoskeletal simulation to investigate how exoskeleton torques applied to the ankle and subtalar joints alter center of mass kinematics during walking. We first created muscle-driven walking simulations using OpenSim Moco by tracking experimental kinematics and ground reaction forces recorded from five healthy adults. We then used forward integration to simulate the effect of exoskeleton torques applied to the ankle and subtalar joints while keeping muscle excitations fixed based on our previous tracking simulation results. Exoskeleton torque lasted for 15% of the gait cycle and was applied between foot-flat and toe-off during the stance phase, and changes in center of mass kinematics were recorded when the torque application ended. We found that changes in center of mass kinematics were dependent on both the type and timing of exoskeleton torques. Plantarflexion torques produced upward and backward changes in velocity of the center of mass in mid-stance and upward and smaller forward velocity changes near toe-off. Eversion and inversion torques primarily produced lateral and medial changes in velocity in mid-stance, respectively. Intrinsic muscle properties reduced kinematic changes from exoskeleton torques. Our results provide mappings between ankle plantarflexion and inversion-eversion torques and changes in center of mass kinematics which can inform designers building exoskeletons aimed at stabilizing balance during walking. Our simulations and software are freely available and allow researchers to explore the effects of applied torques on balance and gait.",4,Exoskeleton assistance could benefit people with neuromuscular deficits by providing stabilizing torques at lower-limb joints.
Evolutionary dynamics on sequential temporal networks.,37549167,https://pubmed.ncbi.nlm.nih.gov/37549167/,https://doi.org/10.1371/journal.pcbi.1011333,[],"Population structure is a well-known catalyst for the evolution of cooperation and has traditionally been considered to be static in the course of evolution. Conversely, real-world populations, such as microbiome communities and online social networks, frequently show a progression from tiny, active groups to huge, stable communities, which is insufficient to be captured by constant structures. Here, we propose sequential temporal networks to characterize growing networked populations, and we extend the theory of evolutionary games to these temporal networks with arbitrary structures and growth rules. We derive analytical rules under which a sequential temporal network has a higher fixation probability for cooperation than its static counterpart. Under neutral drift, the rule is simply a function of the increment of nodes and edges in each time step. But if the selection is weak, the rule is related to coalescence times on networks. In this case, we propose a mean-field approximation to calculate fixation probabilities and critical benefit-to-cost ratios with lower calculation complexity. Numerical simulations in empirical datasets also prove the cooperation-promoting effect of population growth. Our research stresses the significance of population growth in the real world and provides a high-accuracy approximation approach for analyzing the evolution in real-life systems.",2,Population structure is a well-known catalyst for the evolution of cooperation.
"A Novel ""Activation Switch"" Motif Common to All Aminergic Receptors.",37540602,https://pubmed.ncbi.nlm.nih.gov/37540602/,https://doi.org/10.1021/acs.jcim.3c00732,"['aminergic receptors', 'conformational analysis', 'cryo-EM structures', 'crystal structures', 'ligand binding pocket', 'receptor activation']","Aminergic receptors are G protein-coupled receptors (GPCRs) that transduce signals from small endogenous biogenic amines to regulate intracellular signaling pathways. Agonist binding in the ligand binding pocket on the extracellular side opens and prepares a cavity on the intracellular face of the receptors to interact with and activate G proteins and β-arrestins. Here, by reviewing and analyzing all available aminergic receptor structures, we seek to identify activation-related conformational changes that are independent of the specific scaffold of the bound agonist, which we define as ""activation conformational changes"" (ACCs). While some common intracellular ACCs have been well-documented, identifying common extracellular ACCs, including those in the ligand binding pocket, is complicated by local adjustments to different ligand scaffolds. Our analysis shows no common ACCs at the extracellular ends of the transmembrane helices. Furthermore, the restricted access to the ligand binding pocket identified previously in some receptors is not universal. Notably, the Trp",2,Aminergic receptors are G protein-coupled receptors that regulate intracellular signaling pathways.
Block Aligner: an adaptive SIMD-accelerated aligner for sequences and position-specific scoring matrices.,37535681,https://pubmed.ncbi.nlm.nih.gov/37535681/,https://doi.org/10.1093/bioinformatics/btad487,[],"Efficiently aligning sequences is a fundamental problem in bioinformatics. Many recent algorithms for computing alignments through Smith-Waterman-Gotoh dynamic programming (DP) exploit Single Instruction Multiple Data (SIMD) operations on modern CPUs for speed. However, these advances have largely ignored difficulties associated with efficiently handling complex scoring matrices or large gaps (insertions or deletions).",1,Efficiently aligning sequences is a fundamental problem in bioinformatics.
"Multi-task prediction-based graph contrastive learning for inferring the relationship among lncRNAs, miRNAs and diseases.",37529914,https://pubmed.ncbi.nlm.nih.gov/37529914/,https://doi.org/10.1093/bib/bbad276,"['graph contrastive learning', 'lncRNA-disease association', 'lncRNA–miRNA interaction', 'miRNA-disease association', 'multi-task prediction']","Identifying the relationships among long non-coding RNAs (lncRNAs), microRNAs (miRNAs) and diseases is highly valuable for diagnosing, preventing, treating and prognosing diseases. The development of effective computational prediction methods can reduce experimental costs. While numerous methods have been proposed, they often to treat the prediction of lncRNA-disease associations (LDAs), miRNA-disease associations (MDAs) and lncRNA-miRNA interactions (LMIs) as separate task. Models capable of predicting all three relationships simultaneously remain relatively scarce. Our aim is to perform multi-task predictions, which not only construct a unified framework, but also facilitate mutual complementarity of information among lncRNAs, miRNAs and diseases.",1,"Identifying the relationships among long non-coding RNAs (lncRNAs), microRNAs (miRNAs) and diseases is highly valuable for diagnosing, preventing,"
Exploration of whole genome amplification generated chimeric sequences in long-read sequencing data.,37529913,https://pubmed.ncbi.nlm.nih.gov/37529913/,https://doi.org/10.1093/bib/bbad275,"['chimeric sequence', 'long-reads sequencing', 'multiple displacement amplification']","Multiple displacement amplification (MDA) has become the most commonly used method of whole genome amplification, generating a vast amount of DNA with higher molecular weight and greater genome coverage. Coupling with long-read sequencing, it is possible to sequence the amplicons of over 20 kb in length. However, the formation of chimeric sequences (chimeras, expressed as structural errors in sequencing data) in MDA seriously interferes with the bioinformatics analysis but its influence on long-read sequencing data is unknown.",1,Multiple displacement amplification (MDA) has become the most commonly used method of whole genome amplification.
VMD as a Platform for Interactive Small Molecule Preparation and Visualization in Quantum and Classical Simulations.,37506321,https://pubmed.ncbi.nlm.nih.gov/37506321/,https://doi.org/10.1021/acs.jcim.3c00658,[],"Modeling and simulation of small molecules such as drugs and biological cofactors have been both a major focus of computational chemistry for decades and a growing need among computational biophysicists who seek to investigate the interaction of different types of ligands with biomolecules. Of particular interest in this regard are quantum mechanical (QM) calculations that are used to more accurately describe such small molecules, which can be of heterogeneous structures and chemistry, either in purely QM calculations or in hybrid QM/molecular mechanics (MM) simulations. QM programs are also used to develop MM force field parameters for small molecules to be used along with established force fields for biomolecules in classical simulations. With this growing need in mind, here we report a set of software tools developed and closely integrated within the broadly used molecular visualization/analysis program, VMD, that allow the user to construct, modify, and parametrize small molecules and prepare them for QM, hybrid QM/MM, or classical simulations. The tools also provide interactive analysis and visualization capabilities in an easy-to-use and integrated environment. In this paper, we briefly report on these tools and their major features and capabilities, along with examples of how they can facilitate molecular research in computational biophysics that might be otherwise prohibitively complex.",2,Modeling and simulation of small molecules such as drugs and biological cofactors have been a major focus of computational chemistry for decades.
iGRLDTI: an improved graph representation learning method for predicting drug-target interactions over heterogeneous biological information network.,37505483,https://pubmed.ncbi.nlm.nih.gov/37505483/,https://doi.org/10.1093/bioinformatics/btad451,[],"The task of predicting drug-target interactions (DTIs) plays a significant role in facilitating the development of novel drug discovery. Compared with laboratory-based approaches, computational methods proposed for DTI prediction are preferred due to their high-efficiency and low-cost advantages. Recently, much attention has been attracted to apply different graph neural network (GNN) models to discover underlying DTIs from heterogeneous biological information network (HBIN). Although GNN-based prediction methods achieve better performance, they are prone to encounter the over-smoothing simulation when learning the latent representations of drugs and targets with their rich neighborhood information in HBIN, and thereby reduce the discriminative ability in DTI prediction.",12,The task of predicting drug-target interactions (DTIs) plays a significant role in facilitating the development of novel drug discovery.
Sub-Cluster Identification through Semi-Supervised Optimization of Rare-Cell Silhouettes (SCISSORS) in single-cell RNA-sequencing.,37498558,https://pubmed.ncbi.nlm.nih.gov/37498558/,https://doi.org/10.1093/bioinformatics/btad449,[],"Single-cell RNA-sequencing (scRNA-seq) has enabled the molecular profiling of thousands to millions of cells simultaneously in biologically heterogenous samples. Currently, the common practice in scRNA-seq is to determine cell type labels through unsupervised clustering and the examination of cluster-specific genes. However, even small differences in analysis and parameter choosing can greatly alter clustering results and thus impose great influence on which cell types are identified. Existing methods largely focus on determining the optimal number of robust clusters, which can be problematic for identifying cells of extremely low abundance due to their subtle contributions toward overall patterns of gene expression.",4,Single-cell RNA-sequencing (scRNA-seq) has enabled the molecular profiling of thousands to millions of cells simultaneously in biologically heterogenous samples.
Testing phylogenetic signal with categorical traits and tree uncertainty.,37490431,https://pubmed.ncbi.nlm.nih.gov/37490431/,https://doi.org/10.1093/bioinformatics/btad433,[],"The phylogenetic signal, frequently used to identify signatures of adaptive evolution or important associations between genes and phenotypes, measures the tendency for recently diverged species to resemble each other more than distantly related species. An example of such a measure is the δ statistic, which uses Shannon entropy to measure the degree of phylogenetic signal between a categorical trait and a phylogeny. In this study, we refined this statistic to account for tree uncertainty, resulting in more accurate assessments of phylogenetic associations. In addition, we provided a more accessible and computationally efficient implementation of the δ statistic that will facilitate its use by the evolutionary community.",1,The phylogenetic signal is frequently used to identify signatures of adaptive evolution.. It measures the tendency for recently diverged species to resemble each other more than distantly related species.
Mechanism of Ligand Discrimination by the ,37486304,https://pubmed.ncbi.nlm.nih.gov/37486304/,https://doi.org/10.1021/acs.jcim.3c00835,[],"Riboswitches are conserved functional domains in mRNA that almost exclusively exist in bacteria. They regulate the biosynthesis and transport of amino acids and essential metabolites such as coenzymes, nucleobases, and their derivatives by specifically binding small molecules. Due to their ability to precisely discriminate between different cognate molecules as well as their common existence in bacteria, riboswitches have become potential antibacterial drug targets that could deliver urgently needed antibiotics with novel mechanisms of action. In this work, we report the recognition mechanisms of four oxidization products (XAN, AZA, UAC, and HPA) generated during purine degradation by an RNA motif termed the ",1,Riboswitches are conserved functional domains in mRNA that almost exclusively exist in bacteria.
Ten quick tips for editing Wikidata.,37471307,https://pubmed.ncbi.nlm.nih.gov/37471307/,https://doi.org/10.1371/journal.pcbi.1011235,[],,2,
Spatial-MGCN: a novel multi-view graph convolutional network for identifying spatial domains with attention mechanism.,37466210,https://pubmed.ncbi.nlm.nih.gov/37466210/,https://doi.org/10.1093/bib/bbad262,"['graph convolutional network', 'multi-view GCN encoder', 'spatial domain identification', 'spatial transcriptomics']","Recent advances in spatial transcriptomics technologies have enabled gene expression profiles while preserving spatial context. Accurately identifying spatial domains is crucial for downstream analysis and it requires the effective integration of gene expression profiles and spatial information. While increasingly computational methods have been developed for spatial domain detection, most of them cannot adaptively learn the complex relationship between gene expression and spatial information, leading to sub-optimal performance.",1,Recent advances in spatial transcriptomics technologies have enabled gene expression profiles while preserving spatial context.
Predicting metabolite-disease associations based on auto-encoder and non-negative matrix factorization.,37466194,https://pubmed.ncbi.nlm.nih.gov/37466194/,https://doi.org/10.1093/bib/bbad259,"['auto-encoder', 'diseases', 'feature splicing', 'metabolites', 'multi-layer perceptron', 'non-negative matrix factorization']","Metabolism refers to a series of orderly chemical reactions used to maintain life activities in organisms. In healthy individuals, metabolism remains within a normal range. However, specific diseases can lead to abnormalities in the levels of certain metabolites, causing them to either increase or decrease. Detecting these deviations in metabolite levels can aid in diagnosing a disease. Traditional biological experiments often rely on a lot of manpower to do repeated experiments, which is time consuming and labor intensive. To address this issue, we develop a deep learning model based on the auto-encoder and non-negative matrix factorization named as MDA-AENMF to predict the potential associations between metabolites and diseases. We integrate a variety of similarity networks and then acquire the characteristics of both metabolites and diseases through three specific modules. First, we get the disease characteristics from the five-layer auto-encoder module. Later, in the non-negative matrix factorization module, we extract both the metabolite and disease characteristics. Furthermore, the graph attention auto-encoder module helps us obtain metabolite characteristics. After obtaining the features from three modules, these characteristics are merged into a single, comprehensive feature vector for each metabolite-disease pair. Finally, we send the corresponding feature vector and label to the multi-layer perceptron for training. The experiment demonstrates our area under the receiver operating characteristic curve of 0.975 and area under the precision-recall curve of 0.973 in 5-fold cross-validation, which are superior to those of existing state-of-the-art predictive methods. Through case studies, most of the new associations obtained by MDA-AENMF have been verified, further highlighting the reliability of MDA-AENMF in predicting the potential relationships between metabolites and diseases.",35,"Metabolism refers to a series of orderly chemical reactions used to maintain life activities in organisms.. In healthy individuals, metabolism remains within a normal range."
Neural network-based prognostic predictive tool for gastric cardiac cancer: the worldwide retrospective study.,37464415,https://pubmed.ncbi.nlm.nih.gov/37464415/,https://doi.org/10.1186/s13040-023-00335-z,"['Deep learning', 'Gastric cardiac cancer', 'Neural network', 'Survival prediction']",The incidence of gastric cardiac cancer (GCC) has obviously increased recently with poor prognosis. It's necessary to compare GCC prognosis with other gastric sites carcinoma and set up an effective prognostic model based on a neural network to predict the survival of GCC patients.,1,The incidence of gastric cardiac cancer (GCC) has obviously increased recently with poor prognosis.
A multi-scale clutch model for adhesion complex mechanics.,37450544,https://pubmed.ncbi.nlm.nih.gov/37450544/,https://doi.org/10.1371/journal.pcbi.1011250,[],"Cell-matrix adhesion is a central mechanical function to a large number of phenomena in physiology and disease, including morphogenesis, wound healing, and tumor cell invasion. Today, how single cells respond to different extracellular cues has been comprehensively studied. However, how the mechanical behavior of the main individual molecules that form an adhesion complex cooperatively responds to force within the adhesion complex is still poorly understood. This is a key aspect of cell adhesion because how these cell adhesion molecules respond to force determines not only cell adhesion behavior but, ultimately, cell function. To answer this question, we develop a multi-scale computational model for adhesion complexes mechanics. We extend the classical clutch hypothesis to model individual adhesion chains made of a contractile actin network, a talin rod, and an integrin molecule that binds at individual adhesion sites on the extracellular matrix. We explore several scenarios of integrins dynamics and analyze the effects of diverse extracellular matrices on the behavior of the adhesion molecules and on the whole adhesion complex. Our results describe how every single component of the adhesion chain mechanically responds to the contractile actomyosin force and show how they control the traction forces exerted by the cell on the extracellular space. Importantly, our computational results agree with previous experimental data at the molecular and cellular levels. Our multi-scale clutch model presents a step forward not only to further understand adhesion complexes mechanics but also to impact, e.g., the engineering of biomimetic materials, tissue repairment, or strategies to arrest tumor progression.",1,"Cell-matrix adhesion is a central mechanical function to a large number of phenomena in physiology and disease, including morphogenesis, wound healing, and tumor cell invasion."
SBOannotator: a Python tool for the automated assignment of systems biology ontology terms.,37449910,https://pubmed.ncbi.nlm.nih.gov/37449910/,https://doi.org/10.1093/bioinformatics/btad437,[],"The number and size of computational models in biology have drastically increased over the past years and continue to grow. Modeled networks are becoming more complex, and reconstructing them from the beginning in an exchangeable and reproducible manner is challenging. Using precisely defined ontologies enables the encoding of field-specific knowledge and the association of disparate data types. In computational modeling, the medium for representing domain knowledge is the set of orthogonal structured controlled vocabularies named Systems Biology Ontology (SBO). The SBO terms enable modelers to explicitly define and describe model entities, including their roles and characteristics.",3,The number and size of computational models in biology have drastically increased over the past years and continue to grow.
Deep imputation of missing values in time series health data: A review with benchmarking.,37429511,https://pubmed.ncbi.nlm.nih.gov/37429511/,https://doi.org/10.1016/j.jbi.2023.104440,"['Cross-sectional imputation', 'Deep neural network', 'Electronic health records', 'Longitudinal imputation', 'Missing value imputation', 'Multivariate data', 'Sensor data', 'Time series']","The imputation of missing values in multivariate time series (MTS) data is critical in ensuring data quality and producing reliable data-driven predictive models. Apart from many statistical approaches, a few recent studies have proposed state-of-the-art deep learning methods to impute missing values in MTS data. However, the evaluation of these deep methods is limited to one or two data sets, low missing rates, and completely random missing value types. This survey performs six data-centric experiments to benchmark state-of-the-art deep imputation methods on five time series health data sets. Our extensive analysis reveals that no single imputation method outperforms the others on all five data sets. The imputation performance depends on data types, individual variable statistics, missing value rates, and types. Deep learning methods that jointly perform cross-sectional (across variables) and longitudinal (across time) imputations of missing values in time series data yield statistically better data quality than traditional imputation methods. Although computationally expensive, deep learning methods are practical given the current availability of high-performance computing resources, especially when data quality and sample size are of paramount importance in healthcare informatics. Our findings highlight the importance of data-centric selection of imputation methods to optimize data-driven predictive models.",1,"No single imputation method outperforms the others on all five data sets.. The imputation performance depends on data types, individual variable statistics, missing value rates, and types."
Leveraging epigenomes and three-dimensional genome organization for interpreting regulatory variation.,37428809,https://pubmed.ncbi.nlm.nih.gov/37428809/,https://doi.org/10.1371/journal.pcbi.1011286,[],"Understanding the impact of regulatory variants on complex phenotypes is a significant challenge because the genes and pathways that are targeted by such variants and the cell type context in which regulatory variants operate are typically unknown. Cell-type-specific long-range regulatory interactions that occur between a distal regulatory sequence and a gene offer a powerful framework for examining the impact of regulatory variants on complex phenotypes. However, high-resolution maps of such long-range interactions are available only for a handful of cell types. Furthermore, identifying specific gene subnetworks or pathways that are targeted by a set of variants is a significant challenge. We have developed L-HiC-Reg, a Random Forests regression method to predict high-resolution contact counts in new cell types, and a network-based framework to identify candidate cell-type-specific gene networks targeted by a set of variants from a genome-wide association study (GWAS). We applied our approach to predict interactions in 55 Roadmap Epigenomics Mapping Consortium cell types, which we used to interpret regulatory single nucleotide polymorphisms (SNPs) in the NHGRI-EBI GWAS catalogue. Using our approach, we performed an in-depth characterization of fifteen different phenotypes including schizophrenia, coronary artery disease (CAD) and Crohn's disease. We found differentially wired subnetworks consisting of known as well as novel gene targets of regulatory SNPs. Taken together, our compendium of interactions and the associated network-based analysis pipeline leverages long-range regulatory interactions to examine the context-specific impact of regulatory variation in complex phenotypes.",1, understanding the impact of regulatory variants on complex phenotypes is a significant challenge.
Sequential mutations in exponentially growing populations.,37428805,https://pubmed.ncbi.nlm.nih.gov/37428805/,https://doi.org/10.1371/journal.pcbi.1011289,[],"Stochastic models of sequential mutation acquisition are widely used to quantify cancer and bacterial evolution. Across manifold scenarios, recurrent research questions are: how many cells are there with n alterations, and how long will it take for these cells to appear. For exponentially growing populations, these questions have been tackled only in special cases so far. Here, within a multitype branching process framework, we consider a general mutational path where mutations may be advantageous, neutral or deleterious. In the biologically relevant limiting regimes of large times and small mutation rates, we derive probability distributions for the number, and arrival time, of cells with n mutations. Surprisingly, the two quantities respectively follow Mittag-Leffler and logistic distributions regardless of n or the mutations' selective effects. Our results provide a rapid method to assess how altering the fundamental division, death, and mutation rates impacts the arrival time, and number, of mutant cells. We highlight consequences for mutation rate inference in fluctuation assays.",1,Stochastic models of sequential mutation acquisition are widely used to quantify cancer and bacterial evolution.
MOKPE: drug-target interaction prediction via manifold optimization based kernel preserving embedding.,37407927,https://pubmed.ncbi.nlm.nih.gov/37407927/,https://doi.org/10.1186/s12859-023-05401-1,"['Drug repurposing', 'Drug–target interaction prediction', 'Kernel methods', 'Machine learning', 'Manifold optimization']","In many applications of bioinformatics, data stem from distinct heterogeneous sources. One of the well-known examples is the identification of drug-target interactions (DTIs), which is of significant importance in drug discovery. In this paper, we propose a novel framework, manifold optimization based kernel preserving embedding (MOKPE), to efficiently solve the problem of modeling heterogeneous data. Our model projects heterogeneous drug and target data into a unified embedding space by preserving drug-target interactions and drug-drug, target-target similarities simultaneously.",1,"In many applications of bioinformatics, data stem from distinct heterogeneous sources."
PPAD: a deep learning architecture to predict progression of Alzheimer's disease.,37387135,https://pubmed.ncbi.nlm.nih.gov/37387135/,https://doi.org/10.1093/bioinformatics/btad249,[],"Alzheimer's disease (AD) is a neurodegenerative disease that affects millions of people worldwide. Mild cognitive impairment (MCI) is an intermediary stage between cognitively normal state and AD. Not all people who have MCI convert to AD. The diagnosis of AD is made after significant symptoms of dementia such as short-term memory loss are already present. Since AD is currently an irreversible disease, diagnosis at the onset of the disease brings a huge burden on patients, their caregivers, and the healthcare sector. Thus, there is a crucial need to develop methods for the early prediction AD for patients who have MCI. Recurrent neural networks (RNN) have been successfully used to handle electronic health records (EHR) for predicting conversion from MCI to AD. However, RNN ignores irregular time intervals between successive events which occurs common in electronic health record data. In this study, we propose two deep learning architectures based on RNN, namely Predicting Progression of Alzheimer's Disease (PPAD) and PPAD-Autoencoder. PPAD and PPAD-Autoencoder are designed for early predicting conversion from MCI to AD at the next visit and multiple visits ahead for patients, respectively. To minimize the effect of the irregular time intervals between visits, we propose using age in each visit as an indicator of time change between successive visits.",1,Alzheimer's disease (AD) is a neurodegenerative disease that affects millions of people worldwide.
Indigenous Oral and Gut Phages Defeat the Deadly NDM-1 Superbug.,37377794,https://pubmed.ncbi.nlm.nih.gov/37377794/,https://doi.org/10.1177/11779322231182767,"['Lactococcus', 'bacteriophage', 'oral biology', 'oral microflora', 'protein']","Antibiotics treat various diseases by targeting microorganisms by killing them or reducing their multiplication rate. New Delhi Metallo-beta-lactamase-1 (NDM-1) is produced by bacteria possessing the resistance gene blaNDM-1, the enzyme that makes bacteria resistant to beta-lactams. Bacteriophages, especially Lactococcus, have shown their ability to break down lactams. Hence, the current study computationally evaluated the binding potential of Lactococcus bacteriophages with NDM using Molecular docking and dynamics.",1,New Delhi Metallo-beta-lactamase-1 is produced by bacteria possessing the resistance gene blaNDM-1.
In Silico Investigation of a Chimeric IL24-LK6 Fusion Protein as a Potent Candidate Against Breast Cancer.,37377793,https://pubmed.ncbi.nlm.nih.gov/37377793/,https://doi.org/10.1177/11779322231182560,"['Interleukin 24', 'LK-6', 'fusion protein', 'molecular docking']","Targeted delivery of therapeutic anticancer chimeric molecules enhances the efficacy of drug by improving cellular uptake and circulation time. Engineering the molecules to facilitate the specific interaction between chimeric protein and its receptor is critical to elucidate biological mechanism as well as accuracy in modeling of complexes. A theoretically designed novel protein-protein interfaces can serve as a bottom-up method for comprehensive understanding of interacting protein residues. This study was aimed for in silico analyses of a chimeric fusion protein against breast cancer. The amino acid sequences of the interleukin 24 (IL-24) and LK-6 peptide were used to design the chimeric fusion protein via a rigid linker. The secondary and tertiary structures along with physicochemical properties by ProtParam and solubility were predicted using online software. The validation and quality of the fusion protein was confirmed by Rampage and ERRAT2. The newly designed fusion construct has a total length of 179 amino acids. The top-ranked structure from alpha fold2 showed 18.1 KD molecular weight by ProtParam, quality factor of 94.152 by ERRAT, and a valid structure by a Ramachandran plot with 88.5% residues in the favored region. Finally, the docking and simulation studies were performed using HADDOCK and Desmond module of Schrodinger. The quality, validity, interaction analysis, and stability of the fusion protein depict a functional molecule. The fusion gene IL24-LK6 after cloning and expression in a suitable prokaryotic cell might be a useful candidate for developing a novel anticancer therapy.",1,A theoretically designed novel protein-protein interfaces can serve as a bottom-up method for comprehensive understanding of interacting protein residues.
Deep learning approaches to landmark detection in tsetse wing images.,37363914,https://pubmed.ncbi.nlm.nih.gov/37363914/,https://doi.org/10.1371/journal.pcbi.1011194,[],"Morphometric analysis of wings has been suggested for identifying and controlling isolated populations of tsetse (Glossina spp), vectors of human and animal trypanosomiasis in Africa. Single-wing images were captured from an extensive data set of field-collected tsetse wings of species Glossina pallidipes and G. m. morsitans. Morphometric analysis required locating 11 anatomical landmarks on each wing. The manual location of landmarks is time-consuming, prone to error, and infeasible for large data sets. We developed a two-tier method using deep learning architectures to classify images and make accurate landmark predictions. The first tier used a classification convolutional neural network to remove most wings that were missing landmarks. The second tier provided landmark coordinates for the remaining wings. We compared direct coordinate regression using a convolutional neural network and segmentation using a fully convolutional network for the second tier. For the resulting landmark predictions, we evaluate shape bias using Procrustes analysis. We pay particular attention to consistent labelling to improve model performance. For an image size of 1024 × 1280, data augmentation reduced the mean pixel distance error from 8.3 (95% confidence interval [4.4,10.3]) to 5.34 (95% confidence interval [3.0,7.0]) for the regression model. For the segmentation model, data augmentation did not alter the mean pixel distance error of 3.43 (95% confidence interval [1.9,4.4]). Segmentation had a higher computational complexity and some large outliers. Both models showed minimal shape bias. We deployed the regression model on the complete unannotated data consisting of 14,354 pairs of wing images since this model had a lower computational cost and more stable predictions than the segmentation model. The resulting landmark data set was provided for future morphometric analysis. The methods we have developed could provide a starting point to studying the wings of other insect species. All the code used in this study has been written in Python and open sourced.",1,Single-wing images were captured from an extensive data set of field-collected tsetse wings of species Glossina pallidipes and G. m. morsitans.
"MolBook UNIPI─Create, Manage, Analyze, and Share Your Chemical Data for Free.",37358197,https://pubmed.ncbi.nlm.nih.gov/37358197/,https://doi.org/10.1021/acs.jcim.3c00278,[],"Here, we present MolBook UNIPI, freely available and user-friendly software specifically designed for medicinal chemists as a powerful tool for the easy management of virtual libraries of chemical compounds. With MolBook UNIPI, it is possible to create, store, handle, and share molecular databases in a very simple and intuitive way. The software allows users to rapidly generate libraries of bioactive ligands, building blocks, or commercial compounds by either manually creating single molecules or automatically importing compounds from public databases and pre-existing libraries. MolBook UNIPI databases can be enriched with all kinds of data and can be filtered based on molecular structures or properties, allowing the desired molecules, along with their structures and features, to be easily accessible in just a few clicks. Moreover, new molecular properties and potential toxicological effects of compounds can be rapidly and reliably predicted. Notably, all of these functions can be easily mastered even by inexperienced users, with no prior cheminformatics knowledge or programming skills, which makes MolBook UNIPI an invaluable tool for medicinal chemists. MolBook UNIPI can be downloaded free of charge from the project web page https://molbook.farm.unipi.it/.",4,MolBook UNIPI is free software designed for medicinal chemists.
Community detection in empirical kinase networks identifies new potential members of signalling pathways.,37352361,https://pubmed.ncbi.nlm.nih.gov/37352361/,https://doi.org/10.1371/journal.pcbi.1010459,[],"Phosphoproteomics allows one to measure the activity of kinases that drive the fluxes of signal transduction pathways involved in biological processes such as immune function, senescence and cell growth. However, deriving knowledge of signalling network circuitry from these data is challenging due to a scarcity of phosphorylation sites that define kinase-kinase relationships. To address this issue, we previously identified around 6,000 phosphorylation sites as markers of kinase-kinase relationships (that may be conceptualised as network edges), from which empirical cell-model-specific weighted kinase networks may be reconstructed. Here, we assess whether the application of community detection algorithms to such networks can identify new components linked to canonical signalling pathways. Phosphoproteomics data from acute myeloid leukaemia (AML) cells treated separately with PI3K, AKT, MEK and ERK inhibitors were used to reconstruct individual kinase networks. We used modularity maximisation to detect communities in each network, and selected the community containing the main target of the inhibitor used to treat cells. These analyses returned communities that contained known canonical signalling components. Interestingly, in addition to canonical PI3K/AKT/mTOR members, the community assignments returned TTK (also known as MPS1) as a likely component of PI3K/AKT/mTOR signalling. We drew similar insights from an external phosphoproteomics dataset from breast cancer cells treated with rapamycin and oestrogen. We confirmed this observation with wet-lab laboratory experiments showing that TTK phosphorylation was decreased in AML cells treated with AKT and MTOR inhibitors. This study illustrates the application of community detection algorithms to the analysis of empirical kinase networks to uncover new members linked to canonical signalling pathways.",1,"Phosphoproteomics allows one to measure the activity of kinases that drive the fluxes of signal transduction pathways involved in biological processes such as immune function, senescence and"
Discovery of a Novel DCAF1 Ligand Using a Drug-Target Interaction Prediction Model: Generalizing Machine Learning to New Drug Targets.,37350740,https://pubmed.ncbi.nlm.nih.gov/37350740/,https://doi.org/10.1021/acs.jcim.3c00082,[],DCAF1 functions as a substrate recruitment subunit for the RING-type CRL4,2,DCAF1 functions as a substrate recruitment subunit for the RING-type CRL4.
Current progress in artificial intelligence-assisted medical image analysis for chronic kidney disease: A literature review.,37333860,https://pubmed.ncbi.nlm.nih.gov/37333860/,https://doi.org/10.1016/j.csbj.2023.05.029,"['Artificial intelligence', 'Chronic kidney disease', 'Deep learning', 'Radiomics']","Chronic kidney disease (CKD) causes irreversible damage to kidney structure and function. Arising from various etiologies, risk factors for CKD include hypertension and diabetes. With a progressively increasing global prevalence, CKD is an important public health problem worldwide. Medical imaging has become an important diagnostic tool for CKD through the non-invasive identification of macroscopic renal structural abnormalities. Artificial intelligence (AI)-assisted medical imaging techniques aid clinicians in the analysis of characteristics that cannot be easily discriminated by the naked eye, providing valuable information for the identification and management of CKD. Recent studies have demonstrated the effectiveness of AI-assisted medical image analysis as a clinical support tool using radiomics- and deep learning-based AI algorithms for improving the early detection, pathological assessment, and prognostic evaluation of various forms of CKD, including autosomal dominant polycystic kidney disease. Herein, we provide an overview of the potential roles of AI-assisted medical image analysis for the diagnosis and management of CKD.",1,Artificial intelligence (AI)-assisted medical imaging techniques aid clinicians in the analysis of characteristics that cannot be easily discriminated by the naked eye.
What remains from living cells in bacterial lysate-based cell-free systems.,37333859,https://pubmed.ncbi.nlm.nih.gov/37333859/,https://doi.org/10.1016/j.csbj.2023.05.025,"['Adaptation', 'Cell-free', 'E. coli', 'Homeostasis', 'Microfluidics', 'Prototyping', 'Spatial organization']","Because they mimic cells while offering an accessible and controllable environment, lysate-based cell-free systems (CFS) have emerged as valuable biotechnology tools for synthetic biology. Historically used to uncover fundamental mechanisms of life, CFS are nowadays used for a multitude of purposes, including protein production and prototyping of synthetic circuits. Despite the conservation of fundamental functions in CFS like transcription and translation, RNAs and certain membrane-embedded or membrane-bound proteins of the host cell are lost when preparing the lysate. As a result, CFS largely lack some essential properties of living cells, such as the ability to adapt to changing conditions, to maintain homeostasis and spatial organization. Regardless of the application, shedding light on the black-box of the bacterial lysate is necessary to fully exploit the potential of CFS. Most measurements of the activity of synthetic circuits in CFS and ",1,Lysate-based cell-free systems (CFS) have emerged as valuable biotechnology tools for synthetic biology.
Unique features of the TCR repertoire of reactivated memory T cells in the experimental mouse tumor model.,37333858,https://pubmed.ncbi.nlm.nih.gov/37333858/,https://doi.org/10.1016/j.csbj.2023.05.028,"['Adoptive cell therapy', 'Antigen-specific clonotypes', 'Bioinformatics', 'Memory cells', 'NGS sequencing', 'T cell receptor', 'TCR chain centricity', 'TCR physicochemical features', 'TCR repertoire']","T cell engineering with T cell receptors (TCR) specific to tumor antigens has become a breakthrough towards personalized cancer adoptive cell immunotherapy. However, the search for therapeutic TCRs is often challenging, and effective strategies are strongly required for the identification and enrichment of tumor-specific T cells that express TCRs with superior functional characteristics. Using an experimental mouse tumor model, we studied sequential changes in TCR repertoire features of T cells involved in the primary and secondary immune responses to allogeneic tumor antigens. In-depth bioinformatics analysis of TCR repertoires showed differences in reactivated memory T cells compared to primarily activated effectors. After cognate antigen re-encounter, memory cells were enriched with clonotypes that express α-chain TCR with high potential cross-reactivity and enhanced strength of interaction with both MHC and docked peptides. Our findings suggest that functionally true memory T cells could be a better source of therapeutic TCRs for adoptive cell therapy. No marked changes were observed in the physicochemical characteristics of TCRβ in reactivated memory clonotypes, indicative of the dominant role of TCRα in the secondary allogeneic immune response. The results of this study could further contribute to the development of TCR-modified T cell products based on the phenomenon of TCR chain centricity.",1,T cell engineering with T cell receptors (TCR) specific to tumor antigens has become a breakthrough towards personalized cancer adoptive cell immunotherapy.
PLANET: A Multi-objective Graph Neural Network Model for Protein-Ligand Binding Affinity Prediction.,37319418,https://pubmed.ncbi.nlm.nih.gov/37319418/,https://doi.org/10.1021/acs.jcim.3c00253,[],"Predicting protein-ligand binding affinity is a central issue in drug design. Various deep learning models have been published in recent years, where many of them rely on 3D protein-ligand complex structures as input and tend to focus on the single task of reproducing binding affinity. In this study, we have developed a graph neural network model called PLANET (Protein-Ligand Affinity prediction NETwork). This model takes the graph-represented 3D structure of the binding pocket on the target protein and the 2D chemical structure of the ligand molecule as input. It was trained through a multi-objective process with three related tasks, including deriving the protein-ligand binding affinity, protein-ligand contact map, and ligand distance matrix. Besides the protein-ligand complexes with known binding affinity data retrieved from the PDBbind database, a large number of non-binder decoys were also added to the training data for deriving the final model of PLANET. When tested on the CASF-2016 benchmark, PLANET exhibited a scoring power comparable to the best result yielded by other deep learning models as well as a reasonable ranking power and docking power. In virtual screening trials conducted on the DUD-E benchmark, PLANET's performance was notably better than several deep learning and machine learning models. As on the LIT-PCBA benchmark, PLANET achieved comparable accuracy as the conventional docking program Glide, but it only spent less than 1% of Glide's computation time to finish the same job because PLANET did not need exhaustive conformational sampling. Considering the decent accuracy and efficiency of PLANET in binding affinity prediction, it may become a useful tool for conducting large-scale virtual screening.",7,Predicting protein-ligand binding affinity is a central issue in drug design.
Drug Design in the Exascale Era: A Perspective from Massively Parallel QM/MM Simulations.,37319347,https://pubmed.ncbi.nlm.nih.gov/37319347/,https://doi.org/10.1021/acs.jcim.3c00557,[],The initial phases of drug discovery - ,3,The initial phases of drug discovery -  the initial stages of drug discovery.
Impact of loss functions on the performance of a deep neural network designed to restore low-dose digital mammography.,37316093,https://pubmed.ncbi.nlm.nih.gov/37316093/,https://doi.org/10.1016/j.artmed.2023.102555,"['Convolutional neural networks', 'Deep learning', 'Digital mammography', 'Image restoration', 'Loss functions', 'Radiation dose reduction']","Digital mammography is currently the most common imaging tool for breast cancer screening. Although the benefits of using digital mammography for cancer screening outweigh the risks associated with the x-ray exposure, the radiation dose must be kept as low as possible while maintaining the diagnostic utility of the generated images, thus minimizing patient risks. Many studies investigated the feasibility of dose reduction by restoring low-dose images using deep neural networks. In these cases, choosing the appropriate training database and loss function is crucial and impacts the quality of the results. In this work, we used a standard residual network (ResNet) to restore low-dose digital mammography images and evaluated the performance of several loss functions. For training purposes, we extracted 256,000 image patches from a dataset of 400 images of retrospective clinical mammography exams, where dose reduction factors of 75% and 50% were simulated to generate low and standard-dose pairs. We validated the network in a real scenario by using a physical anthropomorphic breast phantom to acquire real low-dose and standard full-dose images in a commercially available mammography system, which were then processed through our trained model. We benchmarked our results against an analytical restoration model for low-dose digital mammography. Objective assessment was performed through the signal-to-noise ratio (SNR) and the mean normalized squared error (MNSE), decomposed into residual noise and bias. Statistical tests revealed that the use of the perceptual loss (PL4) resulted in statistically significant differences when compared to all other loss functions. Additionally, images restored using the PL4 achieved the closest residual noise to the standard dose. On the other hand, perceptual loss PL3, structural similarity index (SSIM) and one of the adversarial losses achieved the lowest bias for both dose reduction factors. The source code of our deep neural network is available at https://github.com/WANG-AXIS/LdDMDenoising.",2,Digital mammography is currently the most common imaging tool for breast cancer screening.
MedKPL: A heterogeneous knowledge enhanced prompt learning framework for transferable diagnosis.,37315832,https://pubmed.ncbi.nlm.nih.gov/37315832/,https://doi.org/10.1016/j.jbi.2023.104417,"['Knowledge Integration', 'Natural Language Processing', 'Prompt Learning', 'Text Classification']","Artificial Intelligence (AI) based diagnosis systems have emerged as powerful tools to reform traditional medical care. Each clinician now wants to have his own intelligent diagnostic partner to expand the range of services he can provide. However, the implementation of intelligent decision support systems based on clinical note has been hindered by the lack of extensibility of end-to-end AI diagnosis algorithms. When reading a clinical note, expert clinicians make inferences with relevant medical knowledge, which serve as prompts for making accurate diagnoses. Therefore, external medical knowledge is commonly employed as an augmentation for medical text classification tasks. Existing methods, however, cannot integrate knowledge from various knowledge sources as prompts nor can fully utilize explicit and implicit knowledge. To address these issues, we propose a Medical Knowledge-enhanced Prompt Learning (MedKPL) diagnostic framework for transferable clinical note classification. Firstly, to overcome the heterogeneity of knowledge sources, such as knowledge graphs or medical QA databases, MedKPL uniform the knowledge relevant to the disease into text sequences of fixed format. Then, MedKPL integrates medical knowledge into the prompt designed for context representation. Therefore, MedKPL can integrate knowledge into the models to enhance diagnostic performance and effectively transfer to new diseases by using relevant disease knowledge. The results of our experiments on two medical datasets demonstrate that our method yields superior medical text classification results and performs better in cross-departmental transfer tasks under few-shot or even zero-shot settings. These findings demonstrate that our MedKPL framework has the potential to improve the interpretability and transferability of current diagnostic systems.",1,Artificial Intelligence (AI) based diagnosis systems have emerged as powerful tools to reform traditional medical care.
"kboolnet: a toolkit for the verification, validation, and visualization of reaction-contingency (rxncon) models.",37308855,https://pubmed.ncbi.nlm.nih.gov/37308855/,https://doi.org/10.1186/s12859-023-05329-6,"['Boolean networks', 'Cell signaling', 'Computational modeling', 'Network biology', 'Rxncon']","Computational models of cell signaling networks are extremely useful tools for the exploration of underlying system behavior and prediction of response to various perturbations. By representing signaling cascades as executable Boolean networks, the previously developed rxncon (""reaction-contingency"") formalism and associated Python package enable accurate and scalable modeling of signal transduction even in large (thousands of components) biological systems. The models are split into reactions, which generate states, and contingencies, that impinge on reactions; this avoids the so-called ""combinatorial explosion"" of system size. Boolean description of the biological system compensates for the poor availability of kinetic parameters which are necessary for quantitative models. Unfortunately, few tools are available to support rxncon model development, especially for large, intricate systems.",1,"The rxncon (""reaction-contingency"") formalism and associated Python package enable accurate and scalable modeling of signal transduction."
Multi-ethnic Imputation System (MI-System): A genotype imputation server for high-dimensional data.,37308034,https://pubmed.ncbi.nlm.nih.gov/37308034/,https://doi.org/10.1016/j.jbi.2023.104423,"['Beagle5.1', 'Genotype imputation', 'IMPUTE2', 'IMPUTE5', 'Taiwan biobank', 'Web-server']","Genotype imputation is a commonly used technique that infers un-typed variants into a study's genotype data, allowing better identification of causal variants in disease studies. However, due to overrepresentation of Caucasian studies, there's a lack of understanding of genetic basis of health-outcomes in other ethnic populations. Therefore, facilitating imputation of missing key-predictor-variants that can potentially improve a risk health-outcome prediction model, specifically for Asian ancestry, is of utmost relevance.",1,Genotype imputation is a commonly used technique that infers un-typed variants into a study's genotype data.
Detecting patterns of accessory genome coevolution in Staphylococcus aureus using data from thousands of genomes.,37296404,https://pubmed.ncbi.nlm.nih.gov/37296404/,https://doi.org/10.1186/s12859-023-05363-4,"['Genetic interaction', 'Genomics', 'Horizontal gene transfer', 'Microbial genomics', 'Software', 'Staphylococcus aureus']","Bacterial genomes exhibit widespread horizontal gene transfer, resulting in highly variable genome content that complicates the inference of genetic interactions. In this study, we develop a method for detecting coevolving genes from large datasets of bacterial genomes based on pairwise comparisons of closely related individuals, analogous to a pedigree study in eukaryotic populations. We apply our method to pairs of genes from the Staphylococcus aureus accessory genome of over 75,000 annotated gene families using a database of over 40,000 whole genomes. We find many pairs of genes that appear to be gained or lost in a coordinated manner, as well as pairs where the gain of one gene is associated with the loss of the other. These pairs form networks of rapidly coevolving genes, primarily consisting of genes involved in virulence, mechanisms of horizontal gene transfer, and antibiotic resistance, particularly the SCCmec complex. While we focus on gene gain and loss, our method can also detect genes that tend to acquire substitutions in tandem, or genotype-phenotype or phenotype-phenotype coevolution. Finally, we present the R package DeCoTUR that allows for the computation of our method.",3,"Bacterial genomes exhibit widespread horizontal gene transfer, resulting in highly variable genome content.. We find many pairs of genes that appear to be gained or lost in a coordinated manner."
Large-Scale Modeling of Sparse Protein Kinase Activity Data.,37294674,https://pubmed.ncbi.nlm.nih.gov/37294674/,https://doi.org/10.1021/acs.jcim.3c00132,[],"Protein kinases are a protein family that plays an important role in several complex diseases such as cancer and cardiovascular and immunological diseases. Protein kinases have conserved ATP binding sites, which when targeted can lead to similar activities of inhibitors against different kinases. This can be exploited to create multitarget drugs. On the other hand, selectivity (lack of similar activities) is desirable in order to avoid toxicity issues. There is a vast amount of protein kinase activity data in the public domain, which can be used in many different ways. Multitask machine learning models are expected to excel for these kinds of data sets because they can learn from implicit correlations between tasks (in this case activities against a variety of kinases). However, multitask modeling of sparse data poses two major challenges: (i) creating a balanced train-test split without data leakage and (ii) handling missing data. In this work, we construct a protein kinase benchmark set composed of two balanced splits without data leakage, using random and dissimilarity-driven cluster-based mechanisms, respectively. This data set can be used for benchmarking and developing protein kinase activity prediction models. Overall, the performance on the dissimilarity-driven cluster-based split is lower than on random split-based sets for all models, indicating poor generalizability of models. Nevertheless, we show that multitask deep learning models, on this very sparse data set, outperform single-task deep learning and tree-based models. Finally, we demonstrate that data imputation does not improve the performance of (multitask) models on this benchmark set.",2,Protein kinases are a protein family that plays an important role in several complex diseases such as cancer and cardiovascular and immunological diseases.
Prediction of Multiple Types of RNA Modifications via Biological Language Model.,37289599,https://pubmed.ncbi.nlm.nih.gov/37289599/,https://doi.org/10.1109/TCBB.2023.3283985,[],"It has been demonstrated that RNA modifications play essential roles in multiple biological processes. Accurate identification of RNA modifications in the transcriptome is critical for providing insights into the biological functions and mechanisms. Many tools have been developed for predicting RNA modifications at single-base resolution, which employ conventional feature engineering methods that focus on feature design and feature selection processes that require extensive biological expertise and may introduce redundant information. With the rapid development of artificial intelligence technologies, end-to-end methods are favorably received by researchers. Nevertheless, each well-trained model is only suitable for a specific RNA methylation modification type for nearly all of these approaches. In this study, we present MRM-BERT by feeding task-specific sequences into the powerful BERT (Bidirectional Encoder Representations from Transformers) model and implementing fine-tuning, which exhibits competitive performance to the state-of-the-art methods. MRM-BERT avoids repeated de novo training of the model and can predict multiple RNA modifications such as pseudouridine, m6A, m5C, and m1A in Mus musculus, Arabidopsis thaliana, and Saccharomyces cerevisiae. In addition, we analyse the attention heads to provide high attention regions for the prediction, and conduct saturated in silico mutagenesis of the input sequences to discover potential changes of RNA modifications, which can better assist researchers in their follow-up research.",1,"MRM-BERT can predict multiple RNA modifications such as pseudouridine, m6A, m5C, and m1A in Mus musculus, Arabidopsis th"
Multiscale model of the different modes of cancer cell invasion.,37289551,https://pubmed.ncbi.nlm.nih.gov/37289551/,https://doi.org/10.1093/bioinformatics/btad374,[],"Mathematical models of biological processes altered in cancer are built using the knowledge of complex networks of signaling pathways, detailing the molecular regulations inside different cell types, such as tumor cells, immune and other stromal cells. If these models mainly focus on intracellular information, they often omit a description of the spatial organization among cells and their interactions, and with the tumoral microenvironment.",2, Mathematical models of biological processes altered in cancer are built using the knowledge of complex networks of signaling pathways.
Hebbian learning with elasticity explains how the spontaneous motor tempo affects music performance synchronization.,37285380,https://pubmed.ncbi.nlm.nih.gov/37285380/,https://doi.org/10.1371/journal.pcbi.1011154,[],"A musician's spontaneous rate of movement, called spontaneous motor tempo (SMT), can be measured while spontaneously playing a simple melody. Data shows that the SMT influences the musician's tempo and synchronization. In this study we present a model that captures these phenomena. We review the results from three previously-published studies: solo musical performance with a pacing metronome tempo that is different from the SMT, solo musical performance without a metronome at a tempo that is faster or slower than the SMT, and duet musical performance between musicians with matching or mismatching SMTs. These studies showed, respectively, that the asynchrony between the pacing metronome and the musician's tempo grew as a function of the difference between the metronome tempo and the musician's SMT, musicians drifted away from the initial tempo toward the SMT, and the absolute asynchronies were smaller if musicians had matching SMTs. We hypothesize that the SMT constantly acts as a pulling force affecting musical actions at a tempo different from a musician's SMT. To test our hypothesis, we developed a model consisting of a non-linear oscillator with Hebbian tempo learning and a pulling force to the model's spontaneous frequency. While the model's spontaneous frequency emulates the SMT, elastic Hebbian learning allows for frequency learning to match a stimulus' frequency. To test our hypothesis, we first fit model parameters to match the data in the first of the three studies and asked whether this same model would explain the data the remaining two studies without further tuning. Results showed that the model's dynamics allowed it to explain all three experiments with the same set of parameters. Our theory offers a dynamical-systems explanation of how an individual's SMT affects synchronization in realistic music performance settings, and the model also enables predictions about performance settings not yet tested.",2,"A musician's spontaneous rate of movement, called spontaneous motor tempo (SMT), can be measured while spontaneously playing a simple melody."
NoVaTeST: identifying genes with location-dependent noise variance in spatial transcriptomics data.,37285319,https://pubmed.ncbi.nlm.nih.gov/37285319/,https://doi.org/10.1093/bioinformatics/btad372,[],Spatial transcriptomics (ST) can reveal the existence and extent of spatial variation of gene expression in complex tissues. Such analyses could help identify spatially localized processes underlying a tissue's function. Existing tools to detect spatially variable genes assume a constant noise variance across spatial locations. This assumption might miss important biological signals when the variance can change across locations.,1,Spatial transcriptomics (ST) can reveal the existence and extent of spatial variation of gene expression in complex tissues.
The NanoFlow Repository.,37285317,https://pubmed.ncbi.nlm.nih.gov/37285317/,https://doi.org/10.1093/bioinformatics/btad368,[],"Extracellular particles (EPs) are the focus of a rapidly growing area of exploration due to the widespread interest in understanding their roles in health and disease. However, despite the general need for EP data sharing and established community standards for data reporting, no standard repository for EP flow cytometry data captures rigor and minimum reporting standards such as those defined by MIFlowCyt-EV (https://doi.org/10.1080/20013078.2020.1713526). We sought to address this unmet need by developing the NanoFlow Repository.",3,No standard repository for EP flow cytometry data captures rigor and minimum reporting standards such as those defined by MIFlowCyt-EV.
JUMP: replicability analysis of high-throughput experiments with applications to spatial transcriptomic studies.,37279733,https://pubmed.ncbi.nlm.nih.gov/37279733/,https://doi.org/10.1093/bioinformatics/btad366,[],Replicability is the cornerstone of scientific research. The current statistical method for high-dimensional replicability analysis either cannot control the false discovery rate (FDR) or is too conservative.,1,The current statistical method for high-dimensional replicability analysis either cannot control the false discovery rate (FDR) or is too conservative.
A mixed-effects stochastic model reveals clonal dominance in gene therapy safety studies.,37268887,https://pubmed.ncbi.nlm.nih.gov/37268887/,https://doi.org/10.1186/s12859-023-05269-1,"['-Leaping', 'Clonal dominance', 'E-M algorithm', 'Gene therapy', 'Mixed-effects models', 'Stochastic reaction networks']","Mathematical models of haematopoiesis can provide insights on abnormal cell expansions (clonal dominance), and in turn can guide safety monitoring in gene therapy clinical applications. Clonal tracking is a recent high-throughput technology that can be used to quantify cells arising from a single haematopoietic stem cell ancestor after a gene therapy treatment. Thus, clonal tracking data can be used to calibrate the stochastic differential equations describing clonal population dynamics and hierarchical relationships in vivo.",1,Clonal tracking is a recent high-throughput technology that can be used to quantify cells arising from a single haematopoietic stem cell ancestor after a gene therapy treatment
Generating synthetic personal health data using conditional generative adversarial networks combining with differential privacy.,37268168,https://pubmed.ncbi.nlm.nih.gov/37268168/,https://doi.org/10.1016/j.jbi.2023.104404,"['Data privacy', 'Generative adversarial network', 'Health data sharing', 'Synthetic data', 'Synthetic health data']","A large amount of personal health data that is highly valuable to the scientific community is still not accessible or requires a lengthy request process due to privacy concerns and legal restrictions. As a solution, synthetic data has been studied and proposed to be a promising alternative to this issue. However, generating realistic and privacy-preserving synthetic personal health data retains challenges such as simulating the characteristics of the patients' data that are in the minority classes, capturing the relations among variables in imbalanced data and transferring them to the synthetic data, and preserving individual patients' privacy. In this paper, we propose a differentially private conditional Generative Adversarial Network model (DP-CGANS) consisting of data transformation, sampling, conditioning, and network training to generate realistic and privacy-preserving personal data. Our model distinguishes categorical and continuous variables and transforms them into latent space separately for better training performance. We tackle the unique challenges of generating synthetic patient data due to the special data characteristics of personal health data. For example, patients with a certain disease are typically the minority in the dataset and the relations among variables are crucial to be observed. Our model is structured with a conditional vector as an additional input to present the minority class in the imbalanced data and maximally capture the dependency between variables. Moreover, we inject statistical noise into the gradients in the networking training process of DP-CGANS to provide a differential privacy guarantee. We extensively evaluate our model with state-of-the-art generative models on personal socio-economic datasets and real-world personal health datasets in terms of statistical similarity, machine learning performance, and privacy measurement. We demonstrate that our model outperforms other comparable models, especially in capturing the dependence between variables. Finally, we present the balance between data utility and privacy in synthetic data generation considering the different data structures and characteristics of real-world personal health data such as imbalanced classes, abnormal distributions, and data sparsity.",1,A large amount of personal health data that is highly valuable to the scientific community is still not accessible or requires a lengthy request process due to privacy concerns and legal restrictions.
Disproportionate impacts of COVID-19 in a large US city.,37262052,https://pubmed.ncbi.nlm.nih.gov/37262052/,https://doi.org/10.1371/journal.pcbi.1011149,[],"COVID-19 has disproportionately impacted individuals depending on where they live and work, and based on their race, ethnicity, and socioeconomic status. Studies have documented catastrophic disparities at critical points throughout the pandemic, but have not yet systematically tracked their severity through time. Using anonymized hospitalization data from March 11, 2020 to June 1, 2021 and fine-grain infection hospitalization rates, we estimate the time-varying burden of COVID-19 by age group and ZIP code in Austin, Texas. During this 15-month period, we estimate an overall 23.7% (95% CrI: 22.5-24.8%) infection rate and 29.4% (95% CrI: 28.0-31.0%) case reporting rate. Individuals over 65 were less likely to be infected than younger age groups (11.2% [95% CrI: 10.3-12.0%] vs 25.1% [95% CrI: 23.7-26.4%]), but more likely to be hospitalized (1,965 per 100,000 vs 376 per 100,000) and have their infections reported (53% [95% CrI: 49-57%] vs 28% [95% CrI: 27-30%]). We used a mixed effect poisson regression model to estimate disparities in infection and reporting rates as a function of social vulnerability. We compared ZIP codes ranking in the 75th percentile of vulnerability to those in the 25th percentile, and found that the more vulnerable communities had 2.5 (95% CrI: 2.0-3.0) times the infection rate and only 70% (95% CrI: 60%-82%) the reporting rate compared to the less vulnerable communities. Inequality persisted but declined significantly over the 15-month study period. Our results suggest that further public health efforts are needed to mitigate local COVID-19 disparities and that the CDC's social vulnerability index may serve as a reliable predictor of risk on a local scale when surveillance data are limited.",1,"CVID-19 has disproportionately impacted individuals depending on where they live and work, and based on their race, ethnicity, and socioeconomic status."
Humans decompose tasks by trading off utility and computational cost.,37262023,https://pubmed.ncbi.nlm.nih.gov/37262023/,https://doi.org/10.1371/journal.pcbi.1011087,[],"Human behavior emerges from planning over elaborate decompositions of tasks into goals, subgoals, and low-level actions. How are these decompositions created and used? Here, we propose and evaluate a normative framework for task decomposition based on the simple idea that people decompose tasks to reduce the overall cost of planning while maintaining task performance. Analyzing 11,117 distinct graph-structured planning tasks, we find that our framework justifies several existing heuristics for task decomposition and makes predictions that can be distinguished from two alternative normative accounts. We report a behavioral study of task decomposition (N = 806) that uses 30 randomly sampled graphs, a larger and more diverse set than that of any previous behavioral study on this topic. We find that human responses are more consistent with our framework for task decomposition than alternative normative accounts and are most consistent with a heuristic-betweenness centrality-that is justified by our approach. Taken together, our results suggest the computational cost of planning is a key principle guiding the intelligent structuring of goal-directed behavior.",2,"Human behavior emerges from planning over elaborate decompositions of tasks into goals, subgoals, and low-level actions."
MRGCN: cancer subtyping with multi-reconstruction graph convolutional network using full and partial multi-omics dataset.,37255323,https://pubmed.ncbi.nlm.nih.gov/37255323/,https://doi.org/10.1093/bioinformatics/btad353,[],"Cancer is a molecular complex and heterogeneous disease. Each type of cancer is usually composed of several subtypes with different treatment responses and clinical outcomes. Therefore, subtyping is a crucial step in cancer diagnosis and therapy. The rapid advances in high-throughput sequencing technologies provide an increasing amount of multi-omics data, which benefits our understanding of cancer genetic architecture, and yet poses new challenges in multi-omics data integration.",3,Cancer is a molecular complex and heterogeneous disease.. Each type of cancer is usually composed of several subtypes with different treatment responses and clinical outcomes.
Nonlinear data fusion over Entity-Relation graphs for Drug-Target Interaction prediction.,37255310,https://pubmed.ncbi.nlm.nih.gov/37255310/,https://doi.org/10.1093/bioinformatics/btad348,[],"The prediction of reliable Drug-Target Interactions (DTIs) is a key task in computer-aided drug design and repurposing. Here, we present a new approach based on data fusion for DTI prediction built on top of the NXTfusion library, which generalizes the Matrix Factorization paradigm by extending it to the nonlinear inference over Entity-Relation graphs.",1,The prediction of reliable Drug-Target Interactions is a key task in computer-aided drug design and repurposing.
Accelerated nanopore basecalling with SLOW5 data format.,37252813,https://pubmed.ncbi.nlm.nih.gov/37252813/,https://doi.org/10.1093/bioinformatics/btad352,[],"Nanopore sequencing is emerging as a key pillar in the genomic technology landscape but computational constraints limiting its scalability remain to be overcome. The translation of raw current signal data into DNA or RNA sequence reads, known as 'basecalling', is a major friction in any nanopore sequencing workflow. Here, we exploit the advantages of the recently developed signal data format 'SLOW5' to streamline and accelerate nanopore basecalling on high-performance computing (HPC) and cloud environments.",2,Nanopore sequencing is emerging as a key pillar in the genomic technology landscape.
IEPAPI: a method for immune epitope prediction by incorporating antigen presentation and immunogenicity.,37232386,https://pubmed.ncbi.nlm.nih.gov/37232386/,https://doi.org/10.1093/bib/bbad171,"['antigen presentation', 'cancer immunotherapy', 'deep learning', 'immunogenicity', 'neoantigen', 'transformer']","CD8+ T cells can recognize peptides presented by class I human leukocyte antigen (HLA-I) of nucleated cells. Exploring this immune mechanism is essential for identifying T-cell vaccine targets in cancer immunotherapy. Over the past decade, the wealth of data generated by experiments has spawned many computational approaches for predicting HLA-I binding, antigen presentation and T-cell immune responses. Nevertheless, existing HLA-I binding and antigen presentation prediction approaches suffer from low precision due to the absence of T-cell receptor (TCR) recognition. Direct modeling of T-cell immune responses is less effective as TCR recognition's mechanism still remains underexplored. Therefore, directly applying these existing methods to screen cancer neoantigens is still challenging. Here, we propose a novel immune epitope prediction method termed IEPAPI by effectively incorporating antigen presentation and immunogenicity. First, IEPAPI employs a transformer-based feature extraction block to acquire representations of peptides and HLA-I proteins. Second, IEPAPI integrates the prediction of antigen presentation prediction into the input of immunogenicity prediction branch to simulate the connection between the biological processes in the T-cell immune response. Quantitative comparison results on an independent antigen presentation test dataset exhibit that IEPAPI outperformed the current state-of-the-art approaches NetMHCpan4.1 and mhcflurry2.0 on 100 (25/25) and 76% (19/25) of the HLA subtypes, respectively. Furthermore, IEPAPI demonstrates the best precision on two independent neoantigen datasets when compared with existing approaches, suggesting that IEPAPI provides a vital tool for T-cell vaccine design.",1,CD8+ T cells can recognize peptides presented by class I human leukocyte antigen (HLA-I) of nucleated cells.
Integrating massive RNA-seq data to elucidate transcriptome dynamics in Drosophila melanogaster.,37232385,https://pubmed.ncbi.nlm.nih.gov/37232385/,https://doi.org/10.1093/bib/bbad177,"['computational methods', 'data integration and quality control', 'gene expression dynamics', 'massively parallel sequencing', 'sequence read archive']","The volume of ribonucleic acid (RNA)-seq data has increased exponentially, providing numerous new insights into various biological processes. However, due to significant practical challenges, such as data heterogeneity, it is still difficult to ensure the quality of these data when integrated. Although some quality control methods have been developed, sample consistency is rarely considered and these methods are susceptible to artificial factors. Here, we developed MassiveQC, an unsupervised machine learning-based approach, to automatically download and filter large-scale high-throughput data. In addition to the read quality used in other tools, MassiveQC also uses the alignment and expression quality as model features. Meanwhile, it is user-friendly since the cutoff is generated from self-reporting and is applicable to multimodal data. To explore its value, we applied MassiveQC to Drosophila RNA-seq data and generated a comprehensive transcriptome atlas across 28 tissues from embryogenesis to adulthood. We systematically characterized fly gene expression dynamics and found that genes with high expression dynamics were likely to be evolutionarily young and expressed at late developmental stages, exhibiting high nonsynonymous substitution rates and low phenotypic severity, and they were involved in simple regulatory programs. We also discovered that human and Drosophila had strong positive correlations in gene expression in orthologous organs, revealing the great potential of the Drosophila system for studying human development and disease.",2,MassiveQC is an unsupervised machine learning-based approach to automatically download and filter large-scale high-throughput data.
Molecular Dynamics Simulation-Driven Focused Virtual Screening and Experimental Validation of Inhibitors for MTDH-SND1 Protein-Protein Interaction.,37226724,https://pubmed.ncbi.nlm.nih.gov/37226724/,https://doi.org/10.1021/acs.jcim.3c00310,[],"Protein-protein interactions (PPIs), in general, are attractive yet challenging drug targets. As a typical PPI, MTDH-SND1 interaction has recently been reported to be a promising drug target to malignant breast cancer and other cancer types. However, the lack of well-defined deep pockets on the MTDH-SND1 interface makes it a tough target for rational drug discovery attempts. To address this issue, in this study, a long time-scale molecular dynamics (MD) simulation-driven focused screening strategy was proposed and reported. A total of 12 virtual hits were purchased and tested in SPR assay, yielding 10 SND1 binders with micromolar or less affinities. As an example, compound ",1,Protein-protein interactions (PPIs) are attractive yet challenging drug targets.
Empowering biologists to decode omics data: the Genekitr R package and web server.,37221491,https://pubmed.ncbi.nlm.nih.gov/37221491/,https://doi.org/10.1186/s12859-023-05342-9,"['Bioinformatics tool', 'Gene set enrichment analysis', 'Non-programming bioinformatics', 'Plotting', 'Web server']","A variety of high-throughput analyses, such as transcriptome, proteome, and metabolome analysis, have been developed, producing unprecedented amounts of omics data. These studies generate large gene lists, of which the biological significance shall be deeply understood. However, manually interpreting these lists is difficult, especially for non-bioinformatics-savvy scientists.",3,"A variety of high-throughput analyses, such as transcriptome, proteome, and metabolome analysis, have been developed."
The MAPK/ERK channel capacity exceeds 6 bit/hour.,37216347,https://pubmed.ncbi.nlm.nih.gov/37216347/,https://doi.org/10.1371/journal.pcbi.1011155,[],"Living cells utilize signaling pathways to sense, transduce, and process information. As the extracellular stimulation often has rich temporal characteristics which may govern dynamic cellular responses, it is important to quantify the rate of information flow through the signaling pathways. In this study, we used an epithelial cell line expressing a light-activatable FGF receptor and an ERK activity reporter to assess the ability of the MAPK/ERK pathway to transduce signal encoded in a sequence of pulses. By stimulating the cells with random light pulse trains, we demonstrated that the MAPK/ERK channel capacity is at least 6 bits per hour. The input reconstruction algorithm detects the light pulses with 1-min accuracy 5 min after their occurrence. The high information transmission rate may enable the pathway to coordinate multiple processes including cell movement and respond to rapidly varying stimuli such as chemoattracting gradients created by other cells.",1,"Living cells utilize signaling pathways to sense, transduce, and process information."
Fast and versatile sequence-independent protein docking for nanomaterials design using RPXDock.,37216343,https://pubmed.ncbi.nlm.nih.gov/37216343/,https://doi.org/10.1371/journal.pcbi.1010680,[],"Computationally designed multi-subunit assemblies have shown considerable promise for a variety of applications, including a new generation of potent vaccines. One of the major routes to such materials is rigid body sequence-independent docking of cyclic oligomers into architectures with point group or lattice symmetries. Current methods for docking and designing such assemblies are tailored to specific classes of symmetry and are difficult to modify for novel applications. Here we describe RPXDock, a fast, flexible, and modular software package for sequence-independent rigid-body protein docking across a wide range of symmetric architectures that is easily customizable for further development. RPXDock uses an efficient hierarchical search and a residue-pair transform (RPX) scoring method to rapidly search through multidimensional docking space. We describe the structure of the software, provide practical guidelines for its use, and describe the available functionalities including a variety of score functions and filtering tools that can be used to guide and refine docking results towards desired configurations.",2, RPXDock uses an efficient hierarchical search and a residue-pair transform (RPX) scoring method to rapidly search through multidimensional docking space.
On a mechanistic impact of transmembrane tetramerization in the pathological activation of RTKs.,37216019,https://pubmed.ncbi.nlm.nih.gov/37216019/,https://doi.org/10.1016/j.csbj.2023.04.021,"['Model membranes', 'Molecular dynamics simulations', 'Pathological mutations', 'Protein oligomerization', 'Signal transduction', 'Structure prediction']","Constitutive activation of receptor tyrosine kinases (RTKs) via different mutations has a strong impact on the development of severe human disorders, including cancer. Here we propose a putative activation scenario of RTKs, whereby transmembrane (TM) mutations can also promote higher-order oligomerization of the receptors that leads to the subsequent ligand-free activation. We illustrate this scenario using a computational modelling framework comprising sequence-based structure prediction and all-atom 1 µs molecular dynamics (MD) simulations in a lipid membrane for a previously characterised oncogenic TM mutation V536E in platelet-derived growth factor receptor alpha (PDGFRA). We show that in the course of MD simulations the mutant TM tetramer retains stable and compact configuration strengthened by tight protein-protein interactions, while the wild type TM tetramer demonstrates looser packing and a tendency to dissociate. Moreover, the mutation affects the characteristic motions of mutated TM helical segments by introducing additional non-covalent crosslinks in the middle of the TM tetramer, which operate as mechanical hinges. This leads to dynamic decoupling of the C-termini from the rigidified N-terminal parts and facilitates more pronounced possible displacement between the C-termini of the mutant TM helical regions that can provide more freedom for mutual rearrangement of the kinase domains located downstream. Our results for the V536E mutation in the context of PDGFRA TM tetramer allow for the possibility that the effect of oncogenic TM mutations can go beyond alternating the structure and dynamics of TM dimeric states and might also promote the formation of higher-order oligomers directly contributing to ligand-independent signalling effectuated by PDGFRA and other RTKs.",1,"Constantutive activation of receptor tyrosine kinases (RTKs) via different mutations has a strong impact on the development of severe human disorders, including cancer."
Integrative big transcriptomics data analysis implicates crucial role of MUC13 in pancreatic cancer.,37216018,https://pubmed.ncbi.nlm.nih.gov/37216018/,https://doi.org/10.1016/j.csbj.2023.04.029,"['Bigdata', 'MUC13', 'MUC13 genomic forms', 'Mucins', 'Pancreatic cancer', 'Structural-Genomics & functional analysis', 'Transcriptomics']","Big data analysis holds a considerable influence on several aspects of biomedical health science. It permits healthcare providers to gain insights from large and complex datasets, leading to improvements in the understanding, diagnosis, medication, and restraint of pathological conditions including cancer. The incidences of pancreatic cancer (PanCa) are sharply rising, and it will become the second leading cause of cancer related deaths by 2030. Various traditional biomarkers are currently in use but are not optimal in sensitivity and specificity. Herein, we determine the role of a new transmembrane glycoprotein, MUC13, as a potential biomarker of pancreatic ductal adenocarcinoma (PDAC) by using integrative big data mining and transcriptomic approaches. This study is helpful to identify and appropriately segment the data related to MUC13, which are scattered in various data sets. The assembling of the meaningful data, representation strategy was used to investigate the MUC13 associated information for the better understanding regarding its structural, expression profiling, genomic variants, phosphorylation motifs, and functional enrichment pathways. For further in-depth investigation, we have adopted several popular transcriptomic methods like DEGseq2, coding and non-coding transcript, single cell seq analysis, and functional enrichment analysis. All these analyzes suggest the presence of three nonsense MUC13 genomic transcripts, two protein transcripts, short MUC13 (s-MUC13, non-tumorigenic or ntMUC13), and long MUC13 (L-MUC13, tumorigenic or tMUC13), several important phosphorylation sites in tMUC13. Altogether, this data confirms that importance of tMUC13 as a potential biomarker, therapeutic target of PanCa, and its significance in pancreatic pathobiology.",2,"The incidences of pancreatic cancer (PanCa) are sharply rising, and it will become the second leading cause of cancer related deaths by 2030."
Deep cross-modal feature learning applied to predict acutely decompensated heart failure using in-home collected electrocardiography and transthoracic bioimpedance.,37210152,https://pubmed.ncbi.nlm.nih.gov/37210152/,https://doi.org/10.1016/j.artmed.2023.102548,"['Deep learning', 'ECG analysis', 'Heart failure', 'Wearable device']","Deep learning has been successfully applied to ECG data to aid in the accurate and more rapid diagnosis of acutely decompensated heart failure (ADHF). Previous applications focused primarily on classifying known ECG patterns in well-controlled clinical settings. However, this approach does not fully capitalize on the potential of deep learning, which directly learns important features without relying on a priori knowledge. In addition, deep learning applications to ECG data obtained from wearable devices have not been well studied, especially in the field of ADHF prediction.",1,Deep learning has been successfully applied to ECG data to aid in the accurate and more rapid diagnosis of acutely decompensated heart failure (ADHF) Previous applications focused primarily on classifying
A unique color-coded visualization system with multimodal information fusion and deep learning in a longitudinal study of Alzheimer's disease.,37210151,https://pubmed.ncbi.nlm.nih.gov/37210151/,https://doi.org/10.1016/j.artmed.2023.102543,"[""Alzheimer's disease"", 'Deep learning', 'Diagnosis', 'Prognosis', 'Trustfulness visualization']","Automated diagnosis and prognosis of Alzheimer's Disease remain a challenging problem that machine learning (ML) techniques have attempted to resolve in the last decade. This study introduces a first-of-its-kind color-coded visualization mechanism driven by an integrated ML model to predict disease trajectory in a 2-year longitudinal study. The main aim of this study is to help capture visually in 2D and 3D renderings the diagnosis and prognosis of AD, therefore augmenting our understanding of the processes of multiclass classification and regression analysis.",1,Automated diagnosis and prognosis of Alzheimer's Disease remain a challenging problem.
"HISS: Snakemake-based workflows for performing SMRT-RenSeq assembly, AgRenSeq and dRenSeq for the discovery of novel plant disease resistance genes.",37198529,https://pubmed.ncbi.nlm.nih.gov/37198529/,https://doi.org/10.1186/s12859-023-05335-8,"['HiFi sequencing', 'High-throughput', 'NLRs', 'Plant disease resistance', 'SMRT-AgRenSeq-d', 'Snakemake', 'Workflow', 'dRenSeq']","In the ten years since the initial publication of the RenSeq protocol, the method has proved to be a powerful tool for studying disease resistance in plants and providing target genes for breeding programmes. Since the initial publication of the methodology, it has continued to be developed as new technologies have become available and the increased availability of computing power has made new bioinformatic approaches possible. Most recently, this has included the development of a k-mer based association genetics approach, the use of PacBio HiFi data, and graphical genotyping with diagnostic RenSeq. However, there is not yet a unified workflow available and researchers must instead configure approaches from various sources themselves. This makes reproducibility and version control a challenge and limits the ability to perform these analyses to those with bioinformatics expertise.",1,"In the ten years since the initial publication of the RenSeq protocol, the method has proved to be a powerful tool for studying disease resistance in plants and providing target genes for breeding programmes"
Guidelines for Reporting Molecular Dynamics Simulations in JCIM Publications.,37191169,https://pubmed.ncbi.nlm.nih.gov/37191169/,https://doi.org/10.1021/acs.jcim.3c00599,[],,2,
,37181662,https://pubmed.ncbi.nlm.nih.gov/37181662/,https://doi.org/10.1016/j.csbj.2023.04.009,"['Brillouin microscopy', 'Corneal biomechanics', 'Corneal visualization scheimpflug technology', 'Elastography', 'Ocular response analyzer', 'Optical coherence elastography', 'Young’s modulus']","Clinical measurement of corneal biomechanics can aid in the early diagnosis, progression tracking, and treatment evaluation of ocular diseases. Over the past two decades, interdisciplinary collaborations between investigators in optical engineering, analytical biomechanical modeling, and clinical research has expanded our knowledge of corneal biomechanics. These advances have led to innovations in testing methods (",2," Clinical measurement of corneal biomechanics can aid in the early diagnosis, progression tracking, and treatment evaluation of ocular diseases."
ViralConsensus: a fast and memory-efficient tool for calling viral consensus genome sequences directly from read alignment data.,37171896,https://pubmed.ncbi.nlm.nih.gov/37171896/,https://doi.org/10.1093/bioinformatics/btad317,[],"In viral molecular epidemiology, reconstruction of consensus genomes from sequence data is critical for tracking mutations and variants of concern. However, as the number of samples that are sequenced grows rapidly, compute resources needed to reconstruct consensus genomes can become prohibitively large.",2,"In viral molecular epidemiology, reconstruction of consensus genomes from sequence data is critical for tracking mutations and variants of concern."
NanoPack2: population-scale evaluation of long-read sequencing data.,37171891,https://pubmed.ncbi.nlm.nih.gov/37171891/,https://doi.org/10.1093/bioinformatics/btad311,[],"Increases in the cohort size in long-read sequencing projects necessitate more efficient software for quality assessment and processing of sequencing data from Oxford Nanopore Technologies and Pacific Biosciences. Here, we describe novel tools for summarizing experiments, filtering datasets, visualizing phased alignments results, and updates to the NanoPack software suite.",23,Oxford Nanopore Technologies and Pacific Biosciences developed NanoPack software.
NAFLDkb: A Knowledge Base and Platform for Drug Development against Nonalcoholic Fatty Liver Disease.,37167092,https://pubmed.ncbi.nlm.nih.gov/37167092/,https://doi.org/10.1021/acs.jcim.3c00395,[],"Nonalcoholic fatty liver disease (NAFLD) is the most common chronic liver disease with a broad spectrum of histologic manifestations. The rapidly growing prevalence and the complex pathologic mechanisms of NAFLD pose great challenges for treatment development. Despite tremendous efforts devoted to drug development, there are no FDA-approved medicines yet. Here, we present NAFLDkb, a specialized knowledge base and platform for computer-aided drug design against NAFLD. With multiperspective information curated from diverse source materials and public databases, NAFLDkb presents the associations of drug-related entities as individual knowledge graphs. Practical drug discovery tools that facilitate the utilization and expansion of NAFLDkb have also been implemented in the web interface, including chemical structure search, drug-likeness screening, knowledge-based repositioning, and research article annotation. Moreover, case studies of a knowledge graph repositioning model and a generative neural network model are presented herein, where three repositioning drug candidates and 137 novel lead-like compounds were newly established as NAFLD pharmacotherapy options reusing data records and machine learning tools in NAFLDkb, suggesting its clinical reliability and great potential in identifying novel drug-disease associations of NAFLD and generating new insights to accelerate NAFLD drug development. NAFLDkb is freely accessible at https://www.biosino.org/nafldkb and will be updated periodically with the latest findings.",1,Nonalcoholic fatty liver disease (NAFLD) is the most common chronic liver disease with a broad spectrum of histologic manifestations.
Fingerprint-Enhanced Graph Attention Network (FinGAT) Model for Antibiotic Discovery.,37167016,https://pubmed.ncbi.nlm.nih.gov/37167016/,https://doi.org/10.1021/acs.jcim.3c00045,[],"Artificial Intelligence (AI) techniques are of great potential to fundamentally change antibiotic discovery industries. Efficient and effective molecular featurization is key to all highly accurate learning models for antibiotic discovery. In this paper, we propose a fingerprint-enhanced graph attention network (FinGAT) model by the combination of sequence-based 2D fingerprints and structure-based graph representation. In our feature learning process, sequence information is transformed into a fingerprint vector, and structural information is encoded through a GAT module into another vector. These two vectors are concatenated and input into a multilayer perceptron (MLP) for antibiotic activity classification. Our model is extensively tested and compared with existing models. It has been found that our FinGAT can outperform various state-of-the-art GNN models in antibiotic discovery.",1,Artificial Intelligence (AI) techniques are of great potential to fundamentally change antibiotic discovery industries.
Low Rank Matrix Factorization Algorithm Based on Multi-Graph Regularization for Detecting Drug-Disease Association.,37159322,https://pubmed.ncbi.nlm.nih.gov/37159322/,https://doi.org/10.1109/TCBB.2023.3274587,[],"Detecting potential associations between drugs and diseases plays an indispensable role in drug development, which has also become a research hotspot in recent years. Compared with traditional methods, some computational approaches have the advantages of fast speed and low cost, which greatly accelerate the progress of predicting the drug-disease association. In this study, we propose a novel similarity-based method of low-rank matrix decomposition based on multi-graph regularization. On the basis of low-rank matrix factorization with L",1,Detecting potential associations between drugs and diseases plays an indispensable role in drug development.
GKLOMLI: a link prediction model for inferring miRNA-lncRNA interactions by using Gaussian kernel-based method on network profile and linear optimization algorithm.,37158823,https://pubmed.ncbi.nlm.nih.gov/37158823/,https://doi.org/10.1186/s12859-023-05309-w,"['Competing endogenous RNA (ceRNA)', 'Computational biology', 'Gaussian kernel', 'Link prediction', 'miRNA–lncRNA interaction']","The limited knowledge of miRNA-lncRNA interactions is considered as an obstruction of revealing the regulatory mechanism. Accumulating evidence on Human diseases indicates that the modulation of gene expression has a great relationship with the interactions between miRNAs and lncRNAs. However, such interaction validation via crosslinking-immunoprecipitation and high-throughput sequencing (CLIP-seq) experiments that inevitably costs too much money and time but with unsatisfactory results. Therefore, more and more computational prediction tools have been developed to offer many reliable candidates for a better design of further bio-experiments.",7, limited knowledge of miRNA-lncRNA interactions is considered as an obstruction of revealing the regulatory mechanism.
ATTIC is an integrated approach for predicting A-to-I RNA editing sites in three species.,37150785,https://pubmed.ncbi.nlm.nih.gov/37150785/,https://doi.org/10.1093/bib/bbad170,"['A-to-I editing', 'RNA modification', 'ensemble learning', 'feature selection', 'machine learning']","A-to-I editing is the most prevalent RNA editing event, which refers to the change of adenosine (A) bases to inosine (I) bases in double-stranded RNAs. Several studies have revealed that A-to-I editing can regulate cellular processes and is associated with various human diseases. Therefore, accurate identification of A-to-I editing sites is crucial for understanding RNA-level (i.e. transcriptional) modifications and their potential roles in molecular functions. To date, various computational approaches for A-to-I editing site identification have been developed; however, their performance is still unsatisfactory and needs further improvement. In this study, we developed a novel stacked-ensemble learning model, ATTIC (A-To-I ediTing predICtor), to accurately identify A-to-I editing sites across three species, including Homo sapiens, Mus musculus and Drosophila melanogaster. We first comprehensively evaluated 37 RNA sequence-derived features combined with 14 popular machine learning algorithms. Then, we selected the optimal base models to build a series of stacked ensemble models. The final ATTIC framework was developed based on the optimal models improved by the feature selection strategy for specific species. Extensive cross-validation and independent tests illustrate that ATTIC outperforms state-of-the-art tools for predicting A-to-I editing sites. We also developed a web server for ATTIC, which is publicly available at http://web.unimelb-bioinfortools.cloud.edu.au/ATTIC/. We anticipate that ATTIC can be utilized as a useful tool to accelerate the identification of A-to-I RNA editing events and help characterize their roles in post-transcriptional regulation.",2,A-to-I editing is the most prevalent RNA editing event.
CosTaL: an accurate and scalable graph-based clustering algorithm for high-dimensional single-cell data analysis.,37150778,https://pubmed.ncbi.nlm.nih.gov/37150778/,https://doi.org/10.1093/bib/bbad157,"['Clustering', 'Flow Cytometry', 'Graph-based clustering', 'Mass Cytometry', 'Single-cell RNA sequencing', 'k nearest neighbors']","With the aim of analyzing large-sized multidimensional single-cell datasets, we are describing a method for Cosine-based Tanimoto similarity-refined graph for community detection using Leiden's algorithm (CosTaL). As a graph-based clustering method, CosTaL transforms the cells with high-dimensional features into a weighted k-nearest-neighbor (kNN) graph. The cells are represented by the vertices of the graph, while an edge between two vertices in the graph represents the close relatedness between the two cells. Specifically, CosTaL builds an exact kNN graph using cosine similarity and uses the Tanimoto coefficient as the refining strategy to re-weight the edges in order to improve the effectiveness of clustering. We demonstrate that CosTaL generally achieves equivalent or higher effectiveness scores on seven benchmark cytometry datasets and six single-cell RNA-sequencing datasets using six different evaluation metrics, compared with other state-of-the-art graph-based clustering methods, including PhenoGraph, Scanpy and PARC. As indicated by the combined evaluation metrics, Costal has high efficiency with small datasets and acceptable scalability for large datasets, which is beneficial for large-scale analysis.",2,CosTaL builds an exact kNN graph using cosine similarity and uses the Tanimoto coefficient as the refining strategy to re-weight the edges.
Interaction of the Inhibitory Peptides ShK and HmK with the Voltage-Gated Potassium Channel K,37143234,https://pubmed.ncbi.nlm.nih.gov/37143234/,https://doi.org/10.1021/acs.jcim.2c01237,[],Peptide toxins that adopt the ShK fold can inhibit the voltage-gated potassium channel K,2,Peptide toxins that adopt the ShK fold can inhibit the voltage-gated potassium channel K.
Concepts and methods for transcriptome-wide prediction of chemical messenger RNA modifications with machine learning.,37139545,https://pubmed.ncbi.nlm.nih.gov/37139545/,https://doi.org/10.1093/bib/bbad163,"['RNA modifications', 'deep learning', 'direct RNA sequencing', 'epitranscriptomics', 'machine learning', 'miCLIP']","The expanding field of epitranscriptomics might rival the epigenome in the diversity of biological processes impacted. In recent years, the development of new high-throughput experimental and computational techniques has been a key driving force in discovering the properties of RNA modifications. Machine learning applications, such as for classification, clustering or de novo identification, have been critical in these advances. Nonetheless, various challenges remain before the full potential of machine learning for epitranscriptomics can be leveraged. In this review, we provide a comprehensive survey of machine learning methods to detect RNA modifications using diverse input data sources. We describe strategies to train and test machine learning methods and to encode and interpret features that are relevant for epitranscriptomics. Finally, we identify some of the current challenges and open questions about RNA modification analysis, including the ambiguity in predicting RNA modifications in transcript isoforms or in single nucleotides, or the lack of complete ground truth sets to test RNA modifications. We believe this review will inspire and benefit the rapidly developing field of epitranscriptomics in addressing the current limitations through the effective use of machine learning.",3,The expanding field of epitranscriptomics might rival the epigenome in the diversity of biological processes impacted.
Machine learning-assisted medium optimization revealed the discriminated strategies for improved production of the foreign and native metabolites.,37138901,https://pubmed.ncbi.nlm.nih.gov/37138901/,https://doi.org/10.1016/j.csbj.2023.04.020,"['Aromatic compound', 'Bacterial growth', 'Machine learning', 'Medium', 'Production', 'Synthetic pathway', 'Transcriptome']","The composition of medium components is crucial for achieving the best performance of synthetic construction in genetically engineered cells. Which and how medium components determine the performance, e.g., productivity, remain poorly investigated. To address the questions, a comparative survey with two genetically engineered ",1,The composition of medium components is crucial for achieving the best performance of synthetic construction in genetically engineered cells.
MBECS: Microbiome Batch Effects Correction Suite.,37138207,https://pubmed.ncbi.nlm.nih.gov/37138207/,https://doi.org/10.1186/s12859-023-05252-w,"['Batch effects', 'Bioconductor', 'Microbiome', 'R-package', 'phyloseq']","Despite the availability of batch effect correcting algorithms (BECA), no comprehensive tool that combines batch correction and evaluation of the results exists for microbiome datasets. This work outlines the Microbiome Batch Effects Correction Suite development that integrates several BECAs and evaluation metrics into a software package for the statistical computation framework R.",1,Microbiome Batch Effects Correction Suite development that integrates several BECAs and evaluation metrics into a software package for R.
BUSZ: compressed BUS files.,37129540,https://pubmed.ncbi.nlm.nih.gov/37129540/,https://doi.org/10.1093/bioinformatics/btad295,[],"We describe a compression scheme for BUS files and an implementation of the algorithm in the BUStools software. Our compression algorithm yields smaller file sizes than gzip, at significantly faster compression and decompression speeds. We evaluated our algorithm on 533 BUS files from scRNA-seq experiments with a total size of 1TB. Our compression is 2.2× faster than the fastest gzip option 35% slower than the fastest zstd option and results in 1.5× smaller files than both methods. This amounts to an 8.3× reduction in the file size, resulting in a compressed size of 122GB for the dataset.",1,"Our compression algorithm yields smaller file sizes than gzip, at significantly faster compression and decompression speeds."
meth-SemiCancer: a cancer subtype classification framework via semi-supervised learning utilizing DNA methylation profiles.,37101254,https://pubmed.ncbi.nlm.nih.gov/37101254/,https://doi.org/10.1186/s12859-023-05272-6,"['Cancer subtype classification', 'DNA methylation', 'Neural network', 'Semi-supervised learning']","Identification of the cancer subtype plays a crucial role to provide an accurate diagnosis and proper treatment to improve the clinical outcomes of patients. Recent studies have shown that DNA methylation is one of the key factors for tumorigenesis and tumor growth, where the DNA methylation signatures have the potential to be utilized as cancer subtype-specific markers. However, due to the high dimensionality and the low number of DNA methylome cancer samples with the subtype information, still, to date, a cancer subtype classification method utilizing DNA methylome datasets has not been proposed.",2,DNA methylation is one of the key factors for tumorigenesis and tumor growth.. DNA methylation signatures have the potential to be utilized as cancer subtype-specific markers.
DGH-GO: dissecting the genetic heterogeneity of complex diseases using gene ontology.,37101154,https://pubmed.ncbi.nlm.nih.gov/37101154/,https://doi.org/10.1186/s12859-023-05290-4,"['Dimension reduction', 'Functionally similarities', 'Gene ontology', 'Genetic heterogeneity', 'Neurodevelopmental disorders', 'Semantic similarity', 'Unsupervised learning']","Complex diseases such as neurodevelopmental disorders (NDDs) exhibit multiple etiologies. The multi-etiological nature of complex-diseases emerges from distinct but functionally similar group of genes. Different diseases sharing genes of such groups show related clinical outcomes that further restrict our understanding of disease mechanisms, thus, limiting the applications of personalized medicine approaches to complex genetic disorders.",1, Complex diseases such as neurodevelopmental disorders (NDDs) exhibit multiple etiologies.
moBRCA-net: a breast cancer subtype classification framework based on multi-omics attention neural networks.,37101124,https://pubmed.ncbi.nlm.nih.gov/37101124/,https://doi.org/10.1186/s12859-023-05273-5,"['Attention', 'Breast cancer subtype classification', 'Deep learning-based framework', 'Multi-omics', 'Neural network']","Breast cancer is a highly heterogeneous disease that comprises multiple biological components. Owing its diversity, patients have different prognostic outcomes; hence, early diagnosis and accurate subtype prediction are critical for treatment. Standardized breast cancer subtyping systems, mainly based on single-omics datasets, have been developed to ensure proper treatment in a systematic manner. Recently, multi-omics data integration has attracted attention to provide a comprehensive view of patients but poses a challenge due to the high dimensionality. In recent years, deep learning-based approaches have been proposed, but they still present several limitations.",3,Breast cancer is a highly heterogeneous disease that comprises multiple biological components.. Early diagnosis and accurate subtype prediction are critical for treatment.
A novel discrete learning-based intelligent methodology for breast cancer classification purposes.,37100500,https://pubmed.ncbi.nlm.nih.gov/37100500/,https://doi.org/10.1016/j.artmed.2023.102492,"['Breast cancer', 'Data mining', 'Discrete and continuous learning algorithms', 'Intelligent modeling and classification', 'Medical decision-making', 'Multilayer perceptrons (MLPs)']","Classification is one of the most significant subfields of data mining that has been successfully applied to various applications. The literature has expended substantial effort to present more efficient and accurate classification models. Despite the diversity of the proposed models, they were all created using the same methodology, and their learning processes ignored a fundamental issue. In all existing classification model learning processes, a continuous distance-based cost function is optimized to estimate the unknown parameters. The classification problem's objective function is discrete. Consequently, applying a continuous cost function to a classification problem with a discrete objective function is illogical or inefficient. This paper proposes a novel classification methodology utilizing a discrete cost function in the learning process. To this end, one of the most popular intelligent classification models, the multilayer perceptron (MLP), is used to implement the proposed methodology. Theoretically, the classification performance of the proposed discrete learning-based MLP (DIMLP) model is not dissimilar to that of its continuous learning-based counterpart. Nevertheless, in this study, to demonstrate the efficacy of the DIMLP model, it was applied to several breast cancer classification datasets, and its classification rate was compared to that of the conventional continuous learning-based MLP model. The empirical results indicate that the proposed DIMLP model outperforms the MLP model across all datasets. The results demonstrate that the presented DIMLP classification model achieves an average classification rate of 94.70 %, a 6.95 % improvement over the classification rate of the traditional MLP model, which was 88.54 %. Therefore, the classification approach proposed in this study can be utilized as an alternative learning process in intelligent classification methods for medical decision-making and other classification applications, particularly when more accurate results are required.",2,"In all existing classification model learning processes, a continuous distance-based cost function is optimized to estimate the unknown parameters."
Recent Advances in Assembly of Complex Plant Genomes.,37100237,https://pubmed.ncbi.nlm.nih.gov/37100237/,https://doi.org/10.1016/j.gpb.2023.04.004,"['Assembly algorithm', 'Complex plant genome', 'Haplotype-resolved assembly', 'Sequencing technology', 'Telomere-to-telomere genome']","Over the past 20 years, tremendous advances in sequencing technologies and computational algorithms have spurred plant genomic research into a thriving era with hundreds of genomes decoded already, ranging from those of nonvascular plants to those of flowering plants. However, complex plant genome assembly is still challenging and remains difficult to fully resolve with conventional sequencing and assembly methods due to high heterozygosity, highly repetitive sequences, or high ploidy characteristics of complex genomes. Herein, we summarize the challenges of and advances in complex plant genome assembly, including feasible experimental strategies, upgrades to sequencing technology, existing assembly methods, and different phasing algorithms. Moreover, we list actual cases of complex genome projects for readers to refer to and draw upon to solve future problems related to complex genomes. Finally, we expect that the accurate, gapless, telomere-to-telomere, and fully phased assembly of complex plant genomes could soon become routine.",3, complex plant genome assembly is still challenging and remains difficult to fully resolve with conventional sequencing and assembly methods.
Contextualized medication information extraction using Transformer-based deep learning architectures.,37100106,https://pubmed.ncbi.nlm.nih.gov/37100106/,https://doi.org/10.1016/j.jbi.2023.104370,"['Clinical natural language processing', 'Deep learning', 'Medication information extraction', 'Named entity recognition', 'Text classification']",To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.,1,To develop a natural language processing (NLP) system to extract medications and contextual information.
Artificial intelligence and deep learning: New tools for histopathological diagnosis of nonalcoholic fatty liver disease/nonalcoholic steatohepatitis.,37090431,https://pubmed.ncbi.nlm.nih.gov/37090431/,https://doi.org/10.1016/j.csbj.2023.03.048,"['Artificial intelligence', 'Machine learning', 'Nonalcoholic fatty liver disease', 'Nonalcoholic steatohepatitis', 'Pathological diagnosis']","Nonalcoholic fatty liver disease (NAFLD)/nonalcoholic steatohepatitis (NASH) is associated with metabolic syndrome and is rapidly increasing globally with the increased prevalence of obesity. Although noninvasive diagnosis of NAFLD/NASH has progressed, pathological evaluation of liver biopsy specimens remains the gold standard for diagnosing NAFLD/NASH. However, the pathological diagnosis of NAFLD/NASH relies on the subjective judgment of the pathologist, resulting in non-negligible interobserver variations. Artificial intelligence (AI) is an emerging tool in pathology to assist diagnoses with high objectivity and accuracy. An increasing number of studies have reported the usefulness of AI in the pathological diagnosis of NAFLD/NASH, and our group has already used it in animal experiments. In this minireview, we first outline the histopathological characteristics of NAFLD/NASH and the basics of AI. Subsequently, we introduce previous research on AI-based pathological diagnosis of NAFLD/NASH.",1,Nonalcoholic fatty liver disease (NAFLD)/nonalcoholic steatohepatitis (NASH) is associated with metabolic syndrome.
FAS: assessing the similarity between proteins using multi-layered feature architectures.,37084276,https://pubmed.ncbi.nlm.nih.gov/37084276/,https://doi.org/10.1093/bioinformatics/btad226,[],"Protein sequence comparison is a fundamental element in the bioinformatics toolkit. When sequences are annotated with features such as functional domains, transmembrane domains, low complexity regions or secondary structure elements, the resulting feature architectures allow better informed comparisons. However, many existing schemes for scoring architecture similarities cannot cope with features arising from multiple annotation sources. Those that do fall short in the resolution of overlapping and redundant feature annotations.",1,Protein sequence comparison is a fundamental element in the bioinformatics toolkit.
spongEffects: ceRNA modules offer patient-specific insights into the miRNA regulatory landscape.,37084275,https://pubmed.ncbi.nlm.nih.gov/37084275/,https://doi.org/10.1093/bioinformatics/btad276,[],"Cancer is one of the leading causes of death worldwide. Despite significant improvements in prevention and treatment, mortality remains high for many cancer types. Hence, innovative methods that use molecular data to stratify patients and identify biomarkers are needed. Promising biomarkers can also be inferred from competing endogenous RNA (ceRNA) networks that capture the gene-miRNA gene regulatory landscape. Thus far, the role of these biomarkers could only be studied globally but not in a sample-specific manner. To mitigate this, we introduce spongEffects, a novel method that infers subnetworks (or modules) from ceRNA networks and calculates patient- or sample-specific scores related to their regulatory activity.",3,Cancer is one of the leading causes of death worldwide.. Innovative methods that use molecular data to stratify patients and identify biomarkers are needed.
Predicting the pathogenicity of missense variants using features derived from AlphaFold2.,37084271,https://pubmed.ncbi.nlm.nih.gov/37084271/,https://doi.org/10.1093/bioinformatics/btad280,[],"Missense variants are a frequent class of variation within the coding genome, and some of them cause Mendelian diseases. Despite advances in computational prediction, classifying missense variants into pathogenic or benign remains a major challenge in the context of personalized medicine. Recently, the structure of the human proteome was derived with unprecedented accuracy using the artificial intelligence system AlphaFold2. This raises the question of whether AlphaFold2 wild-type structures can improve the accuracy of computational pathogenicity prediction for missense variants.",11,Missense variants are a frequent class of variation within the coding genome.. Some of them cause Mendelian diseases.
TripletCell: a deep metric learning framework for accurate annotation of cell types at the single-cell level.,37080771,https://pubmed.ncbi.nlm.nih.gov/37080771/,https://doi.org/10.1093/bib/bbad132,"['batch effect', 'deep metric learning', 'identify novel cell types', 'scRNA-seq data']","Single-cell RNA sequencing (scRNA-seq) has significantly accelerated the experimental characterization of distinct cell lineages and types in complex tissues and organisms. Cell-type annotation is of great importance in most of the scRNA-seq analysis pipelines. However, manual cell-type annotation heavily relies on the quality of scRNA-seq data and marker genes, and therefore can be laborious and time-consuming. Furthermore, the heterogeneity of scRNA-seq datasets poses another challenge for accurate cell-type annotation, such as the batch effect induced by different scRNA-seq protocols and samples. To overcome these limitations, here we propose a novel pipeline, termed TripletCell, for cross-species, cross-protocol and cross-sample cell-type annotation. We developed a cell embedding and dimension-reduction module for the feature extraction (FE) in TripletCell, namely TripletCell-FE, to leverage the deep metric learning-based algorithm for the relationships between the reference gene expression matrix and the query cells. Our experimental studies on 21 datasets (covering nine scRNA-seq protocols, two species and three tissues) demonstrate that TripletCell outperformed state-of-the-art approaches for cell-type annotation. More importantly, regardless of protocols or species, TripletCell can deliver outstanding and robust performance in annotating different types of cells. TripletCell is freely available at https://github.com/liuyan3056/TripletCell. We believe that TripletCell is a reliable computational tool for accurately annotating various cell types using scRNA-seq data and will be instrumental in assisting the generation of novel biological hypotheses in cell biology.",1,Single-cell RNA sequencing has significantly accelerated the experimental characterization of distinct cell lineages and types in complex tissues and organisms.
Using traditional machine learning and deep learning methods for on- and off-target prediction in CRISPR/Cas9: a review.,37080758,https://pubmed.ncbi.nlm.nih.gov/37080758/,https://doi.org/10.1093/bib/bbad131,"['CRISPR-Cas9', 'Deep Learning', 'Genome Editing', 'Machine Learning', 'Off-Targets', 'On-Targets']","CRISPR/Cas9 (Clustered Regularly Interspaced Short Palindromic Repeats and CRISPR-associated protein 9) is a popular and effective two-component technology used for targeted genetic manipulation. It is currently the most versatile and accurate method of gene and genome editing, which benefits from a large variety of practical applications. For example, in biomedicine, it has been used in research related to cancer, virus infections, pathogen detection, and genetic diseases. Current CRISPR/Cas9 research is based on data-driven models for on- and off-target prediction as a cleavage may occur at non-target sequence locations. Nowadays, conventional machine learning and deep learning methods are applied on a regular basis to accurately predict on-target knockout efficacy and off-target profile of given single-guide RNAs (sgRNAs). In this paper, we present an overview and a comparative analysis of traditional machine learning and deep learning models used in CRISPR/Cas9. We highlight the key research challenges and directions associated with target activity prediction. We discuss recent advances in the sgRNA-DNA sequence encoding used in state-of-the-art on- and off-target prediction models. Furthermore, we present the most popular deep learning neural network architectures used in CRISPR/Cas9 prediction models. Finally, we summarize the existing challenges and discuss possible future investigations in the field of on- and off-target prediction. Our paper provides valuable support for academic and industrial researchers interested in the application of machine learning methods in the field of CRISPR/Cas9 genome editing.",3,CRISPR/Cas9 is the most versatile and accurate method of gene and genome editing.
Large-Scale Docking in the Cloud.,37071086,https://pubmed.ncbi.nlm.nih.gov/37071086/,https://doi.org/10.1021/acs.jcim.3c00031,[],"Molecular docking is a pragmatic approach to exploit protein structures for new ligand discovery, but the growing size of available chemical space is increasingly challenging to screen on in-house computer clusters. We have therefore developed AWS-DOCK, a protocol for running UCSF DOCK in the AWS cloud. Our approach leverages the low cost and scalability of cloud resources combined with a low-molecule-cost docking engine to screen billions of molecules efficiently. We benchmarked our system by screening 50 million HAC 22 molecules against the DRD4 receptor with an average CPU time of around 1 s per molecule. We saw up to 3-fold variations in cost between AWS availability zones. Docking 4.5 billion lead-like molecules, a 7 week calculation on our 1000-core lab cluster, runs in about a week depending on accessible CPUs, in AWS for around $25,000, less than the cost of two new nodes. The cloud docking protocol is described in easy-to-follow steps and may be sufficiently general to be used for other docking programs. All the tools to enable AWS-DOCK are available free to everyone, while DOCK 3.8 is free for academic research.",1,AWS-DOCK is a protocol for running UCSF DOCK in the AWS cloud.
"nRCFV: a new, dataset-size-independent metric to quantify compositional heterogeneity in nucleotide and amino acid datasets.",37046225,https://pubmed.ncbi.nlm.nih.gov/37046225/,https://doi.org/10.1186/s12859-023-05270-8,"['Bioinformatics software', 'Compositional heterogeneity', 'Phylogenetics']","Compositional heterogeneity-when the proportions of nucleotides and amino acids are not broadly similar across the dataset-is a cause of a great number of phylogenetic artefacts. Whilst a variety of methods can identify it post-hoc, few metrics exist to quantify compositional heterogeneity prior to the computationally intensive task of phylogenetic tree reconstruction. Here we assess the efficacy of one such existing, widely used, metric: Relative Composition Frequency Variability (RCFV), using both real and simulated data.",5,Compositional heterogeneity is when proportions of nucleotides and amino acids are not broadly similar across the dataset.
lifex-fiber: an open tool for myofibers generation in cardiac computational models.,37046208,https://pubmed.ncbi.nlm.nih.gov/37046208/,https://doi.org/10.1186/s12859-023-05260-w,"['Cardiac fibers', 'Computational cardiology', 'Finite element methods', 'High-performance computing', 'Mathematical modeling']","Modeling the whole cardiac function involves the solution of several complex multi-physics and multi-scale models that are highly computationally demanding, which call for simpler yet accurate, high-performance computational tools. Despite the efforts made by several research groups, no software for whole-heart fully-coupled cardiac simulations in the scientific community has reached full maturity yet.",3,Modeling the whole cardiac function involves the solution of several complex multi-physics and multi-scale models.
Decomposing mosaic tandem repeats accurately from long reads.,37039842,https://pubmed.ncbi.nlm.nih.gov/37039842/,https://doi.org/10.1093/bioinformatics/btad185,[],"Over the past 30 years, extended tandem repeats (TRs) have been correlated with ∼60 diseases with high odds ratios, and most known TRs consist of single repeat units. However, in the last few years, mosaic TRs composed of different units have been found to be associated with several brain disorders by long-read sequencing techniques. Mosaic TRs are difficult-to-characterize sequence configurations that are usually confirmed by manual inspection. Widely used tools are not designed to solve the mosaic TR problem and often fail to properly decompose mosaic TRs.",1,Mosaic TRs are difficult-to-characterize sequence configurations that are usually confirmed by manual inspection.
Identifying B-cell epitopes using AlphaFold2 predicted structures and pretrained language model.,37039829,https://pubmed.ncbi.nlm.nih.gov/37039829/,https://doi.org/10.1093/bioinformatics/btad187,[],"Identifying the B-cell epitopes is an essential step for guiding rational vaccine development and immunotherapies. Since experimental approaches are expensive and time-consuming, many computational methods have been designed to assist B-cell epitope prediction. However, existing sequence-based methods have limited performance since they only use contextual features of the sequential neighbors while neglecting structural information.",1,Identifying the B-cell epitopes is an essential step for guiding rational vaccine development and immunotherapies.
Activity Map and Transition Pathways of G Protein-Coupled Receptor Revealed by Machine Learning.,37036101,https://pubmed.ncbi.nlm.nih.gov/37036101/,https://doi.org/10.1021/acs.jcim.3c00032,[],"Approximately, one-third of all U.S. Food and Drug Administration approved drugs target G protein-coupled receptors (GPCRs). However, more knowledge of protein structure-activity correlation is required to improve the efficacy of the drugs targeting GPCRs. In this study, we developed a machine learning model to predict the activation state and activity level of the receptors with high prediction accuracy. Furthermore, we applied this model to thousands of molecular dynamics trajectories to correlate residue-level conformational changes of a GPCR to its activity level. Finally, the most probable transition pathway between activation states of a receptor can be identified using the state-activity information. In addition, with this model, we can associate the contribution of each amino acid to the activation process. Using this method, we can design drugs that mainly target principal amino acids driving the transition between activation states of GPCRs. Our advanced method is generalizable to all GPCR classes and provides mechanistic insight into the activation mechanism in the receptors.",3,One-third of all U.S. Food and Drug Administration approved drugs target G protein-coupled receptors (GPCRs) More knowledge of protein structure-activity correlation is
3D-Sensitive Encoding of Pharmacophore Features.,37036083,https://pubmed.ncbi.nlm.nih.gov/37036083/,https://doi.org/10.1021/acs.jcim.2c01623,[],"In the presence of structural data, one sometimes need to compare 3D ligands. We design an overlay-free method to rank order 3D molecules in the pharmacophore feature space. The proposed encoding includes only two fittable parameters, is sparse, and is not too high dimensional. At the cost of an additional parameter, to delineate the binding site from a protein-ligand complex, the method can compare binding sites. The method was benchmarked on the LIT-PCBA data set for ligand-based virtual screening experiments and the sc-PDB and a Vertex data set when comparing binding sites. In similarity searches, the proposed method outperforms an open-source software doing optimal superposition of ligand-based pharmacophores and RDKit's 3D pharmacophore fingerprints. When comparing binding sites, the method is competitive with state of the art approaches. On a single CPU core, up to 374,000 ligand/s or 132,000 binding site/s can be rank ordered. The ""AutoCorrelation of Pharmacophore Features"" open-source software is released at https://github.com/tsudalab/ACP4.",1,The method was benchmarked on the LIT-PCBA data set for ligand-based virtual screening experiments and the sc-PDB and a Vertex data set when comparing binding
"A multi-locus linear mixed model methodology for detecting small-effect QTLs for quantitative traits in MAGIC, NAM, and ROAM populations.",37035553,https://pubmed.ncbi.nlm.nih.gov/37035553/,https://doi.org/10.1016/j.csbj.2023.03.022,"['Linear mixed model', 'Multi-locus model', 'Multiparent advanced generation intercross (MAGIC)', 'Nested association mapping (NAM)', 'Random-open-parent association mapping (ROAM)']","Although multi-parent populations (MPPs) integrate the advantages of linkage and association mapping populations in the genetic dissection of complex traits and especially combine genetic analysis with crop breeding, it is difficult to detect small-effect quantitative trait loci (QTL) for complex traits in multiparent advanced generation intercross (MAGIC), nested association mapping (NAM), and random-open-parent association mapping (ROAM) populations. To address this issue, here we proposed a multi-locus linear mixed model method, namely mppQTL, to detect QTLs, especially small-effect QTLs, in these MPPs. The new method includes two steps. The first is genome-wide scanning based on a single-locus linear mixed model; the P-values are obtained from likelihood-ratio test, the peaks of negative logarithm P-value curve are selected by group-lasso, and all the selected peaks are regarded as potential QTLs. In the second step, all the potential QTLs are placed on a multi-locus linear mixed model, all the effects are estimated using expectation-maximization empirical Bayes algorithm, and all the non-zero effect vectors are further evaluated via likelihood-ratio test for significant QTLs. In Monte Carlo simulation studies, the new method has higher power in QTL detection, lower false positive rate, lower mean absolute deviation for QTL position estimate, and lower mean squared error for the estimate of QTL size (r",1,The new method includes two steps.. The first is genome-wide scanning based on a single-locus linear mixed model.
CDT-CAD: Context-Aware Deformable Transformers for End-to-End Chest Abnormality Detection on X-Ray Images.,37030846,https://pubmed.ncbi.nlm.nih.gov/37030846/,https://doi.org/10.1109/TCBB.2023.3258455,[],"Deep learning methods have achieved great success in medical image analysis domain. However, most of them suffer from slow convergency and high computing cost, which prevents their further widely usage in practical scenarios. Moreover, it has been proved that exploring and embedding context knowledge in deep network can significantly improve accuracy. To emphasize these tips, we present CDT-CAD, i.e., context-aware deformable transformers for end-to-end chest abnormality detection on X-Ray images. CDT-CAD firstly constructs an iterative context-aware feature extractor, which not only enlarges receptive fields to encode multi-scale context information via dilated context encoding blocks, but also captures unique and scalable feature variation patterns in wavelet frequency domain via frequency pooling blocks. Afterwards, a deformable transformer detector on the extracted context features is built to accurately classify disease categories and locate regions, where a small set of key points are sampled, thus leading the detector to focus on informative feature subspace and accelerate convergence speed. Through comparative experiments on Vinbig Chest and Chest Det 10 Datasets, CDT-CAD demonstrates its effectiveness in recognizing chest abnormities and outperforms 1.4% and 6.0% than the existing methods in AP",1,Deep learning methods have achieved great success in medical image analysis domain.. Most of them suffer from slow convergency and high computing cost.
iSnoDi-MDRF: Identifying snoRNA-Disease Associations Based on Multiple Biological Data by Ranking Framework.,37030816,https://pubmed.ncbi.nlm.nih.gov/37030816/,https://doi.org/10.1109/TCBB.2023.3258448,[],"Accumulating evidence indicates that the dysregulation of small nucleolar RNAs (snoRNAs) is relevant with diseases. Identifying snoRNA-disease associations by computational methods is desired for biologists, which can save considerable costs and time compared biological experiments. However, it still faces some challenges as followings: (i) Many snoRNAs are detected in recent years, but only a few snoRNAs have been proved to be associated with diseases; (ii) Computational predictors trained with only a few known snoRNA-disease associations fail to accurately identify the snoRNA-disease associations. In this study, we propose a ranking framework, called iSnoDi-MDRF, to identify potential snoRNA-disease associations based on multiple biological data, which has the following highlights: (i) iSnoDi-MDRF integrates ranking framework, which is not only able to identify potential associations between known snoRNAs and diseases, but also can identify diseases associated with new snoRNAs. (ii) Known gene-disease associations are employed to help train a mature model for predicting snoRNA-disease association. Experimental results illustrate that iSnoDi-MDRF is very suitable for identifying potential snoRNA-disease associations. The web server of iSnoDi-MDRF predictor is freely available at http://bliulab.net/iSnoDi-MDRF/.",1,Identifying snoRNA-disease associations by computational methods is desired for biologists.
Deep Factor Learning for Accurate Brain Neuroimaging Data Analysis on Discrimination for Structural MRI and Functional MRI.,37028037,https://pubmed.ncbi.nlm.nih.gov/37028037/,https://doi.org/10.1109/TCBB.2023.3252577,[],"Analysis of neuroimaging data (e.g., Magnetic Resonance Imaging, structural and functional MRI) plays an important role in monitoring brain dynamics and probing brain structures. Neuroimaging data are multi-featured and non-linear by nature, and it is a natural way to organise these data as tensors prior to performing automated analyses such as discrimination of neurological disorders like Parkinson's Disease (PD) and Attention Deficit and Hyperactivity Disorder (ADHD). However, the existing approaches are often subject to performance bottlenecks (e.g., conventional feature extraction and deep learning based feature construction), as these can lose the structural information that correlates multiple data dimensions or/and demands excessive empirical and application-specific settings. This study proposes a Deep Factor Learning model on a Hilbert Basis tensor (namely, HB-DFL) to automatically derive latent low-dimensional and concise factors of tensors. This is achieved through the application of multiple Convolutional Neural Networks (CNNs) in a non-linear manner along all possible dimensions with no assumed a priori knowledge. HB-DFL leverages the Hilbert basis tensor to enhance the stability of the solution by regularizing the core tensor to allow any component in a certain domain to interact with any component in the other dimensions. The final multi-domain features are handled through another multi-branch CNN to achieve reliable classification, exemplified here using MRI discrimination as a typical case. A case study of MRI discrimination has been performed on public MRI datasets for discrimination of PD and ADHD. Results indicate that 1) HB-DFL outperforms the counterparts in terms of FIT, mSIR and stability (mSC and umSC) of factor learning; 2) HB-DFL identifies PD and ADHD with an accuracy significantly higher than state-of-the-art methods do. Overall, HB-DFL has significant potentials for neuroimaging data analysis applications with its stability of automatic construction of structural features.",3,Neuroimaging data are multi-featured and non-linear by nature.. The existing approaches are often subject to performance bottlenecks.
Triplet-Net Classification of Contiguous Stem Cell Microscopy Images.,37027755,https://pubmed.ncbi.nlm.nih.gov/37027755/,https://doi.org/10.1109/TCBB.2023.3247957,[],"Cellular microscopy imaging is a common form of data acquisition for biological experimentation. Observation of gray-level morphological features allows for the inference of useful biological information such as cellular health and growth status. Cellular colonies can contain multiple cell types, making colony level classification very difficult. Additionally, cell types growing in a hierarchical, downstream fashion, can often look visually similar, although biologically distinct. In this paper, it is determined empirically that traditional deep Convolutional Neural Networks (CNN) and classical object recognition techniques are not sufficient to distinguish between these subtle visual differences, resulting in misclassifications. Instead, Triplet-net CNN learning is employed in a hierarchical classification scheme to improve the ability of the model to discern distinct, fine-grain features of two commonly confused morphological image-patch classes, namely Dense and Spread colonies. The Triplet-net method improves classification accuracy over a four-class deep neural network by  ∼  3 %, a value that was determined to be statistically significant, as well as existing state-of-the-art image patch classification approaches and standard template matching. These findings allow for the accurate classification of multi-class cell colonies with contiguous boundaries, and increased reliability and efficiency of automated, high-throughput experimental quantification using non-invasive microscopy.",1,Cellular microscopy imaging is a common form of data acquisition for biological experimentation.
Discharge summary hospital course summarisation of in patient Electronic Health Record text with clinical concept guided deep pre-trained Transformer models.,37023846,https://pubmed.ncbi.nlm.nih.gov/37023846/,https://doi.org/10.1016/j.jbi.2023.104358,"['Clinical natural language processing', 'Clinical text summarisation', 'Pre-trained, deep learning, fine-tuned models for clinical summarisation']","Brief Hospital Course (BHC) summaries are succinct summaries of an entire hospital encounter, embedded within discharge summaries, written by senior clinicians responsible for the overall care of a patient. Methods to automatically produce summaries from inpatient documentation would be invaluable in reducing clinician manual burden of summarising documents under high time-pressure to admit and discharge patients. Automatically producing these summaries from the inpatient course, is a complex, multi-document summarisation task, as source notes are written from various perspectives (e.g. nursing, doctor, radiology), during the course of the hospitalisation. We demonstrate a range of methods for BHC summarisation demonstrating the performance of deep learning summarisation models across extractive and abstractive summarisation scenarios. We also test a novel ensemble extractive and abstractive summarisation model that incorporates a medical concept ontology (SNOMED) as a clinical guidance signal and shows superior performance in 2 real-world clinical data sets.",2,Brief Hospital Course (BHC) summaries are succinct summaries of an entire hospital encounter.
"SpliceAI-10k calculator for the prediction of pseudoexonization, intron retention, and exon deletion.",37021934,https://pubmed.ncbi.nlm.nih.gov/37021934/,https://doi.org/10.1093/bioinformatics/btad179,[],"SpliceAI is a widely used splicing prediction tool and its most common application relies on the maximum delta score to assign variant impact on splicing. We developed the SpliceAI-10k calculator (SAI-10k-calc) to extend use of this tool to predict: the splicing aberration type including pseudoexonization, intron retention, partial exon deletion, and (multi)exon skipping using a 10 kb analysis window; the size of inserted or deleted sequence; the effect on reading frame; and the altered amino acid sequence. SAI-10k-calc has 95% sensitivity and 96% specificity for predicting variants that impact splicing, computed from a control dataset of 1212 single-nucleotide variants (SNVs) with curated splicing assay results. Notably, it has high performance (≥84% accuracy) for predicting pseudoexon and partial intron retention. The automated amino acid sequence prediction allows for efficient identification of variants that are expected to result in mRNA nonsense-mediated decay or translation of truncated proteins.",1,SpliceAI is a widely used splicing prediction tool.
MARSY: a multitask deep-learning framework for prediction of drug combination synergy scores.,37021933,https://pubmed.ncbi.nlm.nih.gov/37021933/,https://doi.org/10.1093/bioinformatics/btad177,[],"Combination therapies have emerged as a treatment strategy for cancers to reduce the probability of drug resistance and to improve outcomes. Large databases curating the results of many drug screening studies on preclinical cancer cell lines have been developed, capturing the synergistic and antagonistic effects of combination of drugs in different cell lines. However, due to the high cost of drug screening experiments and the sheer size of possible drug combinations, these databases are quite sparse. This necessitates the development of transductive computational models to accurately impute these missing values.",2,Combination therapies have emerged as a treatment strategy for cancers to reduce the probability of drug resistance and to improve outcomes.
NetPro: Neighborhood Interaction-Based Drug Repositioning via Label Propagation.,37018341,https://pubmed.ncbi.nlm.nih.gov/37018341/,https://doi.org/10.1109/TCBB.2023.3234331,[],"Drug repositioning is an important approach for predicting new disease indications of the existing drugs in drug discovery. A great progress has been achieved in drug repositioning. However, effectively utilizing the localized neighborhood interaction features of drug and disease in drug-disease associations remains challenging. This paper proposes a neighborhood interaction-based method called NetPro for drug repositioning via label propagation. In NetPro, we first formulate the known drug-disease associations, various disease and drug similarities from different perspectives to construct drug-drug and disease-disease networks. Meanwhile we employ the nearest neighbors and their interactions in the constructed networks to devise a new approach for computing drug similarity and disease similarity. To implement the prediction of new drugs or diseases, a preprocessing step is applied to renew the known drug-disease associations using our calculated drug and disease similarities. We then employ a label propagation model to predict drug-disease associations by the drug and disease linear neighborhood similarities derived from the renewed drug-disease associations. The experimental results on three benchmark datasets show that NetPro can effectively identify potential drug-disease associations and achieve better prediction performance than the existing methods. Case studies further demonstrate that NetPro is capable of predicting promising candidate disease indications for drugs.",1,Neighborhood interaction-based method called NetPro for drug repositioning via label propagation.
High Net Information Density DNA Data Storage by the MOPE Encoding Algorithm.,37015121,https://pubmed.ncbi.nlm.nih.gov/37015121/,https://doi.org/10.1109/TCBB.2023.3263521,[],"DNA has recently been recognized as an attractive storage medium due to its high reliability, capacity, and durability. However, encoding algorithms that simply map binary data to DNA sequences have the disadvantages of low net information density and high synthesis cost. Therefore, this paper proposes an efficient, feasible, and highly robust encoding algorithm called MOPE (Modified Barnacles Mating Optimizer and Payload Encoding). The Modified Barnacles Mating Optimizer (MBMO) algorithm is used to construct the non-payload coding set, and the Payload Encoding (PE) algorithm is used to encode the payload. The results show that the lower bound of the non-payload coding set constructed by the MBMO algorithm is 3%-18% higher than the optimal result of previous work, and theoretical analysis shows that the designed PE algorithm has a net information density of 1.90 bits/nt, which is close to the ideal information capacity of 2 bits per nucleotide. The proposed MOPE encoding algorithm with high net information density and satisfying constraints can not only effectively reduce the cost of DNA synthesis and sequencing but also reduce the occurrence of errors during DNA storage.",2,"DNA has recently been recognized as an attractive storage medium due to its high reliability, capacity, and durability."
PreTP-2L: identification of therapeutic peptides and their types using two-layer ensemble learning framework.,37010503,https://pubmed.ncbi.nlm.nih.gov/37010503/,https://doi.org/10.1093/bioinformatics/btad125,[],"Therapeutic peptides play an important role in immune regulation. Recently various therapeutic peptides have been used in the field of medical research, and have great potential in the design of therapeutic schedules. Therefore, it is essential to utilize the computational methods to predict the therapeutic peptides. However, the therapeutic peptides cannot be accurately predicted by the existing predictors. Furthermore, chaotic datasets are also an important obstacle of the development of this important field. Therefore, it is still challenging to develop a multi-classification model for identification of therapeutic peptides and their types.",2,Therapeutic peptides play an important role in immune regulation.. The therapeutic peptides cannot be accurately predicted by the existing predictors.
"DNAscan2: a versatile, scalable, and user-friendly analysis pipeline for human next-generation sequencing data.",37010501,https://pubmed.ncbi.nlm.nih.gov/37010501/,https://doi.org/10.1093/bioinformatics/btad152,[],"The current widespread adoption of next-generation sequencing (NGS) in all branches of basic research and clinical genetics fields means that users with highly variable informatics skills, computing facilities and application purposes need to process, analyse, and interpret NGS data. In this landscape, versatility, scalability, and user-friendliness are key characteristics for an NGS analysis software. We developed DNAscan2, a highly flexible, end-to-end pipeline for the analysis of NGS data, which (i) can be used for the detection of multiple variant types, including SNVs, small indels, transposable elements, short tandem repeats, and other large structural variants; (ii) covers all standard steps of NGS analysis, from quality control of raw data and genome alignment to variant calling, annotation, and generation of reports for the interpretation and prioritization of results; (iii) is highly adaptable as it can be deployed and run via either a graphic user interface for non-bioinformaticians and a command line tool for personal computer usage; (iv) is scalable as it can be executed in parallel as a Snakemake workflow, and; (v) is computationally efficient by minimizing RAM and CPU time requirements.",1,"DNAscan2 is a highly flexible, end-to-end pipeline for the analysis of NGS data."
SCREE: a comprehensive pipeline for single-cell multi-modal CRISPR screen data processing and analysis.,37000175,https://pubmed.ncbi.nlm.nih.gov/37000175/,https://doi.org/10.1093/bib/bbad123,"['analyses pipeline', 'gene regulatory circuits', 'perturbation efficiency', 'single-cell CRISPR screens']","Single-cell CRISPR screens have been widely used to investigate gene regulatory circuits in diverse biological systems. The recent development of single-cell CRISPR screens has enabled multimodal profiling of perturbed cells with both gene expression, chromatin accessibility and protein levels. However, current methods cannot meet the analysis requirements of different types of data and have limited functions. Here, we introduce Single-cell CRISPR screens data analysEs and perturbation modEling (SCREE) as a comprehensive and flexible pipeline to facilitate the analyses of various types of single-cell CRISPR screens data. SCREE performs read alignment, sgRNA assignment, quality control, clustering and visualization, perturbation enrichment evaluation, perturbation efficiency modeling, gene regulatory score calculation and functional analyses of perturbations for single-cell CRISPR screens with both RNA, ATAC and multimodal readout. SCREE is available at https://github.com/wanglabtongji/SCREE.",1,Single-cell CRISPR screens have been widely used to investigate gene regulatory circuits in diverse biological systems.
Explainable domain transfer of distant supervised cancer subtyping model via imaging-based rules extraction.,36990587,https://pubmed.ncbi.nlm.nih.gov/36990587/,https://doi.org/10.1016/j.artmed.2023.102522,"['Cancer subtyping', 'Domain transfer', 'Explainability', 'Image Clustering', 'Radiomics', 'Rule extraction']","Image texture analysis has for decades represented a promising opportunity for cancer assessment and disease progression evaluation, evolving in a discipline, i.e., radiomics. However, the road to a complete translation into clinical practice is still hampered by intrinsic limitations. As purely supervised classification models fail in devising robust imaging-based biomarkers for prognosis, cancer subtyping approaches would benefit from the employment of distant supervision, for instance exploiting survival/recurrence information. In this work, we assessed, tested, and validated the domain-generality of our previously proposed Distant Supervised Cancer Subtyping model on Hodgkin Lymphoma. We evaluate the model performance on two independent datasets coming from two hospitals, comparing and analyzing the results. Although successful and consistent, the comparison confirmed the instability of radiomics due to an across-center lack of reproducibility, leading to explainable results in one center and poor interpretability in the other. We thus propose a Random Forest-based Explainable Transfer Model for testing the domain-invariance of imaging biomarkers extracted from retrospective cancer subtyping. In doing so, we tested the predictive ability of cancer subtyping in a validation and perspective setting, which led to successful results and supported the domain-generality of the proposed approach. On the other hand, the extraction of decision rules enables to draw of risk factors and robust biomarkers to inform clinical decisions. This work shows the potentialities of the Distant Supervised Cancer Subtyping model to be further evaluated in larger multi-center datasets, to reliably translate radiomics into medical practice. The code is available at this GitHub repository.",1,Image texture analysis has for decades represented a promising opportunity for cancer assessment and disease progression evaluation.
REDfold: accurate RNA secondary structure prediction using residual encoder-decoder network.,36977986,https://pubmed.ncbi.nlm.nih.gov/36977986/,https://doi.org/10.1186/s12859-023-05238-8,"['Deep learning', 'Encoder-decoder network', 'Pseudoknot structure', 'RNA secondary structure']","As the RNA secondary structure is highly related to its stability and functions, the structure prediction is of great value to biological research. The traditional computational prediction for RNA secondary prediction is mainly based on the thermodynamic model with dynamic programming to find the optimal structure. However, the prediction performance based on the traditional approach is unsatisfactory for further research. Besides, the computational complexity of the structure prediction using dynamic programming is [Formula: see text]; it becomes [Formula: see text] for RNA structure with pseudoknots, which is computationally impractical for large-scale analysis.",1,The structure prediction is of great value to biological research.
Integrative analysis of individual-level data and high-dimensional summary statistics.,36964712,https://pubmed.ncbi.nlm.nih.gov/36964712/,https://doi.org/10.1093/bioinformatics/btad156,[],"Researchers usually conduct statistical analyses based on models built on raw data collected from individual participants (individual-level data). There is a growing interest in enhancing inference efficiency by incorporating aggregated summary information from other sources, such as summary statistics on genetic markers' marginal associations with a given trait generated from genome-wide association studies. However, combining high-dimensional summary data with individual-level data using existing integrative procedures can be challenging due to various numeric issues in optimizing an objective function over a large number of unknown parameters.",1,Researchers usually conduct statistical analyses based on models built on raw data collected from individual participants.
Complete sequence verification of plasmid DNA using the Oxford Nanopore Technologies' MinION device.,36964503,https://pubmed.ncbi.nlm.nih.gov/36964503/,https://doi.org/10.1186/s12859-023-05226-y,"['Cell therapy', 'Long-read sequencing', 'MinION', 'Plasmid sequencing']","Sequence verification is essential for plasmids used as critical reagents or therapeutic products. Typically, high-quality plasmid sequence is achieved through capillary-based Sanger sequencing, requiring customized sets of primers for each plasmid. This process can become expensive, particularly for applications where the validated sequence needs to be produced within a regulated and quality-controlled environment for downstream clinical research applications.",5, Sequence verification is essential for plasmids used as critical reagents or therapeutic products.
Benchmark of embedding-based methods for accurate and transferable prediction of drug response.,36961310,https://pubmed.ncbi.nlm.nih.gov/36961310/,https://doi.org/10.1093/bib/bbad098,"['anti-cancer compound', 'drug response', 'variational autoencoder (VAEN)']","Prediction of therapy response has been a major challenge in cancer precision medicine due to the extensive tumor heterogeneity. Recently, several deep learning methods have been developed to predict drug response by utilizing various omics data. Most of them train models by using the drug-response screening data generated from cell lines and then use these models to predict response in cancer patient data. In this study, we focus on and evaluate deep learning methods using transcriptome data for the long-standing question of personalized drug-response prediction. We developed an embedding-based approach for drug-response prediction and benchmarked similar methods for their performance. For all methods, we used pretreatment transcriptome data to train models and then conducted a comprehensive evaluation and comparison of the models using cross-panels, cross-datasets and target genes. We further validated the methods using three independent datasets assessing multiple compounds for their predictive capability of drug response, survival outcome and cell line status. As a result, the methods building on gene embeddings had an overall competitive performance with reduced overfitting when we applied evaluation parameters for model fitting as well as the correlation with clinical outcomes in the validation data. We further developed an ensemble model to combine the results from the three most competitive methods for an overall prediction. Finally, we developed DrVAEN (https://bioinfo.uth.edu/drvaen), a user-friendly and easy-accessible web-server that hosts all these methods for drug-response prediction and model comparison for broad use in cancer research, method evaluation and drug development.",3,Several deep learning methods have been developed to predict drug response by utilizing various omics data.
In vitro-in silico correlation of three-dimensional turbulent flows in an idealized mouth-throat model.,36952557,https://pubmed.ncbi.nlm.nih.gov/36952557/,https://doi.org/10.1371/journal.pcbi.1010537,[],"There exists an ongoing need to improve the validity and accuracy of computational fluid dynamics (CFD) simulations of turbulent airflows in the extra-thoracic and upper airways. Yet, a knowledge gap remains in providing experimentally-resolved 3D flow benchmarks with sufficient data density and completeness for useful comparison with widely-employed numerical schemes. Motivated by such shortcomings, the present work details to the best of our knowledge the first attempt to deliver in vitro-in silico correlations of 3D respiratory airflows in a generalized mouth-throat model and thereby assess the performance of Large Eddy Simulations (LES) and Reynolds-Averaged Numerical Simulations (RANS). Numerical predictions are compared against 3D volumetric flow measurements using Tomographic Particle Image Velocimetry (TPIV) at three steady inhalation flowrates varying from shallow to deep inhalation conditions. We find that a RANS k-ω SST model adequately predicts velocity flow patterns for Reynolds numbers spanning 1'500 to 7'000, supporting results in close proximity to a more computationally-expensive LES model. Yet, RANS significantly underestimates turbulent kinetic energy (TKE), thus underlining the advantages of LES as a higher-order turbulence modeling scheme. In an effort to bridge future endevours across respiratory research disciplines, we provide end users with the present in vitro-in silico correlation data for improved predictive CFD models towards inhalation therapy and therapeutic or toxic dosimetry endpoints.",1,There exists an ongoing need to improve the validity and accuracy of computational fluid dynamics (CFD) simulations of turbulent airflows in the extra-thoracic and upper airways.
Vina-GPU 2.0: Further Accelerating AutoDock Vina and Its Derivatives with Graphics Processing Units.,36941232,https://pubmed.ncbi.nlm.nih.gov/36941232/,https://doi.org/10.1021/acs.jcim.2c01504,[],"Modern drug discovery typically faces large virtual screens from huge compound databases where multiple docking tools are involved for meeting various real scenes or improving the precision of virtual screens. Among these tools, AutoDock Vina and its numerous derivatives are the most popular and have become the standard pipeline for molecular docking in modern drug discovery. Our recent Vina-GPU method realized 14-fold acceleration against AutoDock Vina on a piece of NVIDIA RTX 3090 GPU in one virtual screening case. Further speedup of AutoDock Vina and its derivatives with graphics processing units (GPUs) is beneficial to systematically push their popularization in large-scale virtual screens due to their high benefit-cost ratio and easy operation for users. Thus, we proposed the Vina-GPU 2.0 method to further accelerate AutoDock Vina and the most common derivatives with new docking algorithms (QuickVina 2 and QuickVina-W) with GPUs. Caused by the discrepancy in their docking algorithms, our Vina-GPU 2.0 adopts different GPU acceleration strategies. In virtual screening for two hot protein kinase targets, RIPK1 and RIPK3, from the DrugBank database, our Vina-GPU 2.0 reaches an average of 65.6-fold, 1.4-fold, and 3.6-fold docking acceleration against the original AutoDock Vina, QuickVina 2, and QuickVina-W while ensuring their comparable docking accuracy. In addition, we develop a friendly and installation-free graphical user interface tool for their convenient usage. The codes and tools of Vina-GPU 2.0 are freely available at https://github.com/DeltaGroupNJUPT/Vina-GPU-2.0, coupled with explicit instructions and examples.",4,AutoDock Vina and its numerous derivatives are the most popular and have become the standard pipeline for molecular docking in modern drug discovery.
SoCube: an innovative end-to-end doublet detection algorithm for analyzing scRNA-seq data.,36941114,https://pubmed.ncbi.nlm.nih.gov/36941114/,https://doi.org/10.1093/bib/bbad104,"['doublet detection', 'feature embedding', 'omics', 'scRNA-seq']","Doublets formed during single-cell RNA sequencing (scRNA-seq) severely affect downstream studies, such as differentially expressed gene analysis and cell trajectory inference, and limit the cellular throughput of scRNA-seq. Several doublet detection algorithms are currently available, but their generalization performance could be further improved due to the lack of effective feature-embedding strategies with suitable model architectures. Therefore, SoCube, a novel deep learning algorithm, was developed to precisely detect doublets in various types of scRNA-seq data. SoCube (i) proposed a novel 3D composite feature-embedding strategy that embedded latent gene information and (ii) constructed a multikernel, multichannel CNN-ensembled architecture in conjunction with the feature-embedding strategy. With its excellent performance on benchmark evaluation and several downstream tasks, it is expected to be a powerful algorithm to detect and remove doublets in scRNA-seq data. SoCube is freely provided as an end-to-end tool on the Python official package site PyPi (https://pypi.org/project/socube/) and open-source on GitHub (https://github.com/idrblab/socube/).",2,"Doublets formed during single-cell RNA sequencing (scRNA-seq) severely affect downstream studies, such as differentially expressed gene analysis and cell trajectory inference."
TCMFP: a novel herbal formula prediction method based on network target's score integrated with semi-supervised learning genetic algorithms.,36941113,https://pubmed.ncbi.nlm.nih.gov/36941113/,https://doi.org/10.1093/bib/bbad102,"['genetic algorithm', 'herb combination', 'herbal formula', 'network pharmacology', 'traditional Chinese medicine (TCM)']","Traditional Chinese medicine (TCM) has accumulated thousands years of knowledge in herbal therapy, but the use of herbal formulas is still characterized by reliance on personal experience. Due to the complex mechanism of herbal actions, it is challenging to discover effective herbal formulas for diseases by integrating the traditional experiences and modern pharmacological mechanisms of multi-target interactions. In this study, we propose a herbal formula prediction approach (TCMFP) combined therapy experience of TCM, artificial intelligence and network science algorithms to screen optimal herbal formula for diseases efficiently, which integrates a herb score (Hscore) based on the importance of network targets, a pair score (Pscore) based on empirical learning and herbal formula predictive score (FmapScore) based on intelligent optimization and genetic algorithm. The validity of Hscore, Pscore and FmapScore was verified by functional similarity and network topological evaluation. Moreover, TCMFP was used successfully to generate herbal formulae for three diseases, i.e. the Alzheimer's disease, asthma and atherosclerosis. Functional enrichment and network analysis indicates the efficacy of targets for the predicted optimal herbal formula. The proposed TCMFP may provides a new strategy for the optimization of herbal formula, TCM herbs therapy and drug development.",3,Traditional Chinese medicine (TCM) has accumulated thousands of years of knowledge in herbal therapy.
Trends and opportunities in computable clinical phenotyping: A scoping review.,36933631,https://pubmed.ncbi.nlm.nih.gov/36933631/,https://doi.org/10.1016/j.jbi.2023.104335,"['Cohort selection', 'Computable phenotype', 'Precision medicine', 'Precision oncology']","Identifying patient cohorts meeting the criteria of specific phenotypes is essential in biomedicine and particularly timely in precision medicine. Many research groups deliver pipelines that automatically retrieve and analyze data elements from one or more sources to automate this task and deliver high-performing computable phenotypes. We applied a systematic approach based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines to conduct a thorough scoping review on computable clinical phenotyping. Five databases were searched using a query that combined the concepts of automation, clinical context, and phenotyping. Subsequently, four reviewers screened 7960 records (after removing over 4000 duplicates) and selected 139 that satisfied the inclusion criteria. This dataset was analyzed to extract information on target use cases, data-related topics, phenotyping methodologies, evaluation strategies, and portability of developed solutions. Most studies supported patient cohort selection without discussing the application to specific use cases, such as precision medicine. Electronic Health Records were the primary source in 87.1 % (N = 121) of all studies, and International Classification of Diseases codes were heavily used in 55.4 % (N = 77) of all studies, however, only 25.9 % (N = 36) of the records described compliance with a common data model. In terms of the presented methods, traditional Machine Learning (ML) was the dominant method, often combined with natural language processing and other approaches, while external validation and portability of computable phenotypes were pursued in many cases. These findings revealed that defining target use cases precisely, moving away from sole ML strategies, and evaluating the proposed solutions in the real setting are essential opportunities for future work. There is also momentum and an emerging need for computable phenotyping to support clinical and epidemiological research and precision medicine.",2,Identifying patient cohorts meeting the criteria of specific phenotypes is essential in biomedicine and particularly timely in precision medicine.
Ten simple rules for designing and conducting undergraduate replication projects.,36928436,https://pubmed.ncbi.nlm.nih.gov/36928436/,https://doi.org/10.1371/journal.pcbi.1010957,[],"Conducting a replication study is a valuable way for undergraduate students to learn about the scientific process and gain research experience. By promoting the evaluation of existing studies to confirm their reliability, replications play a unique, though often underappreciated, role in the scientific enterprise. Involving students early in this process can help make replication mainstream among the new generation of scientists. Beyond their benefit to science, replications also provide an invaluable learning ground for students, from encouraging the development of critical thinking to emphasizing the importance of details and honing research skills. In this piece, we outline 10 simple rules for designing and conducting undergraduate replication projects, from conceptualization to implementation and dissemination. We hope that these guidelines can help educators provide students with a meaningful and constructive pedagogical experience, without compromising the scientific value of the replication project, therefore ensuring robust, valuable contributions to our understanding of the world.",1,Students can help make replication mainstream among the new generation of scientists.
Molecular effects of site-specific phosphate-methylated primer on the structure and motions of Taq DNA polymerase.,36923470,https://pubmed.ncbi.nlm.nih.gov/36923470/,https://doi.org/10.1016/j.csbj.2023.02.043,"['DNA polymerase', 'Methyl phosphotriester', 'Molecular dynamics', 'PCR', 'Primer']","Polymerase chain reaction (PCR) is a powerful molecular biology assay for gene detection and quantification. Conventional DNA primers for PCR often suffer from poor sensitivity in specific gene detection. Recently, oligonucleotides containing methyl phosphotriester (MPTE-DNA) have been developed with enhanced DNA hybridization and improved gene detection sensitivity. Yet, site-specific MPTE-modifications on DNA primers have been reported to affect PCR amplification efficiencies while the detailed mechanism remains elusive. Here, we utilized molecular dynamics (MD) simulation to examine the effects of site-specific MPTE-modified primers on the structure and motions of DNA/Taq polymerase complexes. All tested MPTE-DNA/Taq complexes exhibited RMSD values below 2 Å, indicating insignificant effects of all methylation sites on the complex stability. The energetic and hydrogen-bonding analyses suggest minor effects of methylation at t-3, t-4, t-6, and t-7 positions on the DNA-Taq interaction. Principal component analyses further reveal that only t-3, and t-7 methylations preserve the motions of the Taq thumb domain. The site-specific methylation affects the interaction between DNA and the surrounding protein residues, resulting in allosteric-like effects on the DNA/Taq complex. The MD data complement the best experimentally observed PCR efficacies for the t-3 and t-7 positions among all tested MPTE-primers. The unveiled molecular insights can benefit the design of novel PCR primers for improving genetic testing platforms.",1,Polymerase chain reaction (PCR) is a powerful molecular biology assay for gene detection and quantification.
Inter-domain distance prediction based on deep learning for domain assembly.,36920090,https://pubmed.ncbi.nlm.nih.gov/36920090/,https://doi.org/10.1093/bib/bbad100,"['deep learning', 'domain assembly', 'inter-domain distance', 'multi-domain protein']","AlphaFold2 achieved a breakthrough in protein structure prediction through the end-to-end deep learning method, which can predict nearly all single-domain proteins at experimental resolution. However, the prediction accuracy of full-chain proteins is generally lower than that of single-domain proteins because of the incorrect interactions between domains. In this work, we develop an inter-domain distance prediction method, named DeepIDDP. In DeepIDDP, we design a neural network with attention mechanisms, where two new inter-domain features are used to enhance the ability to capture the interactions between domains. Furthermore, we propose a data enhancement strategy termed DPMSA, which is employed to deal with the absence of co-evolutionary information on targets. We integrate DeepIDDP into our previously developed domain assembly method SADA, termed SADA-DeepIDDP. Tested on a given multi-domain benchmark dataset, the accuracy of SADA-DeepIDDP inter-domain distance prediction is 11.3% and 21.6% higher than trRosettaX and trRosetta, respectively. The accuracy of the domain assembly model is 2.5% higher than that of SADA. Meanwhile, we reassemble 68 human multi-domain protein models with TM-score ≤ 0.80 from the AlphaFold protein structure database, where the average TM-score is improved by 11.8% after the reassembly by our method. The online server is at http://zhanglab-bioinf.com/DeepIDDP/.",1,DeepIDDP is a neural network with attention mechanisms.. It can predict nearly all single-domain proteins at experimental resolution.
"Can We Quickly Learn to ""Translate"" Bioactive Molecules with Transformer Models?",36914216,https://pubmed.ncbi.nlm.nih.gov/36914216/,https://doi.org/10.1021/acs.jcim.2c01618,[],"Meaningful exploration of the chemical space of druglike molecules in drug design is a highly challenging task due to a combinatorial explosion of possible modifications of molecules. In this work, we address this problem with transformer models, a type of machine learning (ML) model originally developed for machine translation. By training transformer models on pairs of similar bioactive molecules from the public ChEMBL data set, we enable them to learn medicinal-chemistry-meaningful, context-dependent transformations of molecules, including those absent from the training set. By retrospective analysis on the performance of transformer models on ChEMBL subsets of ligands binding to COX2, DRD2, or HERG protein targets, we demonstrate that the models can generate structures identical or highly similar to most active ligands, despite the models having not seen any ligands active against the corresponding protein target during training. Our work demonstrates that human experts working on hit expansion in drug design can easily and quickly employ transformer models, originally developed to translate texts from one natural language to another, to ""translate"" from known molecules active against a given protein target to novel molecules active against the same target.",3,Transformers are a type of machine learning (ML) model originally developed for machine translation.
First passage time analysis of spatial mutation patterns reveals sub-clonal evolutionary dynamics in colorectal cancer.,36913406,https://pubmed.ncbi.nlm.nih.gov/36913406/,https://doi.org/10.1371/journal.pcbi.1010952,[],"The signature of early cancer dynamics on the spatial arrangement of tumour cells is poorly understood, and yet could encode information about how sub-clones grew within the expanding tumour. Novel methods of quantifying spatial tumour data at the cellular scale are required to link evolutionary dynamics to the resulting spatial architecture of the tumour. Here, we propose a framework using first passage times of random walks to quantify the complex spatial patterns of tumour cell population mixing. First, using a simple model of cell mixing we demonstrate how first passage time statistics can distinguish between different pattern structures. We then apply our method to simulated patterns of mutated and non-mutated tumour cell population mixing, generated using an agent-based model of expanding tumours, to explore how first passage times reflect mutant cell replicative advantage, time of emergence and strength of cell pushing. Finally, we explore applications to experimentally measured human colorectal cancer, and estimate parameters of early sub-clonal dynamics using our spatial computational model. We infer a wide range of sub-clonal dynamics, with mutant cell division rates varying between 1 and 4 times the rate of non-mutated cells across our sample set. Some mutated sub-clones emerged after as few as 100 non-mutant cell divisions, and others only after 50,000 divisions. The majority were consistent with boundary driven growth or short-range cell pushing. By analysing multiple sub-sampled regions in a small number of samples, we explore how the distribution of inferred dynamics could inform about the initial mutational event. Our results demonstrate the efficacy of first passage time analysis as a new methodology in spatial analysis of solid tumour tissue, and suggest that patterns of sub-clonal mixing can provide insights into early cancer dynamics.",1,The signature of early cancer dynamics on the spatial arrangement of tumour cells is poorly understood.. Yet could encode information about how sub-clones grew within the expanding tumour.
ExamPle: explainable deep learning framework for the prediction of plant small secreted peptides.,36897030,https://pubmed.ncbi.nlm.nih.gov/36897030/,https://doi.org/10.1093/bioinformatics/btad108,[],"Plant Small Secreted Peptides (SSPs) play an important role in plant growth, development, and plant-microbe interactions. Therefore, the identification of SSPs is essential for revealing the functional mechanisms. Over the last few decades, machine learning-based methods have been developed, accelerating the discovery of SSPs to some extent. However, existing methods highly depend on handcrafted feature engineering, which easily ignores the latent feature representations and impacts the predictive performance.",1,"Plant Small Secreted Peptides (SSPs) play an important role in plant growth, development, and plant-microbe interactions."
SLEMM: million-scale genomic predictions with window-based SNP weighting.,36897019,https://pubmed.ncbi.nlm.nih.gov/36897019/,https://doi.org/10.1093/bioinformatics/btad127,[],The amount of genomic data is increasing exponentially. Using many genotyped and phenotyped individuals for genomic prediction is appealing yet challenging.,1,The amount of genomic data is increasing exponentially.
Protein phosphorylation database and prediction tools.,36896955,https://pubmed.ncbi.nlm.nih.gov/36896955/,https://doi.org/10.1093/bib/bbad090,"['database', 'post-translational modification', 'predictor', 'protein phosphorylation']","Protein phosphorylation, one of the main protein post-translational modifications, is required for regulating various life activities. Kinases and phosphatases that regulate protein phosphorylation in humans have been targeted to treat various diseases, particularly cancer. High-throughput experimental methods to discover protein phosphosites are laborious and time-consuming. The burgeoning databases and predictors provide essential infrastructure to the research community. To date, >60 publicly available phosphorylation databases and predictors each have been developed. In this review, we have comprehensively summarized the status and applicability of major online phosphorylation databases and predictors, thereby helping researchers rapidly select tools that are most suitable for their projects. Moreover, the organizational strategies and limitations of these databases and predictors have been highlighted, which may facilitate the development of better protein phosphorylation predictors in silico.",2,High-throughput experimental methods to discover protein phosphosites are laborious and time-consuming.
MCANet: shared-weight-based MultiheadCrossAttention network for drug-target interaction prediction.,36892153,https://pubmed.ncbi.nlm.nih.gov/36892153/,https://doi.org/10.1093/bib/bbad082,"['deep learning', 'drug–target interaction', 'ensemble model', 'shared-weight-based MultiheadCrossAttention']","Accurate and effective drug-target interaction (DTI) prediction can greatly shorten the drug development lifecycle and reduce the cost of drug development. In the deep-learning-based paradigm for predicting DTI, robust drug and protein feature representations and their interaction features play a key role in improving the accuracy of DTI prediction. Additionally, the class imbalance problem and the overfitting problem in the drug-target dataset can also affect the prediction accuracy, and reducing the consumption of computational resources and speeding up the training process are also critical considerations. In this paper, we propose shared-weight-based MultiheadCrossAttention, a precise and concise attention mechanism that can establish the association between target and drug, making our models more accurate and faster. Then, we use the cross-attention mechanism to construct two models: MCANet and MCANet-B. In MCANet, the cross-attention mechanism is used to extract the interaction features between drugs and proteins for improving the feature representation ability of drugs and proteins, and the PolyLoss loss function is applied to alleviate the overfitting problem and the class imbalance problem in the drug-target dataset. In MCANet-B, the robustness of the model is improved by combining multiple MCANet models and prediction accuracy further increases. We train and evaluate our proposed methods on six public drug-target datasets and achieve state-of-the-art results. In comparison with other baselines, MCANet saves considerable computational resources while maintaining accuracy in the leading position; however, MCANet-B greatly improves prediction accuracy by combining multiple models while maintaining a balance between computational resource consumption and prediction accuracy.",3,Accurate and effective drug-target interaction (DTI) prediction can greatly shorten the drug development lifecycle and reduce the cost of drug development.
"Machine learning on protein-protein interaction prediction: models, challenges and trends.",36880207,https://pubmed.ncbi.nlm.nih.gov/36880207/,https://doi.org/10.1093/bib/bbad076,"['computational PPI prediction', 'deep learning', 'machine learning', 'protein–protein interaction']","Protein-protein interactions (PPIs) carry out the cellular processes of all living organisms. Experimental methods for PPI detection suffer from high cost and false-positive rate, hence efficient computational methods are highly desirable for facilitating PPI detection. In recent years, benefiting from the enormous amount of protein data produced by advanced high-throughput technologies, machine learning models have been well developed in the field of PPI prediction. In this paper, we present a comprehensive survey of the recently proposed machine learning-based prediction methods. The machine learning models applied in these methods and details of protein data representation are also outlined. To understand the potential improvements in PPI prediction, we discuss the trend in the development of machine learning-based methods. Finally, we highlight potential directions in PPI prediction, such as the use of computationally predicted protein structures to extend the data source for machine learning models. This review is supposed to serve as a companion for further improvements in this field.",4,Protein-protein interactions (PPIs) carry out cellular processes of all living organisms.. Experimental methods for PPI detection suffer from high cost and false-positive rate.
MAW: the reproducible Metabolome Annotation Workflow for untargeted tandem mass spectrometry.,36871033,https://pubmed.ncbi.nlm.nih.gov/36871033/,https://doi.org/10.1186/s13321-023-00695-y,"['FAIR', 'Metabolite annotation', 'Tandem mass spectrometry', 'Untargeted metabolomics', 'Workflow']","Mapping the chemical space of compounds to chemical structures remains a challenge in metabolomics. Despite the advancements in untargeted liquid chromatography-mass spectrometry (LC-MS) to achieve a high-throughput profile of metabolites from complex biological resources, only a small fraction of these metabolites can be annotated with confidence. Many novel computational methods and tools have been developed to enable chemical structure annotation to known and unknown compounds such as in silico generated spectra and molecular networking. Here, we present an automated and reproducible Metabolome Annotation Workflow (MAW) for untargeted metabolomics data to further facilitate and automate the complex annotation by combining tandem mass spectrometry (MS",6,Mapping the chemical space of compounds to chemical structures remains a challenge in metabolomics.
"Signature literature review reveals AHCY, DPYSL3, and NME1 as the most recurrent prognostic genes for neuroblastoma.",36870971,https://pubmed.ncbi.nlm.nih.gov/36870971/,https://doi.org/10.1186/s13040-023-00325-1,"['Endocrine neoplasia', 'Neuro-oncology', 'Neuroblastoma', 'Pediatric cancers', 'Prognostic signatures', 'Review', 'Scientific literature', 'Signatures', 'Survey']","Neuroblastoma is a childhood neurological tumor which affects hundreds of thousands of children worldwide, and information about its prognosis can be pivotal for patients, their families, and clinicians. One of the main goals in the related bioinformatics analyses is to provide stable genetic signatures able to include genes whose expression levels can be effective to predict the prognosis of the patients. In this study, we collected the prognostic signatures for neuroblastoma published in the biomedical literature, and noticed that the most frequent genes present among them were three: AHCY, DPYLS3, and NME1. We therefore investigated the prognostic power of these three genes by performing a survival analysis and a binary classification on multiple gene expression datasets of different groups of patients diagnosed with neuroblastoma. Finally, we discussed the main studies in the literature associating these three genes with neuroblastoma. Our results, in each of these three steps of validation, confirm the prognostic capability of AHCY, DPYLS3, and NME1, and highlight their key role in neuroblastoma prognosis. Our results can have an impact on neuroblastoma genetics research: biologists and medical researchers can pay more attention to the regulation and expression of these three genes in patients having neuroblastoma, and therefore can develop better cures and treatments which can save patients' lives.",1,Neuroblastoma is a childhood neurological tumor which affects hundreds of thousands of children worldwide.
Benchmarking of Machine Learning classifiers on plasma proteomic for COVID-19 severity prediction through interpretable artificial intelligence.,36868685,https://pubmed.ncbi.nlm.nih.gov/36868685/,https://doi.org/10.1016/j.artmed.2023.102490,"['Artificial intelligence', 'COVID-19', 'Forecasting', 'Machine Learning', 'Severity prediction']","The SARS-CoV-2 pandemic highlighted the need for software tools that could facilitate patient triage regarding potential disease severity or even death. In this article, an ensemble of Machine Learning (ML) algorithms is evaluated in terms of predicting the severity of their condition using plasma proteomics and clinical data as input. An overview of AI-based technical developments to support COVID-19 patient management is presented outlining the landscape of relevant technical developments. Based on this review, the use of an ensemble of ML algorithms that analyze clinical and biological data (i.e., plasma proteomics) of COVID-19 patients is designed and deployed to evaluate the potential use of AI for early COVID-19 patient triage. The proposed pipeline is evaluated using three publicly available datasets for training and testing. Three ML ""tasks"" are defined, and several algorithms are tested through a hyperparameter tuning method to identify the highest-performance models. As overfitting is one of the typical pitfalls for such approaches (mainly due to the size of the training/validation datasets), a variety of evaluation metrics are used to mitigate this risk. In the evaluation procedure, recall scores ranged from 0.6 to 0.74 and F1-score from 0.62 to 0.75. The best performance is observed via Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM) algorithms. Additionally, input data (proteomics and clinical data) were ranked based on corresponding Shapley additive explanation (SHAP) values and evaluated for their prognosticated capacity and immuno-biological credence. This ""interpretable"" approach revealed that our ML models could discern critical COVID-19 cases predominantly based on patient's age and plasma proteins on B cell dysfunction, hyper-activation of inflammatory pathways like Toll-like receptors, and hypo-activation of developmental and immune pathways like SCF/c-Kit signaling. Finally, the herein computational workflow is corroborated in an independent dataset and MLP superiority along with the implication of the abovementioned predictive biological pathways are corroborated. Regarding limitations of the presented ML pipeline, the datasets used in this study contain less than 1000 observations and a significant number of input features hence constituting a high-dimensional low-sample (HDLS) dataset which could be sensitive to overfitting. An advantage of the proposed pipeline is that it combines biological data (plasma proteomics) with clinical-phenotypic data. Thus, in principle, the presented approach could enable patient triage in a timely fashion if used on already trained models. However, larger datasets and further systematic validation are needed to confirm the potential clinical value of this approach. The code is available on Github: https://github.com/inab-certh/Predicting-COVID-19-severity-through-interpretable-AI-analysis-of-plasma-proteomics.",1,The SARS-CoV-2 pandemic highlighted the need for software tools that could facilitate patient triage regarding potential disease severity or even death.
Automatic documentation of professional health interactions: A systematic review.,36868684,https://pubmed.ncbi.nlm.nih.gov/36868684/,https://doi.org/10.1016/j.artmed.2023.102487,"['Automatic documentation', 'EHR', 'Neural networks']","Electronic systems are increasingly present in the healthcare system and are often related to improved medical care. However, the widespread use of these technologies ended up building a relationship of dependence that can disrupt the doctor-patient relationship. In this context, digital scribes are automated clinical documentation systems that capture the physician-patient conversation and then generate the documentation for the appointment, enabling the physician to engage with the patient entirely. We have performed a systematic literature review on intelligent solutions for automatic speech recognition (ASR) with automatic documentation during a medical interview. The scope included only original research on systems that could detect speech and transcribe it in a natural and structured fashion simultaneously with the doctor-patient interaction, excluding speech-to-text-only technologies. The search resulted in a total of 1995 titles, with eight articles remaining after filtering for the inclusion and exclusion criteria. The intelligent models mainly consisted of an ASR system with natural language processing capability, a medical lexicon, and structured text output. None of the articles had a commercially available product at the time of the publication and reported limited real-life experience. So far, none of the applications has been prospectively validated and tested in large-scale clinical studies. Nonetheless, these first reports suggest that automatic speech recognition may be a valuable tool in the future to facilitate medical registration in a faster and more reliable manner. Improving transparency, accuracy, and empathy could drastically change how patients and doctors experience a medical visit. Unfortunately, clinical data on the usability and benefits of such applications is almost non-existent. We believe that future work in this area is necessary and needed.",2,Digital scribes are automated clinical documentation systems that capture the physician-patient conversation and then generate the documentation for the appointment.
A mentorship and incubation program using project-based learning to build a professional bioinformatics pipeline in Kenya.,36862660,https://pubmed.ncbi.nlm.nih.gov/36862660/,https://doi.org/10.1371/journal.pcbi.1010904,[],"The demand for well-trained bioinformaticians to support genomics research continues to rise. Unfortunately, undergraduate training in Kenya does not prepare students for specialization in bioinformatics. Graduates are often unaware of the career opportunities in bioinformatics, and those who are may lack mentors to help them choose a specialization. The Bioinformatics Mentorship and Incubation Program seeks to bridge the gap by laying the foundation for a bioinformatics training pipeline using project-based learning. The program selects six participants through an intensive open recruitment exercise for highly competitive students to join the program for four months. The six interns undergo intensive training within the first one and a half months before being assigned to mini-projects. We track the progress of the interns weekly through code review sessions and a final presentation at the end of the four months. We have trained five cohorts, most of whom have secured master's scholarships within and outside the country and job opportunities. We demonstrate the benefit of structured mentorship using project-based learning in filling the training gap after undergraduate programs to generate well-trained bioinformaticians who are competitive in graduate programs and bioinformatics jobs.",1,Undergraduate training in Kenya does not prepare students for specialization in bioinformatics.
Reconstructing B cell lineage trees with minimum spanning tree and genotype abundances.,36849917,https://pubmed.ncbi.nlm.nih.gov/36849917/,https://doi.org/10.1186/s12859-022-05112-z,"['B cell receptor repertoire', 'Lineage Tree', 'phylogenetics']","B cell receptor (BCR) genes exposed to an antigen undergo somatic hypermutations and Darwinian antigen selection, generating a large BCR-antibody diversity. This process, known as B cell affinity maturation, increases antibody affinity, forming a specific B cell lineage that includes the unmutated ancestor and mutated variants. In a B cell lineage, cells with a higher antigen affinity will undergo clonal expansion, while those with a lower affinity will not proliferate and probably be eliminated. Therefore, cellular (genotype) abundance provides a valuable perspective on the ongoing evolutionary process. Phylogenetic tree inference is often used to reconstruct B cell lineage trees and represents the evolutionary dynamic of BCR affinity maturation. However, such methods should process B-cell population data derived from experimental sampling that might contain different cellular abundances. There are a few phylogenetic methods for tracing the evolutionary events occurring in B cell lineages; best-performing solutions are time-demanding and restricted to analysing a reduced number of sequences, while time-efficient methods do not consider cellular abundances. We propose ClonalTree, a low-complexity and accurate approach to construct B-cell lineage trees that incorporates genotype abundances into minimum spanning tree (MST) algorithms. Using both simulated and experimental data, we demonstrate that ClonalTree outperforms MST-based algorithms and achieves a comparable performance to a method that explores tree-generating space exhaustively. Furthermore, ClonalTree has a lower running time, being more convenient for building B-cell lineage trees from high-throughput BCR sequencing data, mainly in biomedical applications, where a lower computational time is appreciable. It is hundreds to thousands of times faster than exhaustive approaches, enabling the analysis of a large set of sequences within minutes or seconds and without loss of accuracy. The source code is freely available at github.com/julibinho/ClonalTree.",4,B cell receptor (BCR) genes exposed to an antigen undergo somatic hypermutations and Darwinian antigen selection.
Beware of Simple Methods for Structure-Based Virtual Screening: The Critical Importance of Broader Comparisons.,36848585,https://pubmed.ncbi.nlm.nih.gov/36848585/,https://doi.org/10.1021/acs.jcim.3c00218,[],"We discuss how data unbiasing and simple methods such as protein-ligand Interaction FingerPrint (IFP) can overestimate virtual screening performance. We also show that IFP is strongly outperformed by target-specific machine-learning scoring functions, which were not considered in a recent report concluding that simple methods were better than machine-learning scoring functions at virtual screening.",3,Simple methods such as protein-ligand Interaction FingerPrint (IFP) can overestimate virtual screening performance.
Exploring and Learning the Universe of Protein Allostery Using Artificial Intelligence Augmented Biophysical and Computational Approaches.,36827465,https://pubmed.ncbi.nlm.nih.gov/36827465/,https://doi.org/10.1021/acs.jcim.2c01634,"['SARS-CoV-2', 'allosteric drug design', 'allosteric mechanisms', 'artificial intelligence', 'first principles', 'high-throughput deep mutational scanning', 'machine learning', 'protein allostery', 'structural prediction methods']","Allosteric mechanisms are commonly employed regulatory tools used by proteins to orchestrate complex biochemical processes and control communications in cells. The quantitative understanding and characterization of allosteric molecular events are among major challenges in modern biology and require integration of innovative computational experimental approaches to obtain atomistic-level knowledge of the allosteric states, interactions, and dynamic conformational landscapes. The growing body of computational and experimental studies empowered by emerging artificial intelligence (AI) technologies has opened up new paradigms for exploring and learning the universe of protein allostery from first principles. In this review we analyze recent developments in high-throughput deep mutational scanning of allosteric protein functions; applications and latest adaptations of Alpha-fold structural prediction methods for studies of protein dynamics and allostery; new frontiers in integrating machine learning and enhanced sampling techniques for characterization of allostery; and recent advances in structural biology approaches for studies of allosteric systems. We also highlight recent computational and experimental studies of the SARS-CoV-2 spike (S) proteins revealing an important and often hidden role of allosteric regulation driving functional conformational changes, binding interactions with the host receptor, and mutational escape mechanisms of S proteins which are critical for viral infection. We conclude with a summary and outlook of future directions suggesting that AI-augmented biophysical and computer simulation approaches are beginning to transform studies of protein allostery toward systematic characterization of allosteric landscapes, hidden allosteric states, and mechanisms which may bring about a new revolution in molecular biology and drug discovery.",6,Allosteric mechanisms are commonly employed regulatory tools used by proteins to orchestrate complex biochemical processes.
TIDAL: Topology-Inferred Drug Addiction Learning.,36826415,https://pubmed.ncbi.nlm.nih.gov/36826415/,https://doi.org/10.1021/acs.jcim.3c00046,[],"Drug addiction is a global public health crisis, and the design of antiaddiction drugs remains a major challenge due to intricate mechanisms. Since experimental drug screening and optimization are too time-consuming and expensive, there is urgent need to develop innovative artificial intelligence (AI) methods for addressing the challenge. We tackle this challenge by topology-inferred drug addiction learning (TIDAL) built from integrating multiscale topological Laplacians, deep bidirectional transformer, and ensemble-assisted neural networks (EANNs). Multiscale topological Laplacians are a novel class of algebraic topology tools that embed molecular topological invariants and algebraic invariants into its harmonic spectra and nonharmonic spectra, respectively. These invariants complement sequence information extracted from a bidirectional transformer. We validate the proposed TIDAL framework on 22 drug addiction related, 4 hERG, and 12 DAT data sets, which suggests that the proposed TIDAL is a state-of-the-art framework for the modeling and analysis of drug addiction data. We carry out cross-target analysis of the current drug addiction candidates to alert their side effects and identify their repurposing potentials. Our analysis reveals drug-mediated linear and bilinear target correlations. Finally, TIDAL is applied to shed light on relative efficacy, repurposing potential, and potential side effects of 12 existing antiaddiction medications. Our results suggest that TIDAL provides a new computational strategy for pressingly needed antisubstance addiction drug development.",3,"Topology-inferred drug addiction learning (TIDAL) is built from integrating multiscale topological Laplacians, deep bidirectional transformer, and ensemble-assisted"
MetaProFi: an ultrafast chunked Bloom filter for storing and querying protein and nucleotide sequence data for accurate identification of functionally relevant genetic variants.,36825843,https://pubmed.ncbi.nlm.nih.gov/36825843/,https://doi.org/10.1093/bioinformatics/btad101,[],"Bloom filters are a popular data structure that allows rapid searches in large sequence datasets. So far, all tools work with nucleotide sequences; however, protein sequences are conserved over longer evolutionary distances, and only mutations on the protein level may have any functional significance.",1,"Bloom filters are a popular data structure that allows rapid searches in large sequence datasets.. So far, all tools work with nucleotide sequences."
Analysis of Protein Folding Simulation with Moving Root Mean Square Deviation.,36821519,https://pubmed.ncbi.nlm.nih.gov/36821519/,https://doi.org/10.1021/acs.jcim.2c01444,[],"We apply moving root-mean-square deviation (mRMSD), which does not require a reference structure, as a method for analyzing protein dynamics. This method can be used to calculate the root-mean-square deviation (RMSD) of structure between two specified time points and to analyze protein dynamics behavior through time series analysis. We applied this method to the Trp-cage trajectory calculated by the Anton supercomputer and found that it shows regions of stable states as well as the conventional RMSD. In addition, we extracted a characteristic structure in which the side chains of Asp1 and Arg16 form hydrogen bonds near the most stable structure of the Trp-cage. We also determined that ≥20 ns is an appropriate time interval to investigate protein dynamics using mRMSD. Applying this method to NuG2 protein, we found that mRMSD can be used to detect regions of metastable states in addition to the stable state. This method can be applied to molecular dynamics simulations of proteins whose stable structures are unknown.",3,Moving root-mean-square deviation (mRMSD) does not require a reference structure.
CLAIRE: contrastive learning-based batch correction framework for better balance between batch mixing and preservation of cellular heterogeneity.,36821425,https://pubmed.ncbi.nlm.nih.gov/36821425/,https://doi.org/10.1093/bioinformatics/btad099,[],"Integration of growing single-cell RNA sequencing datasets helps better understand cellular identity and function. The major challenge for integration is removing batch effects while preserving biological heterogeneities. Advances in contrastive learning have inspired several contrastive learning-based batch correction methods. However, existing contrastive-learning-based methods exhibit noticeable ad hoc trade-off between batch mixing and preservation of cellular heterogeneities (mix-heterogeneity trade-off). Therefore, a deliberate mix-heterogeneity trade-off is expected to yield considerable improvements in scRNA-seq dataset integration.",1,Integration of growing single-cell RNA sequencing datasets helps better understand cellular identity and function.. The major challenge for integration is removing batch effects while preserving biological heterogeneities.
BEAR: A Novel Virtual Screening Method Based on Large-Scale Bioactivity Data.,36821004,https://pubmed.ncbi.nlm.nih.gov/36821004/,https://doi.org/10.1021/acs.jcim.2c01300,[],"Data-driven drug discovery exploits a comprehensive set of big data to provide an efficient path for the development of new drugs. Currently, publicly available bioassay data sets provide extensive information regarding the bioactivity profiles of millions of compounds. Using these large-scale drug screening data sets, we developed a novel in silico method to virtually screen hit compounds against protein targets, named BEAR (Bioactive compound Enrichment by Assay Repositioning). The underlying idea of BEAR is to reuse bioassay data for predicting hit compounds for targets other than their originally intended purposes, i.e., ""assay repositioning"". The BEAR approach differs from conventional virtual screening methods in that (1) it relies solely on bioactivity data and requires no physicochemical features of either the target or ligand. (2) Accordingly, structurally diverse candidates are predicted, allowing for scaffold hopping. (3) BEAR shows stable performance across diverse target classes, suggesting its general applicability. Large-scale cross-validation of more than a thousand targets showed that BEAR accurately predicted known ligands (median area under the curve = 0.87), proving that BEAR maintained a robust performance even in the validation set with additional constraints. In addition, a comparative analysis demonstrated that BEAR outperformed other machine learning models, including a recent deep learning model for ABC transporter family targets. We predicted P-gp and BCRP dual inhibitors using the BEAR approach and validated the predicted candidates using in vitro assays. The intracellular accumulation effects of mitoxantrone, a well-known P-gp/BCRP dual substrate for cancer treatment, confirmed nine out of 72 dual inhibitor candidates preselected by primary cytotoxicity screening. Consequently, these nine hits are novel and potent dual inhibitors for both P-gp and BCRP, solely predicted by bioactivity profiles without relying on any structural information of targets or ligands.",1,Data-driven drug discovery exploits a comprehensive set of big data to provide an efficient path for the development of new drugs.
Enzyme Substrate Prediction from Three-Dimensional Feature Representations Using Space-Filling Curves.,36802628,https://pubmed.ncbi.nlm.nih.gov/36802628/,https://doi.org/10.1021/acs.jcim.3c00005,[],"Compact and interpretable structural feature representations are required for accurately predicting properties and function of proteins. In this work, we construct and evaluate three-dimensional feature representations of protein structures based on space-filling curves (SFCs). We focus on the problem of enzyme substrate prediction, using two ubiquitous enzyme families as case studies: the short-chain dehydrogenase/reductases (SDRs) and the ",1, Compact and interpretable structural feature representations are required for accurately predicting properties and function of proteins.
Modeling and Simulation of Bacterial Outer Membranes with Lipopolysaccharides and Capsular Polysaccharides.,36802606,https://pubmed.ncbi.nlm.nih.gov/36802606/,https://doi.org/10.1021/acs.jcim.3c00072,[],"Capsule is one of the common virulence factors in Gram-negative bacteria protecting pathogens from host defenses and consists of long-chain capsular polysaccharides (CPS) anchored in the outer membrane (OM). Elucidating structural properties of CPS is important to understand its biological functions as well as the OM properties. However, the outer leaflet of the OM in current simulation studies is represented exclusively by LPS due to the complexity and diversity of CPS. In this work, representative ",3,Capsule is one of the common virulence factors in Gram-negative bacteria.
Persistent Tor-algebra for protein-protein interaction analysis.,36790858,https://pubmed.ncbi.nlm.nih.gov/36790858/,https://doi.org/10.1093/bib/bbad046,[],"Protein-protein interactions (PPIs) play crucial roles in almost all biological processes from cell-signaling and membrane transport to metabolism and immune systems. Efficient characterization of PPIs at the molecular level is key to the fundamental understanding of PPI mechanisms. Even with the gigantic amount of PPI models from graphs, networks, geometry and topology, it remains as a great challenge to design functional models that efficiently characterize the complicated multiphysical information within PPIs. Here we propose persistent Tor-algebra (PTA) model for a unified algebraic representation of the multiphysical interactions. Mathematically, our PTA is inherently algebraic data analysis. In our PTA model, protein structures and interactions are described as a series of face rings and Tor modules, from which PTA model is developed. The multiphysical information within/between biomolecules are implicitly characterized by PTA and further represented as PTA barcodes. To test our PTA models, we consider PTA-based ensemble learning for PPI binding affinity prediction. The two most commonly used datasets, i.e. SKEMPI and AB-Bind, are employed. It has been found that our model outperforms all the existing models as far as we know. Mathematically, our PTA model provides a highly efficient way for the characterization of molecular structures and interactions.",1,Protein-protein interactions (PPIs) play crucial roles in almost all biological processes.
MSGCL: inferring miRNA-disease associations based on multi-view self-supervised graph structure contrastive learning.,36790856,https://pubmed.ncbi.nlm.nih.gov/36790856/,https://doi.org/10.1093/bib/bbac623,"['contrastive learning', 'miRNA–disease associations', 'multi-view', 'self-supervised']","Potential miRNA-disease associations (MDA) play an important role in the discovery of complex human disease etiology. Therefore, MDA prediction is an attractive research topic in the field of biomedical machine learning. Recently, several models have been proposed for this task, but their performance limited by over-reliance on relevant network information with noisy graph structure connections. However, the application of self-supervised graph structure learning to MDA tasks remains unexplored. Our study is the first to use multi-view self-supervised contrastive learning (MSGCL) for MDA prediction. Specifically, we generated a learner view without association labels of miRNAs and diseases as input, and utilized the known association network to generate an anchor view that provides guiding signals for the learner view. The graph structure was optimized by designing a contrastive loss to maximize the consistency between the anchor and learner views. Our model is similar to a pre-trained model that continuously optimizes upstream tasks for high-quality association graph topology, thereby enhancing the latent representation of association predictions. The experimental results show that our proposed method outperforms state-of-the-art methods by 2.79$\%$ and 3.20$\%$ in area under the receiver operating characteristic curve (AUC) and area under the precision/recall curve (AUPR), respectively.",3, potential miRNA-disease associations (MDA) play an important role in the discovery of complex human disease etiology.
MDBuilder: a PyMOL plugin for the preparation of molecular dynamics simulations.,36790845,https://pubmed.ncbi.nlm.nih.gov/36790845/,https://doi.org/10.1093/bib/bbad057,"['AMBER', 'CHARMM', 'NAMD', 'PyMOL', 'biomolecular simulations', 'molecular dynamics']","The preprocessed initial files that feed the molecular dynamics (MD) simulation packages dramatically influence the outcome of the simulations. However, the popular MD simulation packages depend, to a great extent, on the user's experience in the preparation of MD simulation systems. In this work, we present an easy-to-use tool called MDBuilder, a PyMOL plugin that assists researchers in building the starting structures for multiple popular MD simulation packages. MDBuilder is not only designed to assist MD beginners to overcome the steep learning curve by providing a menu-oriented, point-and-click user graphic interface (GUI), but also to provide an alternative way to prepare the input files for some highly scalable CHARMM force field-based MD simulation packages. The platform-independent GUI is implemented as a PyMOL plugin using the Python language, and it has been tested on Windows and Linux platforms. The source code and documentation of MDBuilder can be downloaded freely from https://github.com/HuiLiuCode/MDBuilder under the GNU General Public License.",2,MDBuilder is a PyMOL plugin that assists researchers in building the starting structures for multiple popular MD simulation packages.
A computational framework of routine test data for the cost-effective chronic disease prediction.,36772998,https://pubmed.ncbi.nlm.nih.gov/36772998/,https://doi.org/10.1093/bib/bbad054,"['biochemical test', 'chronic diseases', 'machine learning', 'prediction', 'routine blood test']","Chronic diseases, because of insidious onset and long latent period, have become the major global disease burden. However, the current chronic disease diagnosis methods based on genetic markers or imaging analysis are challenging to promote completely due to high costs and cannot reach universality and popularization. This study analyzed massive data from routine blood and biochemical test of 32 448 patients and developed a novel framework for cost-effective chronic disease prediction with high accuracy (AUC 87.32%). Based on the best-performing XGBoost algorithm, 20 classification models were further constructed for 17 types of chronic diseases, including 9 types of cancers, 5 types of cardiovascular diseases and 3 types of mental illness. The highest accuracy of the model was 90.13% for cardia cancer, and the lowest was 76.38% for rectal cancer. The model interpretation with the SHAP algorithm showed that CREA, R-CV, GLU and NEUT% might be important indices to identify the most chronic diseases. PDW and R-CV are also discovered to be crucial indices in classifying the three types of chronic diseases (cardiovascular disease, cancer and mental illness). In addition, R-CV has a higher specificity for cancer, ALP for cardiovascular disease and GLU for mental illness. The association between chronic diseases was further revealed. At last, we build a user-friendly explainable machine-learning-based clinical decision support system (DisPioneer: http://bioinfor.imu.edu.cn/dispioneer) to assist in predicting, classifying and treating chronic diseases. This cost-effective work with simple blood tests will benefit more people and motivate clinical implementation and further investigation of chronic diseases prevention and surveillance program.",1,The study analyzed massive data from routine blood and biochemical test of 32 448 patients.
Identification of metal ion-binding sites in RNA structures using deep learning method.,36772993,https://pubmed.ncbi.nlm.nih.gov/36772993/,https://doi.org/10.1093/bib/bbad049,"['RNA structure', 'deep learning method', 'metal ion-binding site', 'microenvironment', 'visualization']","Metal ion is an indispensable factor for the proper folding, structural stability and functioning of RNA molecules. However, it is very difficult for experimental methods to detect them in RNAs. With the increase of experimentally resolved RNA structures, it becomes possible to identify the metal ion-binding sites in RNA structures through in-silico methods. Here, we propose an approach called Metal3DRNA to identify the binding sites of the most common metal ions (Mg2+, Na+ and K+) in RNA structures by using a three-dimensional convolutional neural network model. The negative samples, screened out based on the analysis for binding surroundings of metal ions, are more like positive ones than the randomly selected ones, which are beneficial to a powerful predictor construction. The microenvironments of the spatial distributions of C, O, N and P atoms around a sample are extracted as features. Metal3DRNA shows a promising prediction power, generally surpassing the state-of-the-art methods FEATURE and MetalionRNA. Finally, utilizing the visualization method, we inspect the contributions of nucleotide atoms to the classification in several cases, which provides a visualization that helps to comprehend the model. The method will be helpful for RNA structure prediction and dynamics simulation study. Availability and implementation: The source code is available at https://github.com/ChunhuaLiLab/Metal3DRNA.",2,"Metal ion is an indispensable factor for the proper folding, structural stability and functioning of RNA molecules."
Dockey: a modern integrated tool for large-scale molecular docking and virtual screening.,36764832,https://pubmed.ncbi.nlm.nih.gov/36764832/,https://doi.org/10.1093/bib/bbad047,"['drug design', 'molecular docking', 'parallel docking', 'protein–ligand interactions', 'virtual screening']","Molecular docking is a structure-based and computer-aided drug design approach that plays a pivotal role in drug discovery and pharmaceutical research. AutoDock is the most widely used molecular docking tool for study of protein-ligand interactions and virtual screening. Although many tools have been developed to streamline and automate the AutoDock docking pipeline, some of them still use outdated graphical user interfaces and have not been updated for a long time. Meanwhile, some of them lack cross-platform compatibility and evaluation metrics for screening lead compound candidates. To overcome these limitations, we have developed Dockey, a flexible and intuitive graphical interface tool with seamless integration of several useful tools, which implements a complete docking pipeline covering molecular sanitization, molecular preparation, paralleled docking execution, interaction detection and conformation visualization. Specifically, Dockey can detect the non-covalent interactions between small molecules and proteins and perform cross-docking between multiple receptors and ligands. It has the capacity to automatically dock thousands of ligands to multiple receptors and analyze the corresponding docking results in parallel. All the generated data will be kept in a project file that can be shared between any systems and computers with the pre-installation of Dockey. We anticipate that these unique characteristics will make it attractive for researchers to conduct large-scale molecular docking without complicated operations, particularly for beginners. Dockey is implemented in Python and freely available at https://github.com/lmdu/dockey.",6,Dockey can detect the non-covalent interactions between small molecules and proteins and perform cross-docking between multiple receptors and ligands.
Bioinformatics toolbox for exploring target mutation-induced drug resistance.,36738254,https://pubmed.ncbi.nlm.nih.gov/36738254/,https://doi.org/10.1093/bib/bbad033,"['in silico', 'database', 'drug resistance mutation', 'protein–ligand affinity', 'web server']","Drug resistance is increasingly among the main issues affecting human health and threatening agriculture and food security. In particular, developing approaches to overcome target mutation-induced drug resistance has long been an essential part of biological research. During the past decade, many bioinformatics tools have been developed to explore this type of drug resistance, and they have become popular for elucidating drug resistance mechanisms in a low cost, fast and effective way. However, these resources are scattered and underutilized, and their strengths and limitations have not been systematically analyzed and compared. Here, we systematically surveyed 59 freely available bioinformatics tools for exploring target mutation-induced drug resistance. We analyzed and summarized these resources based on their functionality, data volume, data source, operating principle, performance, etc. And we concisely discussed the strengths, limitations and application examples of these tools. Specifically, we tested some predictive tools and offered some thoughts from the clinician's perspective. Hopefully, this work will provide a useful toolbox for researchers working in the biomedical, pesticide, bioinformatics and pharmaceutical engineering fields, and a good platform for non-specialists to quickly understand drug resistance prediction.",3,Drug resistance is increasingly among the main issues affecting human health and threatening agriculture and food security.
Benefit-aware early prediction of health outcomes on multivariate EEG time series.,36736937,https://pubmed.ncbi.nlm.nih.gov/36736937/,https://doi.org/10.1016/j.jbi.2023.104296,"['EEG', 'Early classification', 'Multivariate time series']","Given a cardiac-arrest patient being monitored in the ICU (intensive care unit) for brain activity, how can we predict their health outcomes as early as possible? Early decision-making is critical in many applications, e.g. monitoring patients may assist in early intervention and improved care. On the other hand, early prediction on EEG data poses several challenges: (i) earliness-accuracy trade-off; observing more data often increases accuracy but sacrifices earliness, (ii) large-scale (for training) and streaming (online decision-making) data processing, and (iii) multi-variate (due to multiple electrodes) and multi-length (due to varying length of stay of patients) time series. Motivated by this real-world application, we present BeneFitter that infuses the incurred savings from an early prediction as well as the cost from misclassification into a unified domain-specific target called benefit. Unifying these two quantities allows us to directly estimate a single target (i.e. benefit), and importantly, (a) is efficient and fast, with training time linear in the number of input sequences, and can operate in real-time for decision-making, (b) can handle multi-variate and variable-length time-series, suitable for patient data, and (c) is effective, providing up to 2× time-savings with equal or better accuracy as compared to competitors.",1,"Early decision-making is critical in many applications, e.g. monitoring patients may assist in early intervention and improved care."
SWEET: a single-sample network inference method for deciphering individual features in disease.,36719112,https://pubmed.ncbi.nlm.nih.gov/36719112/,https://doi.org/10.1093/bib/bbad032,"['drug repurposing', 'gene expression', 'network inference', 'network medicine', 'precision medicine', 'single-sample network']","Recently, extracting inherent biological system information (e.g. cellular networks) from genome-wide expression profiles for developing personalized diagnostic and therapeutic strategies has become increasingly important. However, accurately constructing single-sample networks (SINs) to capture individual characteristics and heterogeneity in disease remains challenging. Here, we propose a sample-specific-weighted correlation network (SWEET) method to model SINs by integrating the genome-wide sample-to-sample correlation (i.e. sample weights) with the differential network between perturbed and aggregate networks. For a group of samples, the genome-wide sample weights can be assessed without prior knowledge of intrinsic subpopulations to address the network edge number bias caused by sample size differences. Compared with the state-of-the-art SIN inference methods, the SWEET SINs in 16 cancers more likely fit the scale-free property, display higher overlap with the human interactomes and perform better in identifying three types of cancer-related genes. Moreover, integrating SWEET SINs with a network proximity measure facilitates characterizing individual features and therapy in diseases, such as somatic mutation, mut-driver and essential genes. Biological experiments further validated two candidate repurposable drugs, albendazole for head and neck squamous cell carcinoma (HNSCC) and lung adenocarcinoma (LUAD) and encorafenib for HNSCC. By applying SWEET, we also identified two possible LUAD subtypes that exhibit distinct clinical features and molecular mechanisms. Overall, the SWEET method complements current SIN inference and analysis methods and presents a view of biological systems at the network level to offer numerous clues for further investigation and clinical translation in network medicine and precision medicine.",3,The SWEET method complements current SIN inference and analysis methods.
Sequence-based prediction of pH-dependent protein solubility using CamSol.,36719110,https://pubmed.ncbi.nlm.nih.gov/36719110/,https://doi.org/10.1093/bib/bbad004,"['developability', 'drug formulation', 'pH dependency', 'protein solubility', 'solubility prediction']","Solubility is a property of central importance for the use of proteins in research in molecular and cell biology and in applications in biotechnology and medicine. Since experimental methods for measuring protein solubility are material intensive and time consuming, computational methods have recently emerged to enable the rapid and inexpensive screening of solubility for large libraries of proteins, as it is routinely required in development pipelines. Here, we describe the development of one such method to include in the predictions the effect of the pH on solubility. We illustrate the resulting pH-dependent predictions on a variety of antibodies and other proteins to demonstrate that these predictions achieve an accuracy comparable with that of experimental methods. We make this method publicly available at https://www-cohsoftware.ch.cam.ac.uk/index.php/camsolph, as the version 3.0 of CamSol.",4,Solubility is a property of central importance for the use of proteins in research in molecular and cell biology and in applications in biotechnology and medicine.
Biological knowledge graph-guided investigation of immune therapy response in cancer with graph neural network.,36682018,https://pubmed.ncbi.nlm.nih.gov/36682018/,https://doi.org/10.1093/bib/bbad023,"['deep learning', 'graph neural networks', 'immune checkpoints inhibitors']","The determination of transcriptome profiles that mediate immune therapy in cancer remains a major clinical and biological challenge. Despite responses induced by immune-check points inhibitors (ICIs) in diverse tumor types and all the big breakthroughs in cancer immunotherapy, most patients with solid tumors do not respond to ICI therapies. It still remains a big challenge to predict the ICI treatment response. Here, we propose a framework with multiple prior knowledge networks guided for immune checkpoints inhibitors prediction-DeepOmix-ICI (or ICInet for short). ICInet can predict the immune therapy response by leveraging geometric deep learning and prior biological knowledge graphs of gene-gene interactions. Here, we demonstrate more than 600 ICI-treated patients with ICI response data and gene expression profile to apply on ICInet. ICInet was used for ICI therapy responses prediciton across different cancer types-melanoma, gastric cancer and bladder cancer, which includes 7 cohorts from different data sources. ICInet is able to robustly generalize into multiple cancer types. Moreover, the performance of ICInet in those cancer types can outperform other ICI biomarkers in the clinic. Our model [area under the curve (AUC = 0.85)] generally outperformed other measures, including tumor mutational burden (AUC = 0.62) and programmed cell death ligand-1 score (AUC = 0.74). Therefore, our study presents a prior-knowledge guided deep learning method to effectively select immunotherapy-response-associated biomarkers, thereby improving the prediction of immunotherapy response for precision oncology.",3,The determination of transcriptome profiles that mediate immune therapy in cancer remains a major clinical and biological challenge.
Discovery of Natural Bisbenzylisoquinoline Analogs from the Library of Thai Traditional Plants as SARS-CoV-2 3CL,36647612,https://pubmed.ncbi.nlm.nih.gov/36647612/,https://doi.org/10.1021/acs.jcim.2c01309,[],The emergence of SARS-CoV-2 in December 2019 has become a global issue due to the continuous upsurge in patients and the lack of drug efficacy for treatment. SARS-CoV-2 3CL,4,The emergence of SARS-CoV-2 in December 2019 has become a global issue due to the continuous upsurge in patients and the lack of drug efficacy for treatment.
RabbitFX: Efficient Framework for FASTA/Q File Parsing on Modern Multi-Core Platforms.,36327193,https://pubmed.ncbi.nlm.nih.gov/36327193/,https://doi.org/10.1109/TCBB.2022.3219114,[],"The continuous growth of generated sequencing data leads to the development of a variety of associated bioinformatics tools. However, many of them are not able to fully exploit the resources of modern multi-core systems since they are bottlenecked by parsing files leading to slow execution times. This motivates the design of an efficient method for parsing sequencing data that can exploit the power of modern hardware, especially for modern CPUs with fast storage devices. We have developed RabbitFX, a fast, efficient, and easy-to-use framework for processing biological sequencing data on modern multi-core platforms. It can efficiently read FASTA and FASTQ files by combining a lightweight parsing method by means of an optimized formatting implementation. Furthermore, we provide user-friendly and modularized C++ APIs that can be easily integrated into applications in order to increase their file parsing speed. As proof-of-concept, we have integrated RabbitFX into three I/O-intensive applications: fastp, Ktrim, and Mash. Our evaluation shows that the inclusion of RabbitFX leads to speedups of at least 11.6 (6.6), 2.4 (2.4), and 3.7 (3.2) compared to the original versions on plain (gzip-compressed) files, respectively. These case studies demonstrate that RabbitFX can be easily integrated into a variety of NGS analysis tools to significantly reduce associated runtimes. It is open source software available at https://github.com/RabbitBio/RabbitFX.",2,RabbitFX is a framework for processing biological sequencing data on modern multi-core platforms.
An Efficient Detection and Classification of Acute Leukemia Using Transfer Learning and Orthogonal Softmax Layer-Based Model.,36318567,https://pubmed.ncbi.nlm.nih.gov/36318567/,https://doi.org/10.1109/TCBB.2022.3218590,[],"For the early diagnosis of hematological disorders like blood cancer, microscopic analysis of blood cells is very important. Traditional deep CNNs lead to overfitting when it receives small medical image datasets such as ALLIDB1, ALLIDB2, and ASH. This paper proposes a new and effective model for classifying and detecting Acute Lymphoblastic Leukemia (ALL) or Acute Myelogenous Leukemia (AML) that delivers excellent performance in small medical datasets. Here, we have proposed a novel Orthogonal SoftMax Layer (OSL)-based Acute Leukemia detection model that consists of ResNet 18-based deep feature extraction followed by efficient OSL-based classification. Here, OSL is integrated with the ResNet18 to improve the classification performance by making the weight vectors orthogonal to each other. Hence, it integrates ResNet benefits (residual learning and identity mapping) with the benefits of OSL-based classification (improvement of feature discrimination capability and computational efficiency). Furthermore, we have introduced extra dropout and ReLu layers in the architecture to achieve a faster network with enhanced performance. The performance verification is performed on standard ALLIDB1, ALLIDB2, and C_NMC_2019 datasets for efficient ALL detection and ASH dataset for effective AML detection. The experimental performance demonstrates the superiority of the proposed model over other compairing models.",4,Traditional deep CNNs lead to overfitting when it receives small medical image datasets.
PARCEL: Physics-Based Unsupervised Contrastive Representation Learning for Multi-Coil MR Imaging.,36219669,https://pubmed.ncbi.nlm.nih.gov/36219669/,https://doi.org/10.1109/TCBB.2022.3213669,[],"With the successful application of deep learning to magnetic resonance (MR) imaging, parallel imaging techniques based on neural networks have attracted wide attention. However, in the absence of high-quality, fully sampled datasets for training, the performance of these methods is limited. And the interpretability of models is not strong enough. To tackle this issue, this paper proposes a Physics-bAsed unsupeRvised Contrastive rEpresentation Learning (PARCEL) method to speed up parallel MR imaging. Specifically, PARCEL has a parallel framework to contrastively learn two branches of model-based unrolling networks from augmented undersampled multi-coil k-space data. A sophisticated co-training loss with three essential components has been designed to guide the two networks in capturing the inherent features and representations for MR images. And the final MR image is reconstructed with the trained contrastive networks. PARCEL was evaluated on two vivo datasets and compared to five state-of-the-art methods. The results show that PARCEL is able to learn essential representations for accurate MR reconstruction without relying on fully sampled datasets. The code will be made available at https://github.com/ternencewu123/PARCEL.",2,PARCEL has a parallel framework to contrastively learn two branches of model-based unrolling networks from augmented undersampled multi-coil k-space data.
TSNAdb v2.0: The Updated Version of Tumor-specific Neoantigen Database.,36209954,https://pubmed.ncbi.nlm.nih.gov/36209954/,https://doi.org/10.1016/j.gpb.2022.09.012,"['Database', 'Human leukocyte antigen', 'Neoantigen', 'Somatic mutation', 'Tumor immunotherapy']","In recent years, neoantigens have been recognized as ideal targets for tumor immunotherapy. With the development of neoantigen-based tumor immunotherapy, comprehensive neoantigen databases are urgently needed to meet the growing demand for clinical studies. We have built the tumor-specific neoantigen database (TSNAdb) previously, which has attracted much attention. In this study, we provide TSNAdb v2.0, an updated version of the TSNAdb. TSNAdb v2.0 offers several new features, including (1) adopting more stringent criteria for neoantigen identification, (2) providing predicted neoantigens derived from three types of somatic mutations, and (3) collecting experimentally validated neoantigens and dividing them according to the experimental level. TSNAdb v2.0 is freely available at https://pgx.zju.edu.cn/tsnadb/.",5,"In recent years, neoantigens have been recognized as ideal targets for tumor immunotherapy."
A Clustering Method Unifying Cell-Type Recognition and Subtype Identification for Tumor Heterogeneity Analysis.,36044493,https://pubmed.ncbi.nlm.nih.gov/36044493/,https://doi.org/10.1109/TCBB.2022.3203185,[],"The rapid development of single-cell technology has opened up a whole new perspective for identifying cell types in multicellular organisms and understanding the relationships between them. Distinguishing different cell types and subtypes can identify the components of different immune cells and different tumor clones in the tumor microenvironment, which is the basic work of tumor heterogeneity analysis and can help researchers understand the mechanism of tumor immune escape. Existing algorithms treat both cell types and subtypes as populations of cells with specific gene expression patterns, which is not conducive to accurate cell typing. For that, we proposed a cell similarity metric that unifies cell type recognition and subtype identification (UCRSI), with the assumption that selectively expressed genes represent differences in underlying cell type with on/off manner, while differences in expression level represent different cell subtype with more/less manner. Our method calculates these two kinds of differences separately, and then combines them using a consensus adjacency matrix, and finally cell typing is completed using spectral clustering algorithm. The results show that UCRSI can reconstruct expert annotation of single-cell RNA sequencing datasets more robustly than existing methods. And, UCRSI is useful for analyzing tumor heterogeneity and improving visualization of large-scale cell clustering.",1,"Existing algorithms treat both cell types and subtypes as populations of cells with specific gene expression patterns, which is not conducive to accurate cell typing."
WGRLR: A Weighted Group Regularized Logistic Regression for Cancer Diagnosis and Gene Selection.,36044492,https://pubmed.ncbi.nlm.nih.gov/36044492/,https://doi.org/10.1109/TCBB.2022.3203167,[],"Sparse regressions applied to cancer diagnosis suffer from noise reduction, gene grouping, and group significance evaluation. This paper presented the weighted group regularized logistic regression (WGRLR) for dealing with the above problems. Clean data was separated from noisy gene expression profile data, based on which gene grouping and model building were performed. An interpretable gene group significance evaluation criterion was proposed based on symmetrical uncertainty and module eigengene. A group-wise individual gene significance evaluation criterion was also presented. The performances of the proposed method were compared with WGGL, ASGL-CMI, SGL, GL, Elastic Net, and lasso on acute leukemia and brain cancer data. Experimental results demonstrate that the proposed method is superior to the other six methods in cancer diagnosis accuracy and gene selection.",2,WGRLR is a weighted group regularized logistic regression method.
Modeling mRNA Translation With Ribosome Abortions.,36044491,https://pubmed.ncbi.nlm.nih.gov/36044491/,https://doi.org/10.1109/TCBB.2022.3203171,[],"We derive a deterministic mathematical model for the flow of ribosomes along a mRNA called the ribosome flow model with extended objects and abortions (RFMEOA). This model incorporates important cellular features such as every ribosome covers several codons and they may detach from various regions along the track due to more realistic biological situations including phenomena of ribosome-ribosome collisions. We prove that the ribosome density profile along the mRNA in the RFMEOA and in particular, the protein production rate converge to a unique steady-state. Simulations of the RFMEOA demonstrate a surprising result that an increase in the initiation rate may sometimes lead to a decrease in the production rate. We believe that this model could be helpful to provide insight into the effects of premature termination on the protein expression and be useful for understanding and re-engineering the translation process.",1,The model could be helpful to provide insight into the effects of premature termination on the protein expression.
MicroRNA-disease Network Analysis Repurposes Methotrexate for the Treatment of Abdominal Aortic Aneurysm in Mice.,36030000,https://pubmed.ncbi.nlm.nih.gov/36030000/,https://doi.org/10.1016/j.gpb.2022.08.002,"['Abdominal aortic aneurysm', 'Autoimmune disease', 'Methotrexate', 'MicroRNA-derived disease network', 'Network medicine']","Abdominal aortic aneurysm (AAA) is a permanent dilatation of the abdominal aorta and is highly lethal. The main purpose of the current study is to search for noninvasive medical therapies for AAA, for which there is currently no effective drug therapy. Network medicine represents a cutting-edge technology, as analysis and modeling of disease networks can provide critical clues regarding the etiology of specific diseases and therapeutics that may be effective. Here, we proposed a novel algorithm to quantify disease relations based on a large accumulated microRNA-disease association dataset and then built a disease network covering 15 disease classes and 304 diseases. Analysis revealed some patterns for these diseases. For instance, diseases tended to be clustered and coherent in the network. Surprisingly, we found that AAA showed the strongest similarity with rheumatoid arthritis and systemic lupus erythematosus, both of which are autoimmune diseases, suggesting that AAA could be one type of autoimmune diseases in etiology. Based on this observation, we further hypothesized that drugs for autoimmune diseases could be repurposed for the prevention and therapy of AAA. Finally, animal experiments confirmed that methotrexate, a drug for autoimmune diseases, was able to alleviate the formation and development of AAA.",2,Abdominal aortic aneurysm (AAA) is a permanent dilatation of the abdominal aorta.
Explaining Black Box Drug Target Prediction Through Model Agnostic Counterfactual Samples.,35820003,https://pubmed.ncbi.nlm.nih.gov/35820003/,https://doi.org/10.1109/TCBB.2022.3190266,[],"Many high-performance DTA deep learning models have been proposed, but they are mostly black-box and thus lack human interpretability. Explainable AI (XAI) can make DTA models more trustworthy, and allows to distill biological knowledge from the models. Counterfactual explanation is one popular approach to explaining the behaviour of a deep neural network, which works by systematically answering the question ""How would the model output change if the inputs were changed in this way?"". We propose a multi-agent reinforcement learning framework, Multi-Agent Counterfactual Drug-target binding Affinity (MACDA), to generate counterfactual explanations for the drug-protein complex. Our proposed framework provides human-interpretable counterfactual instances while optimizing both the input drug and target for counterfactual generation at the same time. We benchmark the proposed MACDA framework using the Davis and PDBBind dataset and find that our framework produces more parsimonious explanations with no loss in explanation validity, as measured by encoding similarity. We then present a case study involving ABL1 and Nilotinib to demonstrate how MACDA can explain the behaviour of a DTA model in the underlying substructure interaction between inputs in its prediction, revealing mechanisms that align with prior domain knowledge.",1,"Many high-performance DTA deep learning models have been proposed, but they are mostly black-box and thus lack human interpretability."
Hygeia: A Multilabel Deep Learning-Based Classification Method for Imbalanced Electrocardiogram Data.,35605003,https://pubmed.ncbi.nlm.nih.gov/35605003/,https://doi.org/10.1109/TCBB.2022.3176905,[],"Electrocardiogram (ECG) is a common diagnostic indicator of heart disease in hospitals. Because of the low price and noninvasiveness of ECG diagnosis, it is widely used for prescreening and physical examination of heart diseases. In several studies on ECG analysis, only rough diagnoses are made to determine whether ECGs are abnormal or on a few kinds of ECG. In actual scenarios, doctors must analyze ECG samples in detail, which is a multilabel classification problem. Herein, we propose Hygeia, a multilabel deep learning-based ECG classification method that can analyze and classify 55 types of ECG. First, a guidance model is constructed to transform the multilabel classification problem into multiple interrelated two-classification models. This method ensures the good performance of each ECG analysis model, and the relationship between various types of ECG can be used in the analysis. The imbalance of samples in ECG datasets makes it difficult to analyze abnormal ECGs with high sensitivity and accuracy. We used data generation and mixed sampling methods for 11 ECG types with imbalanced problems to improve the average accuracy, sensitivity, F1 value, and accuracy from 87.74%, 43.11%, 0.3929, and 0.3929, to 92.68%, 96.92, 0.9287, and 99.47%, respectively. The average accuracy, sensitivity, F1 value, and accuracy of 44 of the 55 tags of the abnormal ECG analysis model are 99.69%, 95.81%, 0.9758, and 99.72%, respectively.",1,Electrocardiogram (ECG) is a common diagnostic indicator of heart disease in hospitals.
FMGNN: A Method to Predict Compound-Protein Interaction With Pharmacophore Features and Physicochemical Properties of Amino Acids.,35503835,https://pubmed.ncbi.nlm.nih.gov/35503835/,https://doi.org/10.1109/TCBB.2022.3172340,[],"Identifying interactions between compounds and proteins is an essential task in drug discovery. To recommend compounds as new drug candidates, applying the computational approaches has a lower cost than conducting the wet-lab experiments. Machine learning-based methods, especially deep learning-based methods, have advantages in learning complex feature interactions between compounds and proteins. However, deep learning models will over-generalize and lead to the problem of predicting less relevant compound-protein pairs when the compound-protein feature interactions are high-dimensional sparse. This problem can be overcome by learning both low-order and high-order feature interactions. In this paper, we propose a novel hybrid model with Factorization Machines and Graph Neural Network called FMGNN to extract the low-order and high-order features, respectively. Then, we design a compound-protein interactions (CPIs) prediction method with pharmacophore features of compound and physicochemical properties of amino acids. The pharmacophore features can ensure that the prediction results much more fit the expectation of biological experiment and the physicochemical properties of amino acids are loaded into the embedding layer to improve the convergence speed and accuracy of protein feature learning. The experimental results on several datasets, especially on an imbalanced large-scale dataset, showed that our proposed method outperforms other existing methods for CPI prediction. The western blot experiment results on wogonin and its candidate target proteins also showed that our proposed method is effective and accurate for finding target proteins. The computer program of implementing the model FMGNN is available at https://github.com/tcygxu2021/FMGNN.",1,Identifying interactions between compounds and proteins is an essential task in drug discovery.
Predicting miRNA-Disease Associations via Node-Level Attention Graph Auto-Encoder.,35503834,https://pubmed.ncbi.nlm.nih.gov/35503834/,https://doi.org/10.1109/TCBB.2022.3170843,[],"Previous studies have confirmed microRNA (miRNA), small single-stranded non-coding RNA, participates in various biological processes and plays vital roles in many complex human diseases. Therefore, developing an efficient method to infer potential miRNA disease associations could greatly help understand operational mechanisms for diseases at the molecular level. However, during these early stages for miRNA disease prediction, traditional biological experiments are laborious and expensive. Therefore, this study proposes a novel method called AGAEMD (node-level Attention Graph Auto-Encoder to predict potential MiRNA Disease associations). We first create a heterogeneous matrix incorporating miRNA similarity, disease similarity, and known miRNA-disease associations. Then these matrixes are input into a node-level attention encoder-decoder network which utilizes low dimensional dense embeddings to represent nodes and calculate association scores. To verify the effectiveness of the proposed method, we conduct a series of experiments on two benchmark datasets (the Human MicroRNA Disease Database v2.0 and v3.2) and report the averages over 10 runs in comparison with several state-of-the-art methods. Experimental results have demonstrated the excellent performance of AGAEMD in comparison with other methods. Three important diseases (Colon Neoplasms, Lung Neoplasms, Lupus Vulgaris) were applied in case studies. The results comfirm the reliable predictive performance of AGAEMD.",7,Previous studies have confirmed microRNA (miRNA) participates in various biological processes and plays vital roles in many complex human diseases.
Predicting Drug-Target Interaction Via Self-Supervised Learning.,35230952,https://pubmed.ncbi.nlm.nih.gov/35230952/,https://doi.org/10.1109/TCBB.2022.3153963,[],"Recent advances in graph representation learning provide new opportunities for computational drug-target interaction (DTI) prediction. However, it still suffers from deficiencies of dependence on manual labels and vulnerability to attacks. Inspired by the success of self-supervised learning (SSL) algorithms, which can leverage input data itself as supervision,we propose SupDTI, a SSL-enhanced drug-target interaction prediction framework based on a heterogeneous network (i.e., drug-protein, drug-drug, and protein-protein interaction network; drug-disease, drug-side-effect, and protein-disease association network; drug-structure and protein-sequence similarity network). Specifically, SupDTI is an end-to-end learning framework consisting of five components. First, localized and globalized graph convolutions are designed to capture the nodes' information from both local and global perspectives, respectively. Then, we develop a variational autoencoder to constrain the nodes' representation to have desired statistical characteristics. Finally, a unified self-supervised learning strategy is leveraged to enhance the nodes' representation, namely, a contrastive learning module is employed to enable the nodes' representation to fit the graph-level representation, followed by a generative learning module which further maximizes the node-level agreement across the global and local views by learning the probabilistic connectivity distribution of the original heterogeneous network. Experimental results show that our model can achieve better prediction performance than state-of-the-art methods.",2,SupDTI is an end-to-end learning framework consisting of five components.
Screening Linear and Circular RNA Transcripts from Stress Granules.,35085777,https://pubmed.ncbi.nlm.nih.gov/35085777/,https://doi.org/10.1016/j.gpb.2022.01.003,"['Circular RNA', 'Hepatocellular carcinoma', 'Protein–RNA interaction', 'RNA-seq', 'Stress granule']","Stress granules (SGs) are cytoplasmic ribonucleoprotein assemblies formed under stress conditions and are related to various biological processes and human diseases. Previous studies have reported the regulatory role of some proteins and linear RNAs in SG assembly. However, the relationship between circular RNAs (circRNAs) and SGs has not been discovered. Here, we screened both linear RNAs and circRNAs in SGs using improved total RNA sequencing of purified SG cores in mammalian cells and identified circular transcripts specifically localized in SGs. circRNAs with higher SG-related RNA-binding protein (RBP) binding abilities are more likely to be enriched in SGs. Furthermore, some SG-enriched circRNAs are differentially expressed in hepatocellular carcinoma (HCC) and adjacent tissues. These results suggest the regulatory role of circRNAs in SG formation and provide insights into the biological function of circRNAs and SGs in HCC.",6,Stress granules (SGs) are cytoplasmic ribonucleoprotein assemblies formed under stress conditions.
Semi-Supervised 3D Medical Image Segmentation Based on Dual-Task Consistent Joint Learning and Task-Level Regularization.,35061590,https://pubmed.ncbi.nlm.nih.gov/35061590/,https://doi.org/10.1109/TCBB.2022.3144428,[],"Semi-supervised learning has attracted wide attention from many researchers since its ability to utilize a few data with labels and relatively more data without labels to learn information. Some existing semi-supervised methods for medical image segmentation enforce the regularization of training by implicitly perturbing data or networks to perform the consistency. Most consistency regularization methods focus on data level or network structure level, and rarely of them focus on the task level. It may not directly lead to an improvement in task accuracy. To overcome the problem, this work proposes a semi-supervised dual-task consistent joint learning framework with task-level regularization for 3D medical image segmentation. Two branches are utilized to simultaneously predict the segmented and signed distance maps, and they can learn useful information from each other by constructing a consistency loss function between the two tasks. The segmentation branch learns rich information from both labeled and unlabeled data to strengthen the constraints on the geometric structure of the target. Experimental results on two benchmark datasets show that the proposed method can achieve better performance compared with other state-of-the-art works. It illustrates our method improves segmentation performance by utilizing unlabeled data and consistent regularization.",1,Semi-supervised learning has attracted wide attention from many researchers since its ability to utilize a few data with labels and relatively more data without labels to learn information.
